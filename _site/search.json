[
  {
    "objectID": "BDC334/L02a-gradients.html",
    "href": "BDC334/L02a-gradients.html",
    "title": "Lecture 2a. Ecological Gradients",
    "section": "",
    "text": "BCB743\n\n\n\nThis material must be reviewed by BCB743 students in Week 1 of Quantitative Ecology.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2a. Ecological Gradients"
    ]
  },
  {
    "objectID": "BDC334/L02a-gradients.html#robert-h.-whittakers-role-in-understanding-community-formation",
    "href": "BDC334/L02a-gradients.html#robert-h.-whittakers-role-in-understanding-community-formation",
    "title": "Lecture 2a. Ecological Gradients",
    "section": "Robert H. Whittaker’s Role in Understanding Community Formation",
    "text": "Robert H. Whittaker’s Role in Understanding Community Formation\nRobert H. Whittaker (1920-1980) was instrumental in shaping our understanding of ecological gradients and their role in species community formation. He challenged the prevailing Clementsian view of his time of communities as discrete, interdependent units, and instead proposed the “individualistic hypothesis” (Whittaker 1953). This hypothesis posited that species respond individually to environmental gradients, resulting in gradual shifts in community composition along these gradients.\nWhittaker’s undertook extensive field research in diverse ecosystems, from the Great Smoky Mountains to the Siskiyou Mountains. This work provided strong empirical support for his hypothesis (Whittaker 1967). He developed the “gradient analysis” method, a quantitative approach to studying species distributions along environmental gradients, which became a cornerstone of modern community ecology.\nWhittaker’s placed community ecology onto a new trajectory and shifted the focus from discrete community types to the continuous variation of species along environmental gradients. This shift is continuing to have deep implications for our understanding of biodiversity patterns, ecosystem functioning, and conservation strategies.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2a. Ecological Gradients"
    ]
  },
  {
    "objectID": "BDC334/L02a-gradients.html#environmental-gradients",
    "href": "BDC334/L02a-gradients.html#environmental-gradients",
    "title": "Lecture 2a. Ecological Gradients",
    "section": "Environmental Gradients",
    "text": "Environmental Gradients\n\n\n\n\n\nFigure 1: Environmental gradients exist across space and time and link biodiversity outcomes (structure and function) to environmental properties.\n\n\nEnvironmental gradients exist across space and time and link biodiversity outcomes, which we may measure as structure and function, to environmental properties {Figure 1). These gradients can be observed through Earth observation technologies, such as satellite remote sensing, which provide high-resolution spatial data essential for understanding biogeography. Biogeographical patterns help us discern how species distributions and community compositions vary in response to different environmental factors such as temperature, precipitation, and nutrient availability. We refer to these environmental factors as drivers when they affect ecological—and ultimately, biogeographical—outcomes.\nAs we move from present to future scenarios, the data collected enable us to use ecophysiological principles: that is, we use our understanding of physiological processes of organisms and how they adapt to changing environments. Long-term data are crucial for understanding global change processes, such as climate change and nutrient cycles such as those involving N, P, C, and Si, for example. These processes impact ecological outcomes by altering ecosystem structure and function, and can be studied using both classical ecological methods and modern techniques like stable isotopes. These outcomes feed back into biogeochemistry, linking the cycles of key elements to broader ecological and environmental changes. This interconnected approach can help us predict how ecosystems might respond to future environmental shifts, emphasising the importance of integrating data across temporal and spatial scales.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2a. Ecological Gradients"
    ]
  },
  {
    "objectID": "BDC334/L02a-gradients.html#sec-unimodal",
    "href": "BDC334/L02a-gradients.html#sec-unimodal",
    "title": "Lecture 2a. Ecological Gradients",
    "section": "The Unimodal Model",
    "text": "The Unimodal Model\nThe ‘unimodal’ model (sensu Whittaker 1967) is a core concept in ecology. It provides a framework for understanding how species and communities are distributed along environmental gradients and offers an intuitive explanation for the patterns we observe in nature.\nThe unimodal model posits that the relationship between a species’ abundance (or other measures such as biomass or relative frequency) and its position along an environmental gradient follows a unimodal function. This means that the abundance of a species typically peaks at a specific point along the gradient where the conditions are ‘just right’ (to quote Goldilocks) and decreases as conditions deviate from this optimum in either direction.\nThe model implies that each species has a unique set of optimal conditions under which it thrives and attains maximal abundance. This ‘sweet spot’ represents the ideal combination of environmental factors for that particular species. As conditions move away from this optimum, whether becoming too hot or too cold, too wet or too dry, the species’ abundance decreases. This creates a characteristic bell-shaped curve (Figure 2) when plotting abundance against the environmental gradient.\n\nShow the codelibrary(coenocliner)\nset.seed(666)\nM &lt;- 3                                     # number of species\nming &lt;- 3.5                                # gradient minimum...\nmaxg &lt;- 7                                  # ...and maximum\nlocs &lt;- seq(ming, maxg, length = 100)      # gradient locations\nopt  &lt;- runif(M, min = ming, max = maxg)   # species optima\ntol  &lt;- rep(0.25, M)                       # species tolerances\nh    &lt;- ceiling(rlnorm(M, meanlog = 3))    # max abundances\npars &lt;- cbind(opt = opt, tol = tol, h = h) # put in a matrix\n\nmu &lt;- coenocline(locs, responseModel = \"gaussian\", params = pars,\n                 expectation = TRUE)\n\nmatplot(locs, mu, lty = \"solid\", type = \"l\", xlab = \"pH\", ylab = \"Abundance\")\n\n\n\n\n\n\nFigure 2: A coenocline representing the unimodal model of abundance of three species along a hypothetical environmental gradient.\n\n\n\n\nThe unimodal model is simple to understand and has a broad applicability. It’s trivial to conceptualise how species come to be arranged or sorted along gradients based on their individual optimal conditions and tolerance ranges. This sorting effect explains why we often observe distinct changes in species composition as we move along environmental gradients, such as elevation in mountains or moisture in transitions from wetlands to uplands, or even across wider regional gradients such as along a coastline influenced by a western boundary current (e.g. Agulhas Current) or east to west across South Africa. This gives rise to the ideas of distance-decay relationships, community structuring along elevation gradients, and species turnover, for all of which the outcome can be measured as beta diversity.\nIn real-world ecosystems, however, multiple gradients co-exist simultaneously and the situation may be more complex than alluded to in Figure 2. Species are responding not just to one environmental factor, but to a complex interplay of various gradients. These might include temperature, precipitation, soil pH, nutrient availability, and many others. As a result, communities—collections of species coexisting in a given area—are formed within this multidimensional ‘space’ of gradients. Please see the section on coenoplanes and coenospaces for more information. To complicate things further, many types of biotic interactions (e.g. competition, predation, mutualism) can also influence species distributions and community assembly.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2a. Ecological Gradients"
    ]
  },
  {
    "objectID": "BDC334/L02a-gradients.html#sec-niches",
    "href": "BDC334/L02a-gradients.html#sec-niches",
    "title": "Lecture 2a. Ecological Gradients",
    "section": "Fundamental and Realised Niches",
    "text": "Fundamental and Realised Niches\nThe formation of communities in this gradient space can be conceptualised as the outcome of multiple interacting unimodal species-environment relationships, modulated by complex biological interactions. Each species in the community occupies a position that reflects its response to various environmental gradients, shaped by its physiological tolerances, competitive abilities, and other biotic factors. This interplay leads to the complex patterns of species composition and diversity we observe in nature.\nTo fully understand this process, we must consider the concepts of fundamental and realised niches. The fundamental niche represents the full range of environmental conditions under which a species could potentially thrive in the absence of biotic interactions. In the context of the unimodal model, this would correspond to the species’ theoretical response curves along various environmental gradients.\nHowever, in real ecosystems, species rarely occupy their entire fundamental niche. Instead, they occupy a realised niche, which is typically a subset of the fundamental niche. The realised niche is shaped by biotic interactions such as competition, predation, and mutualism, as well as by dispersal limitations and historical factors. In the gradient space, a species’ realised niche is represented by its actual measurable distribution and abundance patterns.\nThe interaction between fundamental and realised niches adds layers of complexity to community formation. Competition may lead to niche compression, where species occupy narrower niches than they are physiologically capable of. Conversely, in the absence of competitors or predators, species might experience niche expansion. Over time, niche differentiation can occur as species evolve to reduce competition, potentially altering their response to environmental gradients.\nMoreover, some species exhibit niche plasticity, adjusting their ecological roles in response to environmental changes or biotic pressures. Others engage in niche construction, actively modifying their environment and thereby altering the gradient space for themselves and other species.\nUnderstanding these dynamics is important if we wish to interpret the complex patterns we observe and measure in nature. ‘Community assembly’ (note, not implying a deliberate act) is not simply a passive response to existing gradients, but a dynamic process involving adaptation, competition, and environmental modification. We must consider both abiotic factors, as emphasised in the unimodal model, and the various kinds of biotic interactions, as highlighted by the concept of realised niches.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2a. Ecological Gradients"
    ]
  },
  {
    "objectID": "BDC334/L02a-gradients.html#the-unified-neutral-theory-of-biodiversity",
    "href": "BDC334/L02a-gradients.html#the-unified-neutral-theory-of-biodiversity",
    "title": "Lecture 2a. Ecological Gradients",
    "section": "The Unified Neutral Theory of Biodiversity",
    "text": "The Unified Neutral Theory of Biodiversity\nAn alternative (or complementary?) hypothesis for community formation—which we will not cover too much but you are nevertheless required to understand the basic premise of—is the Unified Neutral Theory of Biodiversity (UNTB). This theory posits that species in a community are functionally equivalent and that their relative abundances are determined by stochastic processes rather than by their individual traits or interactions. In other words, the UNTB suggests that all species are ecologically equivalent and that community composition is the result of random dispersal, speciation, and extinction events.\nPlease consult the following references for more information on the UNTB:\n\nHubbell (2005)\nHubbell (2011)\nRosindell et al. (2012)\nNeutral Theory of Species Diversity",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2a. Ecological Gradients"
    ]
  },
  {
    "objectID": "blog/2023-11-13-basic-mhw-detect/index.html",
    "href": "blog/2023-11-13-basic-mhw-detect/index.html",
    "title": "Basic Detection and Visualisation of Marine Heatwaves",
    "section": "",
    "text": "This material also appears as a heatwaveR vignette.\nIn the previous post, we demonstrated how to use the heatwaveR package to detect and visualise marine heatwaves (MHWs) and cold spells (MCSs). In this post, we will demonstrate how to use the package to detect and visualise these extreme events. We will also demonstrate how to use the package to calculate the duration, intensity, and cumulative intensity of MHWs and MCSs."
  },
  {
    "objectID": "blog/2023-11-13-basic-mhw-detect/index.html#data",
    "href": "blog/2023-11-13-basic-mhw-detect/index.html#data",
    "title": "Basic Detection and Visualisation of Marine Heatwaves",
    "section": "Data",
    "text": "Data\nThe detect_event() function is the core of this package, and it expects to be fed the output of the second core function, ts2clm(). By default, ts2clm() wants to receive a two-column dataframe with one column labelled t containing all of the date values, and a second column temp containing all of the temperature values. Please note that the date format it expects is “YYYY-MM-DD”. For example, please see the top five rows of one of the datasets included with the heatwaveR package:\n\nhead(heatwaveR::sst_WA)\n\n# A tibble: 6 × 2\n  t           temp\n  &lt;date&gt;     &lt;dbl&gt;\n1 1982-01-01  20.9\n2 1982-01-02  21.2\n3 1982-01-03  21.4\n4 1982-01-04  21.2\n5 1982-01-05  21.3\n6 1982-01-06  21.6\n\n\nIt is possible to use different column names other than t and temp with which to calculate events. Please see the help files for ts2clm() or detect_event() for a thorough explanation of how to do so.\nLoading ones data from a .csv file or other text based format is the easiest approach for the calculation of events, assuming one is not working with gridded data (e.g. NetCDF). Please see this vignette for a detailed walkthrough on using the functions in this package with gridded data."
  },
  {
    "objectID": "blog/2023-11-13-basic-mhw-detect/index.html#calculating-marine-heatwaves-mhws",
    "href": "blog/2023-11-13-basic-mhw-detect/index.html#calculating-marine-heatwaves-mhws",
    "title": "Basic Detection and Visualisation of Marine Heatwaves",
    "section": "Calculating marine heatwaves (MHWs)",
    "text": "Calculating marine heatwaves (MHWs)\nHere are the ts2clm() and detect_event() function applied to the Western Australia test data included with this package (sst_WA), which are also discussed by Hobday et al. (2016):\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(heatwaveR)\n\n# Detect the events in a time series\nts &lt;- ts2clm(sst_WA, climatologyPeriod = c(\"1982-01-01\", \"2011-12-31\"))\nmhw &lt;- detect_event(ts)\n\n# View just a few metrics\nmhw$event %&gt;% \n  dplyr::ungroup() %&gt;%\n  dplyr::select(event_no, duration, date_start, date_peak, intensity_max, intensity_cumulative) %&gt;% \n  dplyr::arrange(-intensity_max) %&gt;% \n  head(5)\n\n# A tibble: 5 × 6\n  event_no duration date_start date_peak  intensity_max intensity_cumulative\n     &lt;int&gt;    &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;             &lt;dbl&gt;                &lt;dbl&gt;\n1       52      105 2010-12-24 2011-02-28          6.58                293. \n2       41       35 2008-03-25 2008-04-14          3.83                 79.3\n3       29       95 1999-05-13 1999-05-22          3.64                240. \n4       60       14 2012-12-27 2012-12-31          3.42                 32.3\n5       59      101 2012-01-10 2012-01-27          3.38                214."
  },
  {
    "objectID": "blog/2023-11-13-basic-mhw-detect/index.html#visualising-marine-heatwaves-mhws",
    "href": "blog/2023-11-13-basic-mhw-detect/index.html#visualising-marine-heatwaves-mhws",
    "title": "Basic Detection and Visualisation of Marine Heatwaves",
    "section": "Visualising marine heatwaves (MHWs)",
    "text": "Visualising marine heatwaves (MHWs)\nDefault MHW visuals\nOne may use event_line() and lolli_plot() directly on the output of detect_event() in order to visualise MHWs. Here are the functions being used to visualise the massive Western Australian heatwave of 2011:\n\nevent_line(mhw, spread = 180, metric = \"intensity_max\", \n           start_date = \"1982-01-01\", end_date = \"2014-12-31\")\n\nlolli_plot(mhw, metric = \"intensity_max\")\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\n\nCustom MHW visuals\nThe event_line() and lolli_plot() functions were designed to work directly on the list returned by detect_event(). If more control over the figures is required, it may be useful to create them in ggplot2 by stacking geoms. We specifically created two new ggplot2 geoms to reproduce the functionality of event_line() and lolli_plot(). These functions are more general in their functionality and can be used outside of the heatwaveR package, too. To apply them to MHWs and MCSs first requires that we access the climatology or event dataframes within the list that is produced by detect_event(). Here is how:\n\n# Select the region of the time series of interest\nmhw2 &lt;- mhw$climatology %&gt;% \n  slice(10580:10720)\n\nggplot(mhw2, aes(x = t, y = temp, y2 = thresh)) +\n  geom_flame() +\n  geom_text(aes(x = as.Date(\"2011-02-25\"), y = 25.8, label = \"the Destroyer\\nof Kelps\"))\n\nggplot(mhw$event, aes(x = date_start, y = intensity_max)) +\n  geom_lolli(colour = \"salmon\", colour_n = \"red\", n = 3) +\n  geom_text(colour = \"black\", aes(x = as.Date(\"2006-08-01\"), y = 5,\n                label = \"The marine heatwaves\\nTend to be left skewed in a\\nGiven time series\")) +\n  labs(y = expression(paste(\"Max. intensity [\", degree, \"C]\")), x = NULL)\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\nSpicy MHW visuals\nThe default output of these function may not be to your liking. If so, not to worry. As ggplot2 geoms, they are highly malleable. For example, if we were to choose to reproduce the format of the MHWs as seen in Hobday et al. (2016), the code would look something like this:\n\n# It is necessary to give geom_flame() at least one row on either side of \n# the event in order to calculate the polygon corners smoothly\nmhw_top &lt;- mhw2 %&gt;% \n  slice(5:111)\n\nggplot(data = mhw2, aes(x = t)) +\n  geom_flame(aes(y = temp, y2 = thresh, fill = \"all\"), show.legend = T) +\n  geom_flame(data = mhw_top, aes(y = temp, y2 = thresh, fill = \"top\"),  show.legend = T) +\n  geom_line(aes(y = temp, colour = \"temp\")) +\n  geom_line(aes(y = thresh, colour = \"thresh\"), size = 1.0) +\n  geom_line(aes(y = seas, colour = \"seas\"), size = 1.2) +\n  scale_colour_manual(name = \"Line Colour\",\n                      values = c(\"temp\" = \"black\", \n                                 \"thresh\" =  \"forestgreen\", \n                                 \"seas\" = \"grey80\")) +\n  scale_fill_manual(name = \"Event Colour\", \n                    values = c(\"all\" = \"salmon\", \n                               \"top\" = \"red\")) +\n  scale_x_date(date_labels = \"%b %Y\") +\n  guides(colour = guide_legend(override.aes = list(fill = NA))) +\n  labs(y = expression(paste(\"Temperature [\", degree, \"C]\")), x = NULL)\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\nIt is also worth pointing out that when we use geom_flame() directly like this, but we don’t want to highlight events greater less than our standard five day length, allowing for a two day gap, we want to use the arguments n and n_gap respectively.\n\nmhw3 &lt;- mhw$climatology %&gt;% \n  slice(850:950)\n\nggplot(mhw3, aes(x = t, y = temp, y2 = thresh)) +\n  geom_flame(fill = \"black\", alpha = 0.5) +\n  # Note the use of n = 5 and n_gap = 2 below\n  geom_flame(n = 5, n_gap = 2, fill = \"red\", alpha = 0.5) +\n  ylim(c(22, 25)) +\n    geom_text(colour = \"black\", aes(x = as.Date(\"1984-05-16\"), y = 24.5,\n                label = \"heat\\n\\n\\n\\n\\nspike\"))\n\n\n\n\n\n\n\nShould we not wish to highlight any events with geom_lolli(), plot them with a colour other than the default, and use a different theme, it would look like this:\n\nggplot(mhw$event, aes(x = date_peak, y = intensity_max)) +\n  geom_lolli(colour = \"firebrick\") +\n  labs(x = \"Peak Date\", \n       y = expression(paste(\"Max. intensity [\", degree, \"C]\")), x = NULL) +\n  theme_linedraw()\n\n\n\n\n\n\nFigure 6\n\n\n\n\n\nBecause these are simple ggplot2 geoms possibilities are nearly infinite."
  },
  {
    "objectID": "blog/2023-11-13-basic-mhw-detect/index.html#calculating-marine-cold-spells-mcss",
    "href": "blog/2023-11-13-basic-mhw-detect/index.html#calculating-marine-cold-spells-mcss",
    "title": "Basic Detection and Visualisation of Marine Heatwaves",
    "section": "Calculating marine cold-spells (MCSs)",
    "text": "Calculating marine cold-spells (MCSs)\nThe calculation and visualisation of cold-spells is also provided for within this package. The data to be fed into the functions is the same as for MHWs. The main difference is that one is now calculating the 10th percentile threshold, rather than the 90th percentile threshold. Here are the top five cold-spells (cumulative intensity) detected in the OISST data for Western Australia:\n\n# First calculate the cold-spells\nts_10th &lt;- ts2clm(sst_WA, climatologyPeriod = c(\"1982-01-01\", \"2011-12-31\"), pctile = 10)\nmcs &lt;- detect_event(ts_10th, coldSpells = TRUE)\n\n# Then look at the top few events\nmcs$event %&gt;% \n  dplyr::ungroup() %&gt;%\n  dplyr::select(event_no, duration, date_start,\n                date_peak, intensity_mean, intensity_max, intensity_cumulative) %&gt;%\n  dplyr::arrange(intensity_cumulative) %&gt;% \n  head(5)\n\n# A tibble: 5 × 7\n  event_no duration date_start date_peak  intensity_mean intensity_max\n     &lt;int&gt;    &lt;dbl&gt; &lt;date&gt;     &lt;date&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n1       15       76 1990-04-13 1990-05-11          -2.50         -3.19\n2       49       58 2003-12-19 2004-01-23          -1.73         -2.59\n3       83       41 2020-04-26 2020-05-25          -2.34         -3.14\n4       64       52 2014-04-14 2014-05-05          -1.78         -2.54\n5       77       46 2018-07-24 2018-08-02          -1.81         -2.43\n# ℹ 1 more variable: intensity_cumulative &lt;dbl&gt;"
  },
  {
    "objectID": "blog/2023-11-13-basic-mhw-detect/index.html#visualising-marine-cold-spells-mcss",
    "href": "blog/2023-11-13-basic-mhw-detect/index.html#visualising-marine-cold-spells-mcss",
    "title": "Basic Detection and Visualisation of Marine Heatwaves",
    "section": "Visualising marine cold-spells (MCSs)",
    "text": "Visualising marine cold-spells (MCSs)\nDefault MCS visuals\nThe default plots showing cold-spells look like this:\n\nevent_line(mcs, spread = 200, metric = \"intensity_cumulative\",\n           start_date = \"1982-01-01\", end_date = \"2014-12-31\")\n\nlolli_plot(mcs, metric = \"intensity_cumulative\", xaxis = \"event_no\")\n\n\n\n\n\n\nFigure 7\n\n\n\n\n\n\n\n\n\nFigure 8\n\n\n\n\n\n\nNote that one does not need to specify that MCSs are to be visualised, the functions are able to understand this on their own.\nCustom MCS visuals\nCold spell figures may be created as geoms in ggplot2, too:\n\n# Select the region of the time series of interest\nmcs2 &lt;- mcs$climatology %&gt;% \n  slice(2900:3190)\n\n# Note that one must specify a colour other than the default 'salmon'\nggplot(mcs2, aes(x = t, y = thresh, y2 = temp)) +\n  geom_flame(fill = \"steelblue3\")\n\nggplot(mcs$event, aes(x = date_start, y = intensity_max)) +\n  geom_lolli(colour = \"steelblue3\", colour_n = \"navy\", n = 3) +\n  labs(x = \"Start Date\",\n       y = expression(paste(\"Max. intensity [\", degree, \"C]\")))\n\n\n\n\n\n\nFigure 9\n\n\n\n\n\n\n\n\n\nFigure 10\n\n\n\n\nMinty MCS visuals\nAgain, because geom_flame() and geom_lolli() are simple ggplot2 geoms, one can go completely bananas with them:\n\nmcs_top &lt;- mcs2 %&gt;% \n  slice(125:202)\n\nggplot(data = mcs2, aes(x = t)) +\n  geom_flame(aes(y = thresh, y2 = temp, fill = \"all\"), show.legend = T) +\n  geom_flame(data = mcs_top, aes(y = thresh, y2 = temp, fill = \"top\"), show.legend = T) +\n  geom_line(aes(y = temp, colour = \"temp\")) +\n  geom_line(aes(y = thresh, colour = \"thresh\"), size = 1.0) +\n  geom_line(aes(y = seas, colour = \"seas\"), size = 1.2) +\n  scale_colour_manual(name = \"Line Colour\",\n                      values = c(\"temp\" = \"black\", \"thresh\" =  \"forestgreen\", \"seas\" = \"grey80\")) +\n  scale_fill_manual(name = \"Event Colour\", values = c(\"all\" = \"steelblue3\", \"top\" = \"navy\")) +\n  scale_x_date(date_labels = \"%b %Y\") +\n  guides(colour = guide_legend(override.aes = list(fill = NA))) +\n  labs(y = expression(paste(\"Temperature [\", degree, \"C]\")), x = NULL)\n\nggplot(mcs$event, aes(x = date_start, y = intensity_cumulative)) +\n  geom_lolli(colour = \"steelblue3\", colour_n = \"navy\", n = 7) +\n  labs( x = \"Start Date\", y = expression(paste(\"Cumulative intensity [days x \", degree, \"C]\")))\n\n\n\n\n\n\nFigure 11\n\n\n\n\n\n\n\n\n\nFigure 12"
  },
  {
    "objectID": "blog/2023-11-13-basic-mhw-detect/index.html#interactive-visuals",
    "href": "blog/2023-11-13-basic-mhw-detect/index.html#interactive-visuals",
    "title": "Basic Detection and Visualisation of Marine Heatwaves",
    "section": "Interactive visuals",
    "text": "Interactive visuals\nAs of heatwaveR v0.3.6.9002, geom_flame() was also able to be used with plotly to allow for interactive MHW visuals. Unfortunately around December of 2020 the plotly packaged was orphaned and CRAN decided it didn’t want packages to include it as an imported package. Therefore as of v0.4.4.9005 heatwaveR no longer has built in support for using geom_flame() with plotly. It is however still possible with a bit of work and a simple working example is given below. It is not currently possible to use geom_lolli() with plotly. Rather one is advised to just create the dots and segments separately with geom_point() and geom_segment() respectively as these are already recognised by plotly.\nNote that the following code chunk is not run as it makes this vignette a bit too large.\n\n# Must load plotly library first\nlibrary(plotly)\n\n# Function needed for making geom_flame() work with plotly\ngeom2trace.GeomFlame &lt;- function (data,\n                                  params,\n                                  p) {\n  \n  x &lt;- y &lt;- y2 &lt;- NULL\n  \n  # Create data.frame for ease of use\n  data1 &lt;- data.frame(x = data[[\"x\"]],\n                      y = data[[\"y\"]],\n                      y2 = data[[\"y2\"]])\n  \n  # Grab parameters\n  n &lt;- params[[\"n\"]]\n  n_gap &lt;- params[[\"n_gap\"]]\n  \n  # Find events that meet minimum length requirement\n  data_event &lt;- heatwaveR::detect_event(data1, x = x, y = y,\n                                        seasClim = y,\n                                        threshClim = y2,\n                                        minDuration = n,\n                                        maxGap = n_gap,\n                                        protoEvents = T)\n  \n  # Detect spikes\n  data_event$screen &lt;- base::ifelse(data_event$threshCriterion == FALSE, FALSE,\n                                    ifelse(data_event$event == FALSE, TRUE, FALSE))\n  \n  # Screen out spikes\n  data1 &lt;- data1[data_event$screen != TRUE,]\n  \n  # Prepare to find the polygon corners\n  x1 &lt;- data1$y\n  x2 &lt;- data1$y2\n  \n  # # Find points where x1 is above x2.\n  above &lt;- x1 &gt; x2\n  above[above == TRUE] &lt;- 1\n  above[is.na(above)] &lt;- 0\n  \n  # Points always intersect when above=TRUE, then FALSE or reverse\n  intersect.points &lt;- which(diff(above) != 0)\n  \n  # Find the slopes for each line segment.\n  x1.slopes &lt;- x1[intersect.points + 1] - x1[intersect.points]\n  x2.slopes &lt;- x2[intersect.points + 1] - x2[intersect.points]\n  \n  # # Find the intersection for each segment.\n  x.points &lt;- intersect.points + ((x2[intersect.points] - x1[intersect.points]) / (x1.slopes - x2.slopes))\n  y.points &lt;- x1[intersect.points] + (x1.slopes * (x.points - intersect.points))\n  \n  # Coerce x.points to the same scale as x\n  x_gap &lt;- data1$x[2] - data1$x[1]\n  x.points &lt;- data1$x[intersect.points] + (x_gap*(x.points - intersect.points))\n  \n  # Create new data frame and merge to introduce new rows of data\n  data2 &lt;- data.frame(y = c(data1$y, y.points), x = c(data1$x, x.points))\n  data2 &lt;- data2[order(data2$x),]\n  data3 &lt;- base::merge(data1, data2, by = c(\"x\",\"y\"), all.y = T)\n  data3$y2[is.na(data3$y2)] &lt;- data3$y[is.na(data3$y2)]\n  \n  # Remove missing values for better plotting\n  data3$y[data3$y &lt; data3$y2] &lt;- NA\n  missing_pos &lt;- !stats::complete.cases(data3[c(\"x\", \"y\", \"y2\")])\n  ids &lt;- cumsum(missing_pos) + 1\n  ids[missing_pos] &lt;- NA\n  \n  # Get the correct positions\n  positions &lt;- data.frame(x = c(data3$x, rev(data3$x)),\n                          y = c(data3$y, rev(data3$y2)),\n                          ids = c(ids, rev(ids)))\n  \n  # Convert to a format geom2trace is happy with\n  positions &lt;- plotly::group2NA(positions, groupNames = \"ids\")\n  positions &lt;- positions[stats::complete.cases(positions$ids),]\n  positions &lt;- dplyr::left_join(positions, data[,-c(2,3)], by = \"x\")\n  if(length(stats::complete.cases(positions$PANEL)) &gt; 1) \n    positions$PANEL &lt;- positions$PANEL[stats::complete.cases(positions$PANEL)][1]\n  if(length(stats::complete.cases(positions$group)) &gt; 1) \n    positions$group &lt;- positions$group[stats::complete.cases(positions$group)][1]\n  \n  # Run the plotly polygon code\n  if(length(unique(positions$PANEL)) == 1){\n    getFromNamespace(\"geom2trace.GeomPolygon\", asNamespace(\"plotly\"))(positions)\n  } else{\n    return()\n  }\n}\n\n# Time series\nts_res &lt;- heatwaveR::ts2clm(data = heatwaveR::sst_WA,\n                            climatologyPeriod = c(\"1982-01-01\", \"2011-12-31\"))\nts_res_sub &lt;- ts_res[10500:10800,]\n\n# Flame Figure\np &lt;- ggplot(data = ts_res_sub, aes(x = t, y = temp)) +\n  heatwaveR::geom_flame(aes(y2 = thresh), n = 5, n_gap = 2) +\n  geom_line(aes(y = temp)) +\n  geom_line(aes(y = seas), colour = \"green\") +\n  geom_line(aes(y = thresh), colour = \"red\") +\n  labs(x = \"\", y = \"Temperature (°C)\")\n\n# Create interactive visuals\nggplotly(p)"
  },
  {
    "objectID": "BCB744/intro_r/08-mapping_style.html",
    "href": "BCB744/intro_r/08-mapping_style.html",
    "title": "8. Mapping With Style",
    "section": "",
    "text": "“Werner Heisenberg is driving down the highway and a police officer stops him. “Sir, do you know you’re going 82 m.p.h.?” the officer asks. “Thanks a lot!” Heisenberg snaps. “Now I’m lost.””\n— Unknown\n\n\n“Science flies you to the moon. Religion flies you into buildings.”\n— Victor Stenger\n\nNow that you have learned the basics of creating a beautiful map in ggplot2 it is time to look at some of the more particular things you will need to make your maps extra stylish. There are also a few more things you need to learn how to do before your maps can be truly publication quality.\nIf we have not yet loaded the tidyverse let’s do so.\n\n# Load libraries\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(ggsn)\n\n# Load Africa map\nload(\"../../data/africa_map.RData\")\n\nDefault maps\nIn order to access the default maps included with the tidyverse we will use the function borders().\n\nggplot() +\n  borders(col = \"black\", fill = \"cornsilk\", size = 0.2) + # The global shape file\n  coord_equal() # Equal sizing for lon/lat \n\n\n\nThe built in global shape file.\n\n\n\nJikes! It’s as simple as that to load a map of the whole planet. Usually you are not going to want to make a map of the entire planet, so let’s see how to focus on just the area around South Africa.\n\nsa_1 &lt;- ggplot() +\n  borders(size = 0.2, fill = \"cornsilk\", colour = \"black\") +\n  coord_equal(xlim = c(12, 36), ylim = c(-38, -22), expand = 0) # Force lon/lat extent\nsa_1\n\n\n\nA better way to get the map of South Africa.\n\n\n\nThat is a very tidy looking map of South(ern) Africa without needing to load any files.\nSpecific labels\nA map is almost always going to need some labels and other visual cues. You saw in the previous section how to add site labels. The following code chunk shows how this differs if yoou want to add just one label at a time. This can be useful if each label needs to be different from all other labels for whatever reason. You may also see that the text labels we are creating have \\n in them. When R sees these two characters together like this it reads this as an instruction to return down a line. Let’s run the code to make sure you see what this means.\n\nsa_2 &lt;- sa_1 +\n  annotate(\"text\", label = \"Atlantic\\nOcean\", \n           x = 15.1, y = -32.0, \n           size = 5.0, \n           angle = 30, \n           colour = \"navy\") +\n  annotate(\"text\", label = \"Indian\\nOcean\", \n           x = 33.2, y = -34.2, \n           size = 5.0, \n           angle = 330, \n           colour = \"red4\")\nsa_2\n\n\n\nMap of southern Africa with specific labels.\n\n\n\nScale bars\nWith your fancy labels added, let’s insert a scale bar next. There is no default scale bar function in the tidyverse, which is why you have loaded the ggsn package. This package is devoted to adding scale bars and North arrows to ggplot2 figures. There are heaps of options so you’ll just focus on one of them for now. It is a bit finicky so to get it looking exactly how you want it requires some guessing and checking. Please feel free to play around with the coordinates below. You may see the list of available North arrow shapes by running northSymbols().\n\nsa_3 &lt;- sa_2 +\n  scalebar(x.min = 22, x.max = 26, y.min = -36, y.max = -35, # Set location of bar\n           dist = 100, dist_unit = \"km\", height = 0.3, st.dist = 0.8, st.size = 4, # Set particulars\n           transform = TRUE, border.size = 0.2, model = \"WGS84\") + # Set appearance\n  north(x.min = 22.5, x.max = 25.5, y.min = -33, y.max = -31, # Set location of symbol\n        scale = 1.2, symbol = 16)\nsa_3\n\n\n\nMap of southern Africa with labels and a scale bar.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSession info\n\ninstalled.packages()[names(sessionInfo()$otherPkgs), \"Version\"]\n\nR&gt;      ggsn    scales lubridate   forcats   stringr     dplyr     purrr     readr \nR&gt;   \"0.5.3\"   \"1.3.0\"   \"1.9.3\"   \"1.0.0\"   \"1.5.1\"   \"1.1.4\"   \"1.0.2\"   \"2.1.5\" \nR&gt;     tidyr    tibble   ggplot2 tidyverse \nR&gt;   \"1.3.1\"   \"3.2.1\"   \"3.5.1\"   \"2.0.0\"\n\n\n\n\n\n\nReuseCC BY-NC-SA 4.0CitationBibTeX citation:@online{j._smit2021,\n  author = {J. Smit, Albertus},\n  title = {8. {Mapping} {With} {Style}},\n  date = {2021-01-01},\n  url = {http://tangledbank.netlify.app/BCB744/intro_r/08-mapping_style.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A (2021) 8. Mapping With Style. http://tangledbank.netlify.app/BCB744/intro_r/08-mapping_style.html.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "8. Mapping With Style"
    ]
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Tangled Bank Blog",
    "section": "",
    "text": "The Blog of the Tangled Bank R Teaching Website at the University of te Western Cape dedicated to the teaching of R and RStudio to students in the Biological Sciences. The Blog deals specifically with applications of R in the Ocean and Biological Sciences, with each post dedicated to solving a computational problem of interest to students and researchers in these fields.\nThe Blog is written by AJ Smit, a Professor in the Department of Biodiversity and Conservation Biology at the University of the Western Cape. AJ is a marine ecologist with a keen interest in the use of R for data analysis and visualisation. AJ is also the author of the Tangled Bank R Teaching Website.\n\n\n\n\n\nBasic Detection and Visualisation of Marine Heatwaves\n\n\nMarine heatwaves and cold spells as per Hobday et al (2016) and Schlegel et al (2017).\n\n\n\nR\n\n\nanalysis\n\n\nMHW\n\n\n\nThis vignette demonstrates the basic use of the heatwaveR package for the detection and visualisation of marine heatwaves.\n\n\n\n\n\nNov 11, 2023\n\n\nAlbertus J. Smit, Robert Schlegel\n\n\n15 min\n\n\n\n\n\n\n\nheatwaveR\n\n\n\n\n\n\nR\n\n\nanalysis\n\n\nMHW\n\n\n\nIntroducing heatwaveR to a non-marine science audience.\n\n\n\n\n\nNov 22, 2023\n\n\nAlbertus J. Smit, Robert Schlegel\n\n\n3 min\n\n\n\n\n\n\n\nDetect event streaks based on specified thresholds\n\n\n\n\n\n\nR\n\n\nanalysis\n\n\nMHW\n\n\n\nThis vignette demonstrates how to use a heatwaveR function to the analysis of experimental data for finding the run lengths of events that meet certain criteria.\n\n\n\n\n\nNov 22, 2023\n\n\nAlbertus J. Smit\n\n\n5 min\n\n\n\n\n\n\nNo matching items\n\n\n\n\n\n\n\n\nReuseCC BY-NC-SA 4.0CitationBibTeX citation:@online{j._smit,\n  author = {J. Smit, Albertus},\n  title = {Tangled {Bank} {Blog}},\n  url = {http://tangledbank.netlify.app/blog.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A Tangled Bank Blog. http://tangledbank.netlify.app/blog.html."
  },
  {
    "objectID": "pages/heatwaveR_publ.html",
    "href": "pages/heatwaveR_publ.html",
    "title": "Notable heatwaveR citations",
    "section": "",
    "text": "Smale, D. A., Wernberg, T., Oliver, E. C., Thomsen, M., Harvey, B. P., Straub, S. C., … & Moore, P. J. (2019). Marine heatwaves threaten global biodiversity and the provision of ecosystem services. Nature Climate Change, 9(4), 306-312.\nBarkhordarian, A., Nielsen, D. M., & Baehr, J. (2022). Recent marine heatwaves in the North Pacific warming pool can be attributed to rising atmospheric levels of greenhouse gases. Communications Earth & Environment, 3(1), 131.\nThoral, F., Montie, S., Thomsen, M. S., Tait, L. W., Pinkerton, M. H., & Schiel, D. R. (2022). Unravelling seasonal trends in coastal marine heatwave metrics across global biogeographical realms. Scientific Reports, 12(1), 7740.\nBenedetti-Cecchi, L. (2021). Complex networks of marine heatwaves reveal abrupt transitions in the global ocean. Scientific Reports, 11(1), 1739.\nWoolway, R. I., Jennings, E., Shatwell, T., Golub, M., Pierson, D. C., & Maberly, S. C. (2021). Lake heatwaves under climate change. Nature, 589(7842), 402-407.\nGarcía Molinos, J., Hunt, H. L., Green, M. E., Champion, C., Hartog, J. R., & Pecl, G. T. (2022). Climate, currents and species traits contribute to early stages of marine species redistribution. Communications biology, 5(1), 1329.\nSmith, K. E., Burrows, M. T., Hobday, A. J., Sen Gupta, A., Moore, P. J., Thomsen, M., … & Smale, D. A. (2021). Socioeconomic impacts of marine heatwaves: Global issues and opportunities. Science, 374(6566), eabj3593."
  },
  {
    "objectID": "pages/heatwaveR_publ.html#sec-impact",
    "href": "pages/heatwaveR_publ.html#sec-impact",
    "title": "Notable heatwaveR citations",
    "section": "",
    "text": "Smale, D. A., Wernberg, T., Oliver, E. C., Thomsen, M., Harvey, B. P., Straub, S. C., … & Moore, P. J. (2019). Marine heatwaves threaten global biodiversity and the provision of ecosystem services. Nature Climate Change, 9(4), 306-312.\nBarkhordarian, A., Nielsen, D. M., & Baehr, J. (2022). Recent marine heatwaves in the North Pacific warming pool can be attributed to rising atmospheric levels of greenhouse gases. Communications Earth & Environment, 3(1), 131.\nThoral, F., Montie, S., Thomsen, M. S., Tait, L. W., Pinkerton, M. H., & Schiel, D. R. (2022). Unravelling seasonal trends in coastal marine heatwave metrics across global biogeographical realms. Scientific Reports, 12(1), 7740.\nBenedetti-Cecchi, L. (2021). Complex networks of marine heatwaves reveal abrupt transitions in the global ocean. Scientific Reports, 11(1), 1739.\nWoolway, R. I., Jennings, E., Shatwell, T., Golub, M., Pierson, D. C., & Maberly, S. C. (2021). Lake heatwaves under climate change. Nature, 589(7842), 402-407.\nGarcía Molinos, J., Hunt, H. L., Green, M. E., Champion, C., Hartog, J. R., & Pecl, G. T. (2022). Climate, currents and species traits contribute to early stages of marine species redistribution. Communications biology, 5(1), 1329.\nSmith, K. E., Burrows, M. T., Hobday, A. J., Sen Gupta, A., Moore, P. J., Thomsen, M., … & Smale, D. A. (2021). Socioeconomic impacts of marine heatwaves: Global issues and opportunities. Science, 374(6566), eabj3593."
  },
  {
    "objectID": "pages/heatwaveR_publ.html#sec-cross",
    "href": "pages/heatwaveR_publ.html#sec-cross",
    "title": "Notable heatwaveR citations",
    "section": "Examples of cross-discipline research in marine heatwaves",
    "text": "Examples of cross-discipline research in marine heatwaves\n\nSchlegel, R. W., Oliver, E. C., & Chen, K. (2021). Drivers of marine heatwaves in the Northwest Atlantic: The role of air–sea interaction during onset and decline. Frontiers in Marine Science, 8, 627970.\nHu, L. (2021). A global assessment of coastal marine heatwaves and their relation with coastal urban thermal changes. Geophysical Research Letters, 48(9), e2021GL093260.\nBarkhordarian, A., Nielsen, D. M., & Baehr, J. (2022). Greenhouse Gas Forcing a Necessary Causation for Marine Heatwaves Over the Northeast Pacific Warming Pool."
  },
  {
    "objectID": "pages/heatwaveR_publ.html#sec-outside",
    "href": "pages/heatwaveR_publ.html#sec-outside",
    "title": "Notable heatwaveR citations",
    "section": "Use outside of the initially intended field of application",
    "text": "Use outside of the initially intended field of application\n\nTassone, S. J., Besterman, A. F., Buelo, C. D., Ha, D. T., Walter, J. A., & Pace, M. L. (2023). Increasing heatwave frequency in streams and rivers of the United States. Limnology and Oceanography Letters, 8(2), 295-304.\nDiniz, F. R., Gonçalves, F. L. T., & Sheridan, S. (2020). Heat wave and elderly mortality: Historical analysis and future projection for metropolitan region of São Paulo, Brazil. Atmosphere, 11(9), 933.\nWoolway, R. I., Albergel, C., Frölicher, T. L., & Perroud, M. (2022). Severe Lake Heatwaves Attributable to Human‐Induced Global Warming. Geophysical Research Letters, 49(4), e2021GL097031.\nReynaert, S., De Boeck, H. J., Verbruggen, E., Verlinden, M., Flowers, N., & Nijs, I. (2021). Risk of short‐term biodiversity loss under more persistent precipitation regimes. Global Change Biology, 27(8), 1614-1626.\nWoolway, R. I., Anderson, E. J., & Albergel, C. (2021). Rapidly expanding lake heatwaves under climate change. Environmental Research Letters, 16(9), 094013.\nPaton, E. (2022). Intermittency analysis of dry spell magnitude and timing using different spell definitions. Journal of Hydrology, 608, 127645.\nMartinez-Baroja, L., Rey-Benayas, J. M., Perez-Camacho, L., & Villar-Salvador, P. (2022). Drivers of oak establishment in Mediterranean old fields from 25-year-old woodland islets planted to assist natural regeneration. European Journal of Forest Research, 141(1), 17-30.\nPappert, D., Barriendos, M., Brugnara, Y., Imfeld, N., Jourdain, S., Przybylak, R., … & Brönnimann, S. (2022). Statistical reconstruction of daily temperature and sea level pressure in Europe for the severe winter 1788/89. Climate of the Past, 18(12), 2545-2565.\nNgoungue Langue, C. G., Lavaysse, C., Vrac, M., & Flamant, C. (2023). Heat wave monitoring over West African cities: uncertainties, characterization and recent trends. Natural Hazards and Earth System Sciences, 23(4), 1313-1333."
  },
  {
    "objectID": "pages/heatwaveR_publ.html#sec-policy",
    "href": "pages/heatwaveR_publ.html#sec-policy",
    "title": "Notable heatwaveR citations",
    "section": "Support of policy development around the management of marine living resources",
    "text": "Support of policy development around the management of marine living resources\n\nBuenafe, K. C. V., Dunn, D. C., Everett, J. D., Brito-Morales, I., Schoeman, D. S., Hanson, J. O., … & Richardson, A. J. (2022). A climate-smart spatial planning framework.\nWegscheider, B., Linnansaari, T., Monk, W., Ndong, M., Haralampides, K., St-Hilaire, A., … & Allen, R. (2020). Quantitative modelling of fish habitat under future regulated and hydro-climatically driven flow regimes in the Saint John River (New Brunswick, Canada). Quantitative modelling of existing and future fish habitat in the Saint John River, NB, Canada, 184.\nBuenafe, K. C. V., Dunn, D. C., Everett, J. D., Brito-Morales, I., Schoeman, D. S., Hanson, J. O., … & Richardson, A. J. (2023). A metric-based framework for climate-smart conservation planning. Ecological Applications, e2852.\nMuñoz-Pizza, D. M., Sanchez-Rodriguez, R. A., & Manzano, E. G. Linking Climate Change to Urban Planning Through Vulnerability Assessment: The Case of Two Cities at the Mexico-Us Border. Available at SSRN 4348277."
  },
  {
    "objectID": "pages/heatwaveR_publ.html#sec-novel",
    "href": "pages/heatwaveR_publ.html#sec-novel",
    "title": "Notable heatwaveR citations",
    "section": "Novel research questions and hypotheses",
    "text": "Novel research questions and hypotheses\n\nLeach, T. S., BuyanUrt, B., & Hofmann, G. E. (2021). Exploring impacts of marine heatwaves: paternal heat exposure diminishes fertilization success in the purple sea urchin (Strongylocentrotus purpuratus). Marine Biology, 168(7), 103.\nPegado, M. R., Santos, C. P., Raffoul, D., Konieczna, M., Sampaio, E., Maulvault, A. L., … & Rosa, R. (2020). Impact of a simulated marine heatwave in the hematological profile of a temperate shark (Scyliorhinus canicula). Ecological Indicators, 114, 106327.\nKraufvelin, L. (2021). Identification of marine heatwaves in the Archipelago Sea and experimental testing of their impacts on the non-indigenous Harris mud crab.\nOliveira, H., Maulvault, A. L., Santos, C. P., Silva, M., Bandarra, N. M., Valente, L. M., … & Anacleto, P. (2023). Can marine heatwaves affect the fatty acid composition and energy budget of the tropical fish Zebrasoma scopas?. Environmental Research, 224, 115504.\nLeach, T. S. (2022). The Role of Pre-and Post-Spawning Temperature Stress on Fertilization Dynamics Within Santa Barbara Channel Sea Urchin Species. University of California, Santa Barbara.\nMinuti, J. J., Byrne, M., Hemraj, D. A., & Russell, B. D. (2021). Capacity of an ecologically key urchin to recover from extreme events: Physiological impacts of heatwaves and the road to recovery. Science of the Total Environment, 785, 147281.\nClare, X. S., Kui, L., & Hofmann, G. E. (2022). Larval Thermal Tolerance of Kellet’s Whelk (Kelletia kelletii) as a Window into the Resilience of a Wild Shellfishery to Marine Heatwaves. Journal of Shellfish Research, 41(2), 283-290.\nMarochi, M. Z., De Grande, F. R., Pardo, J. C. F., Montenegro, Á., & Costa, T. M. (2022). Marine heatwave impacts on newly-hatched planktonic larvae of an estuarine crab. Estuarine, Coastal and Shelf Science, 278, 108122.\nVan Der Walt, K. A., Potts, W. M., Porri, F., Winkler, A. C., Duncan, M. I., Skeeles, M. R., & James, N. C. (2021). Marine Heatwaves Exceed Cardiac Thermal Limits of Adult Sparid Fish (Diplodus capensis, Smith 1884). Frontiers in Marine Science, 8, 702463."
  },
  {
    "objectID": "pages/heatwaveR_publ.html#sec-trackers",
    "href": "pages/heatwaveR_publ.html#sec-trackers",
    "title": "Notable heatwaveR citations",
    "section": "Online trackers of marine heatwaves",
    "text": "Online trackers of marine heatwaves\n\nThe original marine heatwave tracker\nThe Physical Sciences Laboratory heatwave website\nWhaleMap"
  },
  {
    "objectID": "pages/NRF_ratings.html",
    "href": "pages/NRF_ratings.html",
    "title": "NRF Rating: thoughts",
    "section": "",
    "text": "The South African National Research Foundation (NRF) rating system claims to evaluate and benchmark the research performance of individual researchers in the country. The system’s purpose is intended to:\n\nRecognise and reward research excellence The system acknowledges researchers who produce high-quality research and contribute significantly to their respective fields. A favourable rating is supposed to increase recognition, both nationally and internationally, as well as improve funding opportunities.\nEncourage research productivity By providing incentives and recognition for high-quality research, the NRF rating system aims to promote academic productivity and encourages continuous advancement.\nEnhance research capacity It supposedly identifies academics with solid potential and supports the development of research capacity in South Africa by providing funding and other resources to rated researchers.\nFacilitate collaboration The NRF rating system claims to facilitate scientific cooperation by enabling researchers, institutions, and funding agencies to identify potential partners based on their research expertise and performance.\nPromote international competitiveness The NRF suggests that a robust research evaluation system helps to ensure that South African researchers remain competitive on the global stage, which is essential for attracting international funding, partnerships, and talent.\nInform decision-making NRF ratings inform institutional, national, and international decision-making regarding research priorities, funding allocations, and strategic planning, ensuring that resources are directed towards high-impact research.\n\nThere are alternatives to the NRF rating system. The H-index is a globally recognised rapid assessment of research impact, of which Google offers one implementation on their Google Scholar system. This H-index is consistently applied to researchers from any country or any academic discipline. The metric is based on citation data and provides a more objective and quantitative measure of research impact. Since the H-index is easily accessible and hassle-free, it is calculated on the fly using various citation databases, such as Google Scholar. This last point contrasts starkly with the NRF rating system, which is lengthy, and requires significant effort and time from both the applicants and reviewers.\nFurther comparisons of the NRF rating system to a metric such as Google Scholar’s H-index reveal other possible advantages. The NRF’s approach is a more integrated and robust assessment of research ‘prowess’ as the system considers multiple aspects of academic contributions. This includes not only the quality, impact, and significance of research output (similar to the H-index, but differ in how these are assessed) but also a broader contribution to academics’ research fields using assessments that are not based on publications, such as participation in various international bodies, panels and working groups. This integrated assessment leads to a more nuanced evaluation of academic performance that citation metrics, such as the H-index, cannot capture. It also acknowledges academics for their role in developing research capacity, which in South Africa is a critical role that all academics must play.\nNRF ratings are determined through a rigorous peer-review process, which claims to ensure that the evaluations are fair and unbiased. However, despite the peer-review process, personal biases or conflicts of interest may still influence the ratings, and the system could be more objective. The system is also specific to South Africa, and the recognition that might stem from one’s NRF rating does not favour one as much as one would wish to think. This is true especially once international research funding becomes attractive and one is willing to enter more comprehensive international research consortia.\nIn the past, rated researchers were offered incentive funding. This system no longer exists, at least not in the format it was implemented in the early- to mid-2010s. Note, the ‘Competitive Support for Unrated Researchers (CSUR) - 2024 Funding Framework’ and ‘Competitive Programme for Rated Researchers (CPRR) – 2024 Funding Framework’ do take rating into account, but others, such as the ‘African Coelacanth Ecosystem Programme (ACEP) – South African Marine and Antarctic Research Strategy,’ do not. Similarly, international funders, where I will focus my attention in the future, also do not acknowledge NRF ratings.\nWhether or not one maintains an NRF rating depends on personal research values. This should be decided on personal conviction and not dictated by the institution within which one is employed. I have yet to experience the NRF rating system to offer me any tangible advantage regarding recognition of research excellence, encouragement of productivity, enhancement of capacity, the facilitation of collaboration, or enhanced international competitiveness. The only benefit resulting from NRF ratings goes to the employers to inform institutional decision-making.\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{j._smit2023,\n  author = {J. Smit, Albertus},\n  title = {NRF {Rating:} Thoughts},\n  date = {2023-04-24},\n  url = {http://tangledbank.netlify.app/pages/NRF_ratings.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A (2023) NRF Rating: thoughts. http://tangledbank.netlify.app/pages/NRF_ratings.html."
  },
  {
    "objectID": "pages/kaggle_earthquakes.html",
    "href": "pages/kaggle_earthquakes.html",
    "title": "Kaggle Earthquake database",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggthemes)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthhires)\n\nHere’s a map of earthquake location and magnitude (&gt;=5.5) from 1965-2016. The data may be found on Kaggle.\n\nWGS84_proj &lt;- \"+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\"\nNE_proj &lt;- \"+proj=natearth +lon_0=170\"\n\n\nquakes &lt;- read_csv(\"../data/kaggle_earthquakes_database.csv\",\n  skip = 3, col_types = cols(Date = col_date(format = \"%d/%m/%Y\")))\nquakes_sf &lt;- quakes |&gt; \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"),\n    crs = WGS84_proj)\nquakes_sf_trans &lt;- st_transform(quakes_sf, NE_proj)\nhead(quakes_sf)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDate\nTime\nType\nDepth\nDepth Error\nDepth Seismic Stations\nMagnitude\nMagnitude Type\nMagnitude Error\nMagnitude Seismic Stations\nAzimuthal Gap\nHorizontal Distance\nHorizontal Error\nRoot Mean Square\nID\nSource\nLocation Source\nMagnitude Source\nStatus\ngeometry\n\n\n\n1965-02-01\n13:44:18\nEarthquake\n131.6\nNA\nNA\n6.0\nMW\nNA\nNA\nNA\nNA\nNA\nNA\nISCGEM860706\nISCGEM\nISCGEM\nISCGEM\nAutomatic\nPOINT (145.616 19.246)\n\n\n1965-04-01\n11:29:49\nEarthquake\n80.0\nNA\nNA\n5.8\nMW\nNA\nNA\nNA\nNA\nNA\nNA\nISCGEM860737\nISCGEM\nISCGEM\nISCGEM\nAutomatic\nPOINT (127.352 1.863)\n\n\n1965-05-01\n18:05:58\nEarthquake\n20.0\nNA\nNA\n6.2\nMW\nNA\nNA\nNA\nNA\nNA\nNA\nISCGEM860762\nISCGEM\nISCGEM\nISCGEM\nAutomatic\nPOINT (-173.972 -20.579)\n\n\n1965-08-01\n18:49:43\nEarthquake\n15.0\nNA\nNA\n5.8\nMW\nNA\nNA\nNA\nNA\nNA\nNA\nISCGEM860856\nISCGEM\nISCGEM\nISCGEM\nAutomatic\nPOINT (-23.557 -59.076)\n\n\n1965-09-01\n13:32:50\nEarthquake\n15.0\nNA\nNA\n5.8\nMW\nNA\nNA\nNA\nNA\nNA\nNA\nISCGEM860890\nISCGEM\nISCGEM\nISCGEM\nAutomatic\nPOINT (126.427 11.938)\n\n\n1965-10-01\n13:36:32\nEarthquake\n35.0\nNA\nNA\n6.7\nMW\nNA\nNA\nNA\nNA\nNA\nNA\nISCGEM860922\nISCGEM\nISCGEM\nISCGEM\nAutomatic\nPOINT (166.629 -13.405)\n\n\n\n\n\n\n\nplot(quakes_sf[,\"Magnitude\"])\n\n\n\n\n\n\n\n\nworld_1 &lt;- ne_countries(returnclass = 'sf',\n  scale = 10, type = \"countries\") |&gt; \n  select(continent, sovereignt, iso_a3) |&gt; \n  st_break_antimeridian(lon_0 = 170) |&gt; \n  st_transform(NE_proj)\n\n\nggplot() +\n  geom_sf(data = world_1, colour = \"grey60\", fill = \"grey70\") +\n  geom_sf(data = quakes_sf_trans, aes(colour = Magnitude, size = Magnitude),\n    stat = \"sf_coordinates\",\n    shape = \"*\", alpha = 0.4) +\n  scale_colour_viridis_c(option = \"mako\", direction = 1) +\n  guides(size = \"none\",\n    colour = guide_colourbar(title = \"Magnitude\",\n      title.position = \"left\")) +\n  coord_sf(expand = FALSE) +\n  labs(x = NULL, y = NULL,\n    title = \"The Kaggle Earthquake Data\",\n    subtitle = \"Significant Earthquakes, 1965-2016\") +\n  theme_minimal() +\n  theme(\n    panel.grid.major = element_line(colour = \"grey90\"),\n    legend.background = element_blank(),\n    legend.title = element_text(angle = 90),\n    legend.title.align = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{j._smit,\n  author = {J. Smit, Albertus and Smit, AJ},\n  title = {Kaggle {Earthquake} Database},\n  url = {http://tangledbank.netlify.app/pages/kaggle_earthquakes.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A, Smit A Kaggle Earthquake database. http://tangledbank.netlify.app/pages/kaggle_earthquakes.html."
  },
  {
    "objectID": "pages/promotion_index.html",
    "href": "pages/promotion_index.html",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "",
    "text": "About the square bracket `[]` notation\n\n\n\nA list of the links provided in my Case for Promotion document is provided here. The numbers in square brackets ‘[]’ refer to the footnote in the Case for Promotion document."
  },
  {
    "objectID": "pages/promotion_index.html#develop-level-3-module-bdc334-and-bsc-hons-modules-bcb744-and-bcb743-for-the-bcb-department",
    "href": "pages/promotion_index.html#develop-level-3-module-bdc334-and-bsc-hons-modules-bcb744-and-bcb743-for-the-bcb-department",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.1.1. Develop Level-3 module BDC334, and BSc (Hons) modules BCB744 and BCB743 for the BCB Department",
    "text": "4.1.1. Develop Level-3 module BDC334, and BSc (Hons) modules BCB744 and BCB743 for the BCB Department\n[5] I was instrumental in developing South Africa’s first undergraduate Marine Biology curriculum at the University of KwaZulu-Natal in 2007 (with Profs. Perissinotto and Schoeman)\n[6] See a discussion about how I allow modern technologies to influence and shape my teaching\n[7] Views on collaborative learning\n[8] Example exercises and bonus, designed to reward and incentivise continued learning towards advanced skills\n[9] Assessment policy for BCB744\n[10] Explanation of modes of assessment\n[11] Module-specific graduate attributes\n[12] The difference between science and data science\n[13] Thoughts about the learning process\n[14] Access to old test and exam questions"
  },
  {
    "objectID": "pages/promotion_index.html#develop-the-tangled-bank-website-in-support-of-undergraduate-and-bsc-hons-modules",
    "href": "pages/promotion_index.html#develop-the-tangled-bank-website-in-support-of-undergraduate-and-bsc-hons-modules",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.1.2. Develop the Tangled Bank website in support of undergraduate and BSc (Hons) modules",
    "text": "4.1.2. Develop the Tangled Bank website in support of undergraduate and BSc (Hons) modules\n[15] For an example of information rich text, see the example page\n[16] See the ‘vignettes’ menu at the top of The Tangled Bank.\n[17] For example, the FAQ page for BDC223\n[18] See feedback from colleagues about The Tangled Bank"
  },
  {
    "objectID": "pages/promotion_index.html#feedback-from-external-peer-reviewers-and-students-about-above-modules-taught",
    "href": "pages/promotion_index.html#feedback-from-external-peer-reviewers-and-students-about-above-modules-taught",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.1.3. Feedback from external (peer) reviewers and students about above modules taught",
    "text": "4.1.3. Feedback from external (peer) reviewers and students about above modules taught\n[19] Prof. Sophie von der Heyden’s feedback about BCB743 in 2022\n[20] Prof. Sophie von der Heyden’s feedback about BCB744 in 2022\n[21] BCB744 assessment policy\n[22] BCB743 assessment policy\n[23] BDC334 assessment policy\n[24] Student feedback about BDC223, BDC334, BCB744, and BCB743 are available at the links below:\n\nBDC223\nBDC334\nBCB744\nBCB743"
  },
  {
    "objectID": "pages/promotion_index.html#tangled-bank-vignettes-and-reproducible-research",
    "href": "pages/promotion_index.html#tangled-bank-vignettes-and-reproducible-research",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.1.4. Tangled Bank vignettes and reproducible research",
    "text": "4.1.4. Tangled Bank vignettes and reproducible research\n[25] See my essay on eResearch and reproducible research\n[26] Dr Robert Schlegel’s GitHub page\n[27] Ms Amieroh Abrahams’s GitHub page\n[28] Mr Ross Coppin’s GitHub page\n[29] Examples of vignettes may be access at The Tangled Bank under the ‘vignettes’ menu at the top. For example:\n\nRetrieving Chlorophyll-a Data from ERDDAP Servers\nWavelet analysis of diatom time series\nEvent horizon plots\n\nOther vignettes are at the heatwaveR website in the vignettes top menu."
  },
  {
    "objectID": "pages/promotion_index.html#successful-and-prolific-funding-attraction",
    "href": "pages/promotion_index.html#successful-and-prolific-funding-attraction",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.2.1. Successful and prolific funding attraction",
    "text": "4.2.1. Successful and prolific funding attraction\n[30] List of the more recent research funding received:\n\n2020 – 2022: Belmont Forum Collaborative Research Action on Transdisciplinary Research for Ocean Sustainability: Ecological and Economic impacts of the intensification of extreme events in the Benguela Upwelling System, Principal Investigator (EXEBUS) PDF\n2019 – 2021: SANOCEAN: Factors influencing the formation, fate and transport of microplastic in marine coastal ecosystems (FORTRAN) PDF\n2019 – 2021: SANOCEAN: Blue growth opportunities in changing kelp forests (BlueConnect) PDF\n2019 – 2023: Horizon 2020: iAtlantic, led by Prof. Murray Robert, own capacity as Regional Coordinator for the SE Atlantic PDF\n\n[31] List of older nationally funded research\n\n2019 – 2021: NRF Global Change Grand Challenge: Earth System Science Research Programme — Extreme Climatic Events in the Coastal Zone, Principal Investigator (ESS180920360856) PDF\nNRF GRANT for 2018 – 2020: Competitive Programme for Rated Researchers —Upwelling dynamics in kelp beds: implications for trophic function PDF\n2017: CHEC/CCT Joint Research Programme 2017: What can kelp loss processes and beach cast patterns tell us about the sandy beach management? PDF\n2015 – 2017: NRF COMPETITIVE PROGRAMME FOR RATED RESEARCHERS (CPRR) — Thermal characteristics of the South African nearshore: implications for biodiversity PDF\n2014 – 2016: NRF COMPETITIVE PROGRAMME FOR RATED RESEARCHERS (CPRR) — Kelps and climate change: South Africa in a global context PDF\n2014 – 2016: NRF GRANT FOR 2014: INCENTIVE FUNDING FOR RATED RESEARCHERS (IPRR) Grant No. IFR14020764026 PDF\n\n[32] My thoughts about the NRF rating system and maintaining my own rating"
  },
  {
    "objectID": "pages/promotion_index.html#development-of-r-packages-in-marine-heatwave-analysis",
    "href": "pages/promotion_index.html#development-of-r-packages-in-marine-heatwave-analysis",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.2.2. Development of R packages in marine heatwave analysis",
    "text": "4.2.2. Development of R packages in marine heatwave analysis\n[33] The RmarineHeatWaves documentation.\n[34] heatwaveR. Also see the GitHub page.\n[35] This number is hard to track, but a search in Google Scholar for the term “heatwaveR” (inverted commas included) yields at least 150 citations. A shorter list of the citations is provided at https://robwschlegel.github.io/heatwaveR/CITATIONS.html. Notable examples of high-impact publications are provided here:\n\nSmale, D. A., Wernberg, T., Oliver, E. C., Thomsen, M., Harvey, B. P., Straub, S. C., … & Moore, P. J. (2019). Marine heatwaves threaten global biodiversity and the provision of ecosystem services. Nature Climate Change, 9(4), 306-312.\nBarkhordarian, A., Nielsen, D. M., & Baehr, J. (2022). Recent marine heatwaves in the North Pacific warming pool can be attributed to rising atmospheric levels of greenhouse gases. Communications Earth & Environment, 3(1), 131.\nThoral, F., Montie, S., Thomsen, M. S., Tait, L. W., Pinkerton, M. H., & Schiel, D. R. (2022). Unravelling seasonal trends in coastal marine heatwave metrics across global biogeographical realms. Scientific Reports, 12(1), 7740.\nBenedetti-Cecchi, L. (2021). Complex networks of marine heatwaves reveal abrupt transitions in the global ocean. Scientific Reports, 11(1), 1739.\nWoolway, R. I., Jennings, E., Shatwell, T., Golub, M., Pierson, D. C., & Maberly, S. C. (2021). Lake heatwaves under climate change. Nature, 589(7842), 402-407.\nGarcía Molinos, J., Hunt, H. L., Green, M. E., Champion, C., Hartog, J. R., & Pecl, G. T. (2022). Climate, currents and species traits contribute to early stages of marine species redistribution. Communications biology, 5(1), 1329.\nSmith, K. E., Burrows, M. T., Hobday, A. J., Sen Gupta, A., Moore, P. J., Thomsen, M., … & Smale, D. A. (2021). Socioeconomic impacts of marine heatwaves: Global issues and opportunities. Science, 374(6566), eabj3593.\n\n[36] Examples of cross-discipline research in marine heatwaves promoted by the heatwaveR package are provided here:\n\nSchlegel, R. W., Oliver, E. C., & Chen, K. (2021). Drivers of marine heatwaves in the Northwest Atlantic: The role of air–sea interaction during onset and decline. Frontiers in Marine Science, 8, 627970.\nHu, L. (2021). A global assessment of coastal marine heatwaves and their relation with coastal urban thermal changes. Geophysical Research Letters, 48(9), e2021GL093260.\nBarkhordarian, A., Nielsen, D. M., & Baehr, J. (2022). Greenhouse Gas Forcing a Necessary Causation for Marine Heatwaves Over the Northeast Pacific Warming Pool.\n\n[37] Evidence of the application of the heatwaveR package outside of the initially intended field of application, marine science\n\nTassone, S. J., Besterman, A. F., Buelo, C. D., Ha, D. T., Walter, J. A., & Pace, M. L. (2023). Increasing heatwave frequency in streams and rivers of the United States. Limnology and Oceanography Letters, 8(2), 295-304.\nDiniz, F. R., Gonçalves, F. L. T., & Sheridan, S. (2020). Heat wave and elderly mortality: Historical analysis and future projection for metropolitan region of São Paulo, Brazil. Atmosphere, 11(9), 933.\nWoolway, R. I., Albergel, C., Frölicher, T. L., & Perroud, M. (2022). Severe Lake Heatwaves Attributable to Human‐Induced Global Warming. Geophysical Research Letters, 49(4), e2021GL097031.\nReynaert, S., De Boeck, H. J., Verbruggen, E., Verlinden, M., Flowers, N., & Nijs, I. (2021). Risk of short‐term biodiversity loss under more persistent precipitation regimes. Global Change Biology, 27(8), 1614-1626.\nWoolway, R. I., Anderson, E. J., & Albergel, C. (2021). Rapidly expanding lake heatwaves under climate change. Environmental Research Letters, 16(9), 094013.\nPaton, E. (2022). Intermittency analysis of dry spell magnitude and timing using different spell definitions. Journal of Hydrology, 608, 127645.\nMartinez-Baroja, L., Rey-Benayas, J. M., Perez-Camacho, L., & Villar-Salvador, P. (2022). Drivers of oak establishment in Mediterranean old fields from 25-year-old woodland islets planted to assist natural regeneration. European Journal of Forest Research, 141(1), 17-30.\nPappert, D., Barriendos, M., Brugnara, Y., Imfeld, N., Jourdain, S., Przybylak, R., … & Brönnimann, S. (2022). Statistical reconstruction of daily temperature and sea level pressure in Europe for the severe winter 1788/89. Climate of the Past, 18(12), 2545-2565.\nNgoungue Langue, C. G., Lavaysse, C., Vrac, M., & Flamant, C. (2023). Heat wave monitoring over West African cities: uncertainties, characterization and recent trends. Natural Hazards and Earth System Sciences, 23(4), 1313-1333.\n\n[38] For studies that have used metrics calculated by heatwaveR in support of policy development around the management of marine living resources, see this list\n\nBuenafe, K. C. V., Dunn, D. C., Everett, J. D., Brito-Morales, I., Schoeman, D. S., Hanson, J. O., … & Richardson, A. J. (2022). A climate-smart spatial planning framework.\nWegscheider, B., Linnansaari, T., Monk, W., Ndong, M., Haralampides, K., St-Hilaire, A., … & Allen, R. (2020). Quantitative modelling of fish habitat under future regulated and hydro-climatically driven flow regimes in the Saint John River (New Brunswick, Canada). Quantitative modelling of existing and future fish habitat in the Saint John River, NB, Canada, 184.\nBuenafe, K. C. V., Dunn, D. C., Everett, J. D., Brito-Morales, I., Schoeman, D. S., Hanson, J. O., … & Richardson, A. J. (2023). A metric-based framework for climate-smart conservation planning. Ecological Applications, e2852.\nMuñoz-Pizza, D. M., Sanchez-Rodriguez, R. A., & Manzano, E. G. Linking Climate Change to Urban Planning Through Vulnerability Assessment: The Case of Two Cities at the Mexico-Us Border. Available at SSRN 4348277.\n\n[39] Evidence of examples where such novel research questions and hypotheses have been addressed\n\nLeach, T. S., BuyanUrt, B., & Hofmann, G. E. (2021). Exploring impacts of marine heatwaves: paternal heat exposure diminishes fertilization success in the purple sea urchin (Strongylocentrotus purpuratus). Marine Biology, 168(7), 103.\nPegado, M. R., Santos, C. P., Raffoul, D., Konieczna, M., Sampaio, E., Maulvault, A. L., … & Rosa, R. (2020). Impact of a simulated marine heatwave in the hematological profile of a temperate shark (Scyliorhinus canicula). Ecological Indicators, 114, 106327.\nKraufvelin, L. (2021). Identification of marine heatwaves in the Archipelago Sea and experimental testing of their impacts on the non-indigenous Harris mud crab.\nOliveira, H., Maulvault, A. L., Santos, C. P., Silva, M., Bandarra, N. M., Valente, L. M., … & Anacleto, P. (2023). Can marine heatwaves affect the fatty acid composition and energy budget of the tropical fish Zebrasoma scopas?. Environmental Research, 224, 115504.\nLeach, T. S. (2022). The Role of Pre-and Post-Spawning Temperature Stress on Fertilization Dynamics Within Santa Barbara Channel Sea Urchin Species. University of California, Santa Barbara.\nMinuti, J. J., Byrne, M., Hemraj, D. A., & Russell, B. D. (2021). Capacity of an ecologically key urchin to recover from extreme events: Physiological impacts of heatwaves and the road to recovery. Science of the Total Environment, 785, 147281.\nClare, X. S., Kui, L., & Hofmann, G. E. (2022). Larval Thermal Tolerance of Kellet’s Whelk (Kelletia kelletii) as a Window into the Resilience of a Wild Shellfishery to Marine Heatwaves. Journal of Shellfish Research, 41(2), 283-290.\nMarochi, M. Z., De Grande, F. R., Pardo, J. C. F., Montenegro, Á., & Costa, T. M. (2022). Marine heatwave impacts on newly-hatched planktonic larvae of an estuarine crab. Estuarine, Coastal and Shelf Science, 278, 108122.\nVan Der Walt, K. A., Potts, W. M., Porri, F., Winkler, A. C., Duncan, M. I., Skeeles, M. R., & James, N. C. (2021). Marine Heatwaves Exceed Cardiac Thermal Limits of Adult Sparid Fish (Diplodus capensis, Smith 1884). Frontiers in Marine Science, 8, 702463.\n\n[40] Various online trackers of marine heatwaves use heatwaveR as the underlying processing engine, some of which are reported on my ePortfolio\n\nThe original marine heatwave tracker\nThe Physical Sciences Laboratory heatwave website\nWhaleMap"
  },
  {
    "objectID": "pages/promotion_index.html#student-supervision",
    "href": "pages/promotion_index.html#student-supervision",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.2.3. Student supervision",
    "text": "4.2.3. Student supervision\n[41] Extract from the NRFOnline system listing most of my post-graduate students"
  },
  {
    "objectID": "pages/promotion_index.html#the-south-african-coastal-seawater-temperature-network-sactn",
    "href": "pages/promotion_index.html#the-south-african-coastal-seawater-temperature-network-sactn",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.2.4. The South African Coastal Seawater Temperature Network (SACTN)",
    "text": "4.2.4. The South African Coastal Seawater Temperature Network (SACTN)\n[42] The The South African Coastal Seawater Temperature Network (SACTN) GitHub page from where data can be downloaded\n[43] Smit, A. J., Roberts, M., Anderson, R. J., Dufois, F., Dudley, S. F., Bornman, T. G., … & Bolton, J. J. (2013). A coastal seawater temperature dataset for biogeographical studies: large biases between in situ and remotely-sensed data sets around the coast of South Africa. PLoS One, 8(12), e81944.\n[44] A few personal well-cited publications that cite the SACTN:\n\nSchlegel, R. W., Oliver, E. C., Wernberg, T., & Smit, A. J. (2017). Nearshore and offshore co-occurrence of marine heatwaves and cold-spells. Progress in Oceanography, 151, 189-205.\nSchlegel, R. W., Oliver, E. C., Perkins-Kirkpatrick, S., Kruger, A., & Smit, A. J. (2017). Predominant atmospheric and oceanic patterns during coastal marine heatwaves. Frontiers in Marine Science, 4, 323."
  },
  {
    "objectID": "pages/promotion_index.html#editorial-contributions",
    "href": "pages/promotion_index.html#editorial-contributions",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.2.5. Editorial contributions",
    "text": "4.2.5. Editorial contributions\n[45] Associate Editor for Aquatic Botany\n[46] My Reviewer’s profile on Loop for editorial contributions to Frontiers in Ecology & Evolution"
  },
  {
    "objectID": "pages/promotion_index.html#committees-and-programmes",
    "href": "pages/promotion_index.html#committees-and-programmes",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.2.6. Committees and programmes",
    "text": "4.2.6. Committees and programmes"
  },
  {
    "objectID": "pages/promotion_index.html#academic-lead-kelp-scientific-collaboration-ppp",
    "href": "pages/promotion_index.html#academic-lead-kelp-scientific-collaboration-ppp",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.3.1. Academic Lead, Kelp Scientific Collaboration PPP",
    "text": "4.3.1. Academic Lead, Kelp Scientific Collaboration PPP\n[47] Kelp Scientific Collaboration mission statement"
  },
  {
    "objectID": "pages/promotion_index.html#a-research-project-funded-by-sanocean-blueconnect-about-the-perceived-value-of-south-african-kelp",
    "href": "pages/promotion_index.html#a-research-project-funded-by-sanocean-blueconnect-about-the-perceived-value-of-south-african-kelp",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.3.2. A research project, funded by SANOCEAN BlueConnect, about the perceived value of South African kelp",
    "text": "4.3.2. A research project, funded by SANOCEAN BlueConnect, about the perceived value of South African kelp\n[48] Perceived Value of Kelp\n[49] Kelp, South Africa’s Golden Forests on YouTube\n[50] Akshata Mehta’s MPhil thesis"
  },
  {
    "objectID": "pages/promotion_index.html#blueconnect-engagements",
    "href": "pages/promotion_index.html#blueconnect-engagements",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.3.3. BlueConnect engagements",
    "text": "4.3.3. BlueConnect engagements\n[51] Invitation letter to the GEAK workshop held in Norway\n[52] BlueConnect March 2020 Field Course"
  },
  {
    "objectID": "pages/promotion_index.html#other-community-engagements-and-capacity-building-contributions",
    "href": "pages/promotion_index.html#other-community-engagements-and-capacity-building-contributions",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.3.4. Other community engagements and capacity-building contributions",
    "text": "4.3.4. Other community engagements and capacity-building contributions\n[53] See most recent invitation to participate in a capacity building initiative\n[54] Invitation quarterly Kogelberg Marine Working Group meeting"
  },
  {
    "objectID": "pages/promotion_index.html#covid-19-environmental-research-group",
    "href": "pages/promotion_index.html#covid-19-environmental-research-group",
    "title": "Ad Personam Promotion 2023: e-Portfolio",
    "section": "4.3.5. CoVID-19 Environmental Research Group",
    "text": "4.3.5. CoVID-19 Environmental Research Group\n[55] Smit et al (2020) about CoVID-19"
  },
  {
    "objectID": "pages/Transboundary_systems.html",
    "href": "pages/Transboundary_systems.html",
    "title": "Transboundary systems",
    "section": "",
    "text": "Transboundary systems\nTransboundary systems refer to ecosystems that span the boundaries of more than one country or jurisdiction. These can include a variety of natural resources like water bodies (rivers, lakes, aquifers), marine ecosystems, forests, wildlife habitats, and mountain ranges, among others.\nTransboundary systems pose unique challenges and opportunities for management and conservation due to their shared nature. They require cooperative management strategies, often necessitating bilateral or multilateral agreements between the countries involved. This alliance ensures the sustainable use of the shared resource, while also managing any potential conflicts that may arise due to differing national interests.\nA transboundary river system, for example, may originate in one country, flow through another, and finally discharge into the ocean in a third country. Each country might have differing needs and priorities for the river’s use—for drinking water, irrigation, hydroelectric power, etc. Coordinated management is crucial to ensure the river’s health and equitable use.\n\n\nLarge marine ecosystems\nLarge Marine Ecosystems (LMEs) are regions of the world’s oceans, encompassing coastal areas from river basins and estuaries to the seaward boundaries of continental shelves and the outer margins of the major current systems. They are characterised by their vast size—typically they are over 200,000 square kilometers—and their distinctive bathymetry,1 hydrography,2 productivity,3 and trophically dependent populations.4\n1 The underwater topography, including features like continental shelves, deep sea trenches, and seamounts.2 The physical and chemical characteristics of the water, including temperature, salinity, currents, and nutrient levels.3 The biological productivity of the area, including both primary producers like phytoplankton and the various levels of consumers in the food web.4 These are groups of species that are interconnected in the food web, including predators, prey, and competitors.The concept of LMEs was developed in the 1980s by Dr. Ken Sherman of the US National Oceanic and Atmospheric Administration (NOAA) in response to the growing need for a comprehensive, ecosystem-based approach to manage and conserve coastal and marine resources. This approach recognises that marine resources are interconnected and that effective management must consider the entire ecosystem rather than individual species or issues in isolation. As such, the LME approach was intended to bridge the gap between single-species management and broader ecosystem-based management.\nThere are 66 recognised LMEs globally, seven of which are around the African continent (Sweijd and Smit 2020), including the Benguela Current LME off South Africa, Namibia, and Angola. Each LME is unique and requires a tailored management approach, but the overarching goal is the same: to ensure the long-term sustainability and health of the world’s coastal and marine ecosystems.\n\n\nThe Benguela Current Large Marine Ecosystem\nThe LME classification system, established in the 1980s, represents a giant stride in acknowledging and managing contiguous, transboundary marine ecosystems. Among the 66 LMEs identified worldwide, the Benguela Current LME (BCLME) stands out as a pivotal Eastern Boundary Upwelling System (EBUS), a category shared only by the Humboldt Current LME, the California LME, and the Canary Current.\nThe BCLME is comprised of the southern, central northern, and northern Benguela subsystems. This marine region extends from the shoreline at the high-water mark to the countries’ Exclusive Economic Zones (EEZs). From the Cape of Good Hope, its southern and eastern border seasonally stretches as far as 27°E longitude, near Gqeberha. Northward, the boundary reaches to 5°S near Nimibe in Angola, aligning with the southern edge of the Guinea Current Large Marine Ecosystem (GCLME). This boundary definition is fundamental to the sustainable management and conservation of the BCLME, thereby fortifying the environmental, economic, and social resilience of the region.\nThe BCLME is part of a mere 3% of the world’s sea surface occupied by the four EBUS but yields nearly 40% of the global annual marine fish catch. LMEs worldwide, though only accounting for a fraction of the ocean’s surface, contribute an impressive 80% to this vital food resource.\nYet the significance of BCLME transcends its remarkable productivity. It serves as a crucial climate regulator, with its abundant biomass acting as a significant carbon sink, mitigating the effects of climate change. This critical role underscores the BCLME’s global significance, as it helps maintain our planet’s delicate climatic balance.\nThe BCLME is also a reservoir of marine biodiversity that enriches our world ecologically and economically, and the upwelling of cool, nutrient-rich water is reasoned to act as a haven for species that might be prone to ocean warming. However, like many of Earth’s natural ecosystems, the BCLME is under severe stress. It faces challenges from overfishing, pollution, and climate change impacts, leading to biodiversity loss and habitat degradation. Consequences for the people making a living from the system are already emerging.\nIn light of these challenges, the conservation and sustainable management of the BCLME is not just a regional concern—it is a global imperative and a human right. The BCLME’s importance as a climate regulator, biodiversity reservoir, and primary productivity centre demands immediate attention and action. Investing in the health of this ecosystem is, in essence, investing in the future of our planet.\nThe commitment to ensuring a sustainable future of the BCLME is embodied in a tripartite alliance between Angola, Namibia, and South Africa, the parties to the Benguela Current Convention. This boundary demarcation facilitates the deployment of a practical ecosystem management framework for this transboundary ecosystem.\n\n\nManaging transboundary marine ecosystems\nManaging transboundary marine ecosystems is complex due to the multitude of stakeholders and jurisdictions involved, as well as the inherent dynamism and complexity of marine ecosystems. However, several strategies have been identified as effective:\n\nEcosystem-Based Management (EBM): This approach aims to balance ecological, social, and economic goals in managing marine resources. It takes into account the entire ecosystem, including human activities, rather than focusing on one species or resource at a time.\nMarine Spatial Planning (MSP): MSP is a practical way to create and establish a more rational use of marine space to benefit economic, social and environmental objectives. It involves allocating and managing parts of the ocean to specific uses or activities, in a way that minimises conflict and maximises compatibility among different activities.\nCooperative Management and Governance: Transboundary ecosystems require cooperation between all nations whose waters are part of the ecosystem. This can be achieved through international treaties, conventions, or other agreements. An example of this is the Benguela Current Convention between Angola, Namibia, and South Africa.\nScience-Based Decision Making: Regular monitoring and research are crucial to understand the state of the ecosystem and the impacts of human activities. This information should be used to inform management decisions and adaptive strategies.\nStakeholder Engagement: All relevant stakeholders, including governments, industry, indigenous communities, and the public, should be involved in decision-making processes. This ensures a diversity of perspectives and promotes equitable outcomes.\nAdaptive Management: Given the dynamic nature of marine ecosystems, management strategies need to be flexible and responsive to change. This involves regular monitoring, periodic evaluations, and adjustments to management plans as needed.\nIntegrated Coastal Management (ICM): This is a process for governance and management of coastal areas. ICM aims to balance the different objectives of society - economic development, coastal livelihoods, and environmental conservation.\nPrecautionary Approach: In situations of scientific uncertainty, the precautionary approach advocates for erring on the side of caution to prevent serious or irreversible damage to the ecosystem.\n\nThese strategies require significant resources and political will, but are crucial for the sustainable management of transboundary marine ecosystems.\n\n\nTreaties and Conventions\nTreaties and Conventions are fundamental to managing transboundary issues around LMEs. Given the inherently shared nature of marine resources that traverse political boundaries, international collaboration facilitated by such agreements is vital. They provide a legal framework that encourages cooperation and coordination among nations, ensuring sustainable management and conservation of marine resources, protection of marine biodiversity, and resolution of potential conflicts. Notably, they allow for integrated management strategies that consider the ecosystem as a whole, rather than fractured approaches divided by national boundaries. Such holistic approaches are crucial for preserving the health and resilience of LMEs in the face of pressing global challenges like overfishing, pollution, and climate change.\nIn the field of international law, the terms “treaty” and “convention” are often used interchangeably. Both are agreements under international law entered into by actors in international law, namely sovereign states and international organisations. They may also be known as international agreements, protocols, covenants, or exchanges of letters, among other terms.\nHowever, sometimes subtle distinctions are made between Treaties and Conventions:\n\nTreaty: This term is often used to describe an agreement of significant importance. Treaties generally require ratification by the national government of the signing parties and usually require approval by the executive or legislative branch, depending on a country’s laws. A treaty might address a specific issue, like a peace treaty or a treaty of alliance, or it might establish long-term relationships or conditions, like a free trade treaty.\nConvention: A convention is typically a broader agreement that deals with a wide area of concern or is used to codify and develop major areas of international law. Conventions are usually open for any relevant countries to join. An example would be the United Nations Framework Convention on Climate Change (UNFCCC), which establishes a framework for addressing the issue of climate change.\n\nDespite these subtle differences, the choice of term often depends more on tradition or the preference of the parties involved than any strict legal distinction. What matters most is the content of the agreement and how it is implemented and enforced, not the label given to it.\n\n\nThe Benguela Current Convention\nThe Benguela Current Convention and the Benguela Current Commission have their roots in a shared recognition by Angola, Namibia, and South Africa of the importance of the BCLME and the need for a cooperative approach to its management. Both stem from the earlier Benguela Environment Fisheries Interaction and Training (BENEFIT) program.\nBENEFIT was launched in 1997 as a bilateral initiative between Namibia and Angola, and South Africa joined later. It promoted the sustainable utilisation of marine resources in the Benguela Current region. The program placed an emphasis on capacity building, training, and scientific research, particularly focusing on the interactions between the environment and fisheries. Except for benefiting from the training component, people were not yet recognised as an important feature of the system. However, BENEFIT was instrumental in improving the understanding of the complex Benguela ecosystem and the impacts of various human activities on it.\nRecognising the ecological and economic significance of this region, the three nations initiated a cooperative venture in 1995, funded by the Global Environment Facility (GEF), to address shared marine and coastal management issues. This led to the creation of the BCLME Programme, which operated from 2002 to 2011. The work of BENEFIT was integrated into the new program and this ensured continuity in scientific research and capacity-building efforts, and allowed the BCLME Programme to advance BENEFIT’s achievements.\nBuilding on the early achievements and lessons of the BCLME Programme, the three countries formally established the Benguela Current Commission (‘the Commission’) in 2007 as an interim arrangement. The Commission’s objective was to promote a coordinated regional approach to the long-term conservation, protection, rehabilitation, enhancement, and sustainable use of the BCLME. This was intended to provide benefits to the countries through improving the conditions of the marine environment and promoting sustainable economic development.\nThe Benguela Current Convention (‘the BCC’), on the other hand, came into existence on 18 March 2013 when it was signed by the ministers responsible for fisheries and environment from Angola, Namibia, and South Africa. This legal agreement formalised the cooperative approach that had been initiated with the establishment of the Commission. The BCC committed the countries to work together through the Commission to promote a policy of ecosystem-based management, to share information and data, to harmonise policies and laws, and to seek funding for activities that support the BCC’s objectives.\nThus, the Commission5 was established first as an interim body to coordinate the management of the BCLME, and the Convention, i.e. the BCC,6 was subsequently signed to formalise and strengthen this regional cooperation, making the Commission the implementing body for the BCC.\n5 The Benguela Current Commission (the Commission) is the organisation or body that was established to implement the provisions of the Convention6 The Benguela Current Convention (BCC) is the actual legal agreement that was signed by the governments of the three countries.The BCC reflects an ideology of shared responsibility, cooperation, and sustainable management of a transboundary marine ecosystem, the BCLME. It represents a commitment by the three coastal countries—Angola, Namibia, and South Africa—to the long-term conservation, protection, rehabilitation, enhancement, and sustainable use of this LME.\nThe BCC acknowledges the BCLME as a shared resource and emphasises the importance of regional cooperation to maintain its health and productivity. The ideology includes recognising the socio-economic and ecological importance of the region, the need to prevent and reduce environmental degradation, and the importance of basing management decisions on the best available scientific information.\nThe BCC also adopts the Ecosystem Approach to Fisheries (EAF) and Integrated Ocean Management (IOM), principles that emphasise holistic, precautionary, and adaptive management, considering ecological relationships among species and their habitats, and balancing diverse societal objectives.\nMoreover, the BCC recognises the importance of involving all stakeholders, including local communities, in the management process, reflecting an ideals of inclusivity and equitable benefit sharing. In essence, the BCC is underpinned by the principles of sustainability, shared responsibility, cooperative management, scientific knowledge, and inclusive stakeholder participation.\n\n\nOther Africa-focussed treaties and conventions\nYes, there are a number of transboundary conventions, agreements, and treaties active around Africa, including the following:\n\nNairobi Convention: Officially known as the Convention for the Protection, Management and Development of the Marine and Coastal Environment of the Western Indian Ocean, this convention involves ten countries: Comoros, France, Kenya, Madagascar, Mauritius, Mozambique, Seychelles, Somalia, Tanzania, and South Africa. Similar to the Benguela Current Convention, the Nairobi Convention provides a platform for governments, civil society and the private sector to work together for the sustainable management and use of the Western Indian Ocean.\nConvention for Cooperation in the Protection, Management and Development of the Marine and Coastal Environment of the Atlantic Coast of the West, Central and Southern Africa Region (Abidjan Convention): A comprehensive agreement among 22 African nations aimed at the protection and preservation of the marine environment and coastal areas. It is governed by the United Nations Environment Programme (UNEP) and provides a collaborative framework to address a wide range of environmental challenges, such as pollution from various sources, coastal erosion, and the conservation of biodiversity. It promotes cooperative research, monitoring, and the implementation of specific protocols, including those addressing oil spills and the establishment of protected areas, to ensure sustainable use and management of the region’s shared marine resources.\nAbuja Convention: This proposed convention is set to replace the Abidjan Convention, covering a larger geographical area and including more countries. Its main purpose is to promote regional cooperation for the protection and development of the marine and coastal environment of the Atlantic coast of West, Central and Southern Africa.\nBamako Convention: Although not specifically focused on marine environments, the Bamako Convention on the Ban of the Import into Africa and the Control of Transboundary Movement and Management of Hazardous Wastes within Africa has relevance in terms of preventing marine pollution. The convention prohibits the import of any hazardous (including radioactive) waste. The treaty also emphasizes reducing the production of hazardous waste and promoting environmentally sound management of such wastes.\nThe Joint Development Zone Treaty between Nigeria and Sao Tome and Principe: This is an agreement between the two nations to jointly develop petroleum and other resources in the maritime areas which both nations lay claim to.\nLake Chad Basin Commission (LCBC): While not marine-focused, the LCBC is a prime example of transboundary water management. It was established in 1964 by Cameroon, Chad, Niger, and Nigeria, with the Central African Republic joining later. The Commission aims to sustainably and equitably manage shared water resources and promote regional integration, peace, and security.\n\nEach of these agreements and conventions share similarities with the BCC in that they aim to foster cooperation and sustainable use of shared marine and environmental resources among the participating nations. However, they each have unique focuses and cover different geographical areas.\n\n\nComparing the BCC with the Abidjan Convention\nThe Abidjan Convention and the BCC are both concerned with the the west coast of the African continent. They share the common goal of protecting and managing marine and coastal environments, but they operate in different geographical regions and with some different focus areas. The Abidjan Convention covers the Atlantic coast of Africa, from Mauritania to South Africa, while the BCC covers the Benguela Current Large Marine Ecosystem (BCLME), which extends from South Africa to Angola. Both conventions adhere to an ecosystem-based approach to management. They acknowledge the interconnectedness of marine ecosystems and aim to manage these systems in a holistic manner. The importance of cooperation and collaboration among the member states in managing shared marine resources and addressing common environmental challenges is key to the success of both.\nThere are key differences between the two convention. The Abidjan Convention has a broader membership with 22 African countries, while the BCC only includes three countries—Angola, Namibia, and South Africa. The latter has a unique focus on the BCLME (i.e. it is designed on the idea of the LME), one of the world’s richest marine ecosystems with a high level of endemism and biodiversity. It is also particularly concerned with the effects of climate change and variability on this ecosystem. The Abidjan Convention, while also concerned with marine ecosystems and biodiversity, has a broader mandate that includes issues such as coastal erosion and marine pollution from various sources.\nThere are also differences in structure and governance. The BCC is led by a commission consisting of ministers from the three member states, while the Abidjan Convention is overseen by the United Nations Environment Programme (UNEP) and has a wider governance structure involving all member states. As such, the Abidjan Convention has established specific protocols to address issues like oil spills and protected areas. The BCC, while it does cover similar issues, does not have specific protocols but rather uses strategic action programs and other mechanisms to address these concerns. More recently, a Marine Spatial Plan has also been developed for the BCC.\n\n\nInternational examples of transboundary management of marine regions\nThere are several international treaties and conventions that aim to manage and protect transboundary marine ecosystems, similar to the Benguela Current Convention (BCC):\n\nConvention for the Protection of the Marine Environment of the North-East Atlantic (OSPAR Convention): This convention was established in 1992 and covers the north-east Atlantic. Like the BCC, it focuses on the protection and conservation of the marine environment. However, it differs in that it covers a broader geographic area and has more contracting parties, involving 15 Governments and the EU. The convention has five main strategies: Biodiversity and Ecosystems, Eutrophication, Hazardous Substances, Offshore Industry, and Radioactive Substances.\nConvention on the Protection of the Marine Environment of the Baltic Sea Area (Helsinki Convention): This convention was established in 1974 and revised in 1992. It covers the Baltic Sea area, which is bordered by nine countries. Similar to the BCC, it aims to prevent and eliminate pollution in order to promote the ecological restoration of the Baltic Sea. However, it covers a smaller geographic area and includes more specific commitments, such as banning dumping of waste from ships and aircraft.\nBarcelona Convention for the Protection of the Marine Environment and the Coastal Region of the Mediterranean: Established in 1976, this convention covers the Mediterranean Sea and its coastal areas. It involves 21 countries bordering the Mediterranean, and the European Union. Like the BCC, it focuses on the protection and sustainable development of the marine and coastal environment, but it has a greater emphasis on specific issues such as pollution from land-based sources, pollution by dumping, pollution from ships, and pollution resulting from exploration and exploitation of the continental shelf and the seabed and its subsoil.\n\nWhat makes the BCC unique is that it covers the Benguela Current Large Marine Ecosystem (BCLME), which is one of the richest marine ecosystems on earth and one of the four major eastern boundary upwelling systems. This system is of global importance for marine biodiversity and climate regulation. The BCC is the first to be based on the Large Marine Ecosystem (LME) concept of ocean governance, a concept that is endorsed by the United Nations. The BCC is also unique in its tri-national approach, involving Angola, Namibia, and South Africa, and in its comprehensive coverage of marine conservation, sustainable development, and the sharing of benefits and responsibilities among the contracting parties.\n\n\nOther notable treaties and conventions\nThe examples I provided earlier are some of the key international treaties and conventions that focus on the protection and management of transboundary marine ecosystems. However, there are other important marine conventions and agreements around the world. A few more include:\n\nRamsar Convention on Wetlands: Established in 1971, this convention provides a framework for the conservation and wise use of all wetlands, including marine systems in coastal zones, through local and national actions and international cooperation. It currently includes 171 contracting parties.\nConvention on Biological Diversity (CBD): Although this convention covers all ecosystems, its specific work on marine and coastal biodiversity is very significant. It recognises the ecological, economic, and cultural importance of marine and coastal ecosystems and aims to safeguard them through science-based management practices.\nWestern and Central Pacific Fisheries Convention (WCPFC): This convention specifically aims to conserve and manage highly migratory fish stocks across the western and central Pacific Ocean. It does this by cooperating with relevant countries and stakeholders to ensure long-term sustainability of these resources.\nAntarctic Treaty System: This includes the Antarctic Treaty and related agreements, such as the Convention for the Conservation of Antarctic Marine Living Resources. It’s unique in that it governs the entire Antarctic region, which is recognised as a natural reserve, devoted to peace and science.\nCartagena Convention: Formally known as the Convention for the Protection and Development of the Marine Environment of the Wider Caribbean Region, it aims to protect, develop and manage the Marine Environment of the Wider Caribbean Region in a sustainable way.\n\nThese, along with the ones already mentioned, are some of the many efforts globally to manage and conserve marine ecosystems. Each is unique in its focus, region, challenges, and approach to marine management. The BCC remains notable for its LME-based approach and its focus on one of the world’s most productive marine ecosystems.\n\n\n\n\n\n\n\n\nReferences\n\nSweijd N, Smit A (2020) Trends in sea surface temperature and chlorophyll-a in the seven african large marine ecosystems. Environmental Development 36:100585.\n\nReuseCC BY 4.0CitationBibTeX citation:@online{j._smit2023,\n  author = {J. Smit, Albertus},\n  title = {Transboundary Systems},\n  date = {2023-05-15},\n  url = {http://tangledbank.netlify.app/pages/Transboundary_systems.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A (2023) Transboundary systems. http://tangledbank.netlify.app/pages/Transboundary_systems.html.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Transboundary systems"
    ]
  },
  {
    "objectID": "pages/research_grants.html",
    "href": "pages/research_grants.html",
    "title": "National and international research grants",
    "section": "",
    "text": "2020 – 2022: Belmont Forum Collaborative Research Action on Transdisciplinary Research for Ocean Sustainability: Ecological and Economic impacts of the intensification of extreme events in the Benguela Upwelling System, Principal Investigator (EXEBUS) PDF\n2019 – 2021: SANOCEAN: Factors influencing the formation, fate and transport of microplastic in marine coastal ecosystems (FORTRAN) PDF\n2019 – 2021: SANOCEAN: Blue growth opportunities in changing kelp forests (BlueConnect) PDF\n2019 – 2023: Horizon 2020: iAtlantic, led by Prof. Murray Robert, own capacity as Regional Coordinator for the SE Atlantic PDF"
  },
  {
    "objectID": "pages/research_grants.html#international-grants",
    "href": "pages/research_grants.html#international-grants",
    "title": "National and international research grants",
    "section": "",
    "text": "2020 – 2022: Belmont Forum Collaborative Research Action on Transdisciplinary Research for Ocean Sustainability: Ecological and Economic impacts of the intensification of extreme events in the Benguela Upwelling System, Principal Investigator (EXEBUS) PDF\n2019 – 2021: SANOCEAN: Factors influencing the formation, fate and transport of microplastic in marine coastal ecosystems (FORTRAN) PDF\n2019 – 2021: SANOCEAN: Blue growth opportunities in changing kelp forests (BlueConnect) PDF\n2019 – 2023: Horizon 2020: iAtlantic, led by Prof. Murray Robert, own capacity as Regional Coordinator for the SE Atlantic PDF"
  },
  {
    "objectID": "pages/research_grants.html#national-grants",
    "href": "pages/research_grants.html#national-grants",
    "title": "National and international research grants",
    "section": "National grants",
    "text": "National grants\n\n2019 – 2021: NRF Global Change Grand Challenge: Earth System Science Research Programme — Extreme Climatic Events in the Coastal Zone, Principal Investigator (ESS180920360856) PDF\n2018 – 2020: NRF Competitive Programme for Rated Researchers —Upwelling dynamics in kelp beds: implications for trophic function PDF\n2017: CHEC/CCT Joint Research Programme 2017: What can kelp loss processes and beach cast patterns tell us about the sandy beach management? PDF\n2015 – 2017: NRF Competitive Programme for Rated Researchers (CPRR) — Thermal characteristics of the South African nearshore: implications for biodiversity PDF\n2014 – 2016: NRF Competitive Programme for Rated Researchers (CPRR) — Kelps and climate change: South Africa in a global context PDF\n2014 – 2016: NRF Incentive Funding for Rated Researchers (IPRR) Grant No. IFR14020764026 PDF"
  },
  {
    "objectID": "pages/case_for_promotion.html#develop-level-3-module-bdc334-and-bsc-hons-modules-bcb744-and-bcb743-for-the-bcb-department",
    "href": "pages/case_for_promotion.html#develop-level-3-module-bdc334-and-bsc-hons-modules-bcb744-and-bcb743-for-the-bcb-department",
    "title": "Ad Personam Promotion 2023",
    "section": "4.1.1. Develop Level-3 module BDC334, and BSc (Hons) modules BCB744 and BCB743 for the BCB Department",
    "text": "4.1.1. Develop Level-3 module BDC334, and BSc (Hons) modules BCB744 and BCB743 for the BCB Department\nCapitalising on an extensive history of curriculum development5, I have played a vital role in revitalising the core BSc (Hons) module, BCB744 Biostatistics, and in creating the innovative elective BSc (Hons) module, BCB743 Quantitative Ecology. My deep fascination with biological, ecological, and environmental data underpins these modules, fuelling my passion for data processing, analysis, interpretation, and the invaluable insights that emerge from such data-driven enquiries.\n5 I was instrumental in developing South Africa’s first undergraduate Marine Biology curriculum at the University of KwaZulu-Natal in 2007 (with Profs. Perissinotto and Schoeman)6 See a discussion about how I allow modern technologies to influence and shape my teachingR, an open-source software ecosystem extensively adopted by ecologists, is the cornerstone of my core and elective BSc (Hons) modules. The increasing number of research papers and publications in biology and ecology utilising R and its packages attests to its importance. In academic settings such as UWC, Africa, and less developed countries, open-source software removes potential licensing obstacles presented by limited financial resources. This allows universal access to the software, enhancing scientific reporting, collaboration, and the principles of reproducible research, while fostering a culture of technological infusion6.\nAnother new module, BDC334 Global Biogeography & Macroecology, for which I share 50% of the credit for its development, is less data-intensive. This module lays the groundwork for engaging with species and environmental data matrices from which functional ecological processes can be extracted. Recent feedback from students who completed this module in 2022 indicated that exposure to more data-intensive coursework and an introduction to basic coding skills significantly alleviated the anxiety many students feel about coding (scripting). They further suggested that this exposure smoothed their transition into BCB744, the core module they undertake at the start of their BSc (Hons) degrees.\nCollaborative learning is a cornerstone of my teaching approach7, the benefits of which I discuss in my online teaching materials. I use engaging teaching tools to instil interest in my subjects. For example, figures and maps8 serve as critical heuristic devices throughout the modules. The visually appealing and information-rich outcomes of their learning efforts provide an immediate measure of success. In this way, students develop programming skills by breaking down problems into computable parts, whilst also enhancing their visual literacy skills. This engaging and interactive approach is deeply integrated with an agile assessment policy that evaluates teaching and learning9 10. My modules demystify coding, making it more accessible and enjoyable for beginners.\n7 Views on collaborative learning8 Example exercises and bonus, designed to reward and incentivise continued learning towards advanced skills9 Assessment policy for BCB74410 Explanation of modes of assessment11 Module-specific graduate attributes12 The difference between science and data scienceThe skills learnt and the graduate attributes11 developed are designed to produce competencies outside the narrow confines of Biodiversity and Conservation Biology. Transferable core skills include compartmentalising complex problems and finding analytical solutions to problems in diverse fields such as finance, market research, and data science. Many students who graduate with a BSc (Hons) course from the BCB Department will, without requiring further training, have the same skills as someone who has completed a data science course.12 Many of our graduates will not pursue a research-focused career, yet they would like to continue benefiting from the skills gained at the BCB Department.\nStructured outlines of the syllabus, timetables, course content, learning outcomes, required and recommended reading, assessment policies, advice for success (e.g. how to learn to understand13), model answers to old tests and exam questions (e.g. for BDC33414), and much else, are made available for all modules. During 2023 I will continue to build upon existing content and expand my approach to the other module I teach, BDC223 Plant Ecophysiology.\n13 Thoughts about the learning process14 Access to old test and exam questions"
  },
  {
    "objectID": "pages/case_for_promotion.html#develop-the-tangled-bank-website-in-support-of-undergraduate-and-bsc-hons-modules",
    "href": "pages/case_for_promotion.html#develop-the-tangled-bank-website-in-support-of-undergraduate-and-bsc-hons-modules",
    "title": "Ad Personam Promotion 2023",
    "section": "4.1.2. Develop the Tangled Bank website in support of undergraduate and BSc (Hons) modules",
    "text": "4.1.2. Develop the Tangled Bank website in support of undergraduate and BSc (Hons) modules\nWhile I’m not particularly fond of PowerPoint slides, I recognise their utility in structuring lectures. My preference leans towards long-form, information-rich text for delivering in-depth content15. Ideally, I would base my teaching on textbooks, but these are not accessible to all our students. In our fast-paced world, information can quickly become outdated, posing a challenge to addressing students’ evolving learning and knowledge needs. The reality is that many students are averse to reading. To overcome this, I’ve developed and continue to enhance The Tangled Bank, a teaching-oriented website tailored to the needs of students enrolled in my Level-3 and BSc (Hons) modules. Leveraging the website format, I can ensure timely updates of knowledge and technologies in response to the swiftly changing scientific landscape and students’ learning requirements and feedback.\n15 For an example of information rich text, see the example page16 See the ‘vignettes’ menu at the top of The Tangled Bank.17 For example, the FAQ page for BDC22318 See feedback from colleagues about The Tangled BankThe Tangled Bank serves as my main repository for lecture content and a continually expanding knowledge base for guiding research within my areas of focus. This website preserves invaluable behind-the-scenes insights16, contributes to the development of online textbooks, consolidates frequently asked questions about module content which ensures responsiveness to students17, and reinforces BCB Department modules by integrating relevant examples from my colleagues’ work18. The Tangled Bank aids peers in overcoming module-specific challenges, thereby enriching the learning experience.\nProviding students access to long-form written teaching materials and instilling an expectation to engage with this content are pivotal in preparing students for their undergraduate and graduate degree programs. Long-form content facilitates a thorough exploration of ideas, offering context, nuances, and essential background information that enable students to understand complex concepts. By immersing themselves in comprehensive texts, students can cultivate a profound understanding of intricate topics, empowering them to think critically and analytically.\nContrary to summarised bullet points, which can oversimplify and condense information, possibly omitting crucial details, long-form materials motivate students to delve deep into a subject and contemplate various perspectives. This approach fosters intellectual curiosity and instills a genuine interest in the subject, promoting a culture of lifelong learning. Engaging with long-form content allows the motivated student to build a robust knowledge base rooted in self-driven learning, forming a firm foundation for their future academic and professional pursuits. As an educator, this is my aspiration.\nFurthermore, interacting with long-form written materials enhances students’ reading comprehension skills. As they sift through dense texts, they learn to distinguish main ideas, supporting arguments, and potential counterarguments. This process refines their capacity to analyse and evaluate information—an essential skill in both academic and professional environments. Improving this skill is particularly crucial for the younger generation.\nBy supplying students with comprehensive content, I aim to foster a deeper appreciation for their chosen field, thus equipping them for success in their academic and professional journeys.\nLastly, The Tangled Bank strives to provide a detailed overview and breakdown of each module’s syllabus, including:\n\nan up-to-date timetable and links to each lecture’s material and assessments,\ninformation about the desired learning outcomes and graduate attributes,\nadditional supporting information,\nprerequisites,\nthe method of instruction,\nviews on the benefits of colaborative learning,\nattendance policies,\nassessment policies, and\nsupport.\n\nPlease refer to BDC33419, BCB744,20, and BCB74321 for the above-mentioned information.\n19 The BCB744 module syllabus and course outline20 The BCB743 syllabus and course outline21 The BDC334 syllabus and course outline"
  },
  {
    "objectID": "pages/case_for_promotion.html#feedback-from-external-peer-reviewers-and-students-about-above-modules-taught",
    "href": "pages/case_for_promotion.html#feedback-from-external-peer-reviewers-and-students-about-above-modules-taught",
    "title": "Ad Personam Promotion 2023",
    "section": "4.1.3. Feedback from external (peer) reviewers and students about above modules taught",
    "text": "4.1.3. Feedback from external (peer) reviewers and students about above modules taught\nThe following feedback was received from Prof. Sophie von der Heyden for BCB74322 following her assessment of the module in her capacity of External Module Evaluator for the BCB BSc (Hons) Programme: “This is an excellent course; I really appreciate that everything is online and very easy to follow. The course is appropriate and challenging at the Honours level, but there also seems excellent support for the students. Really a standout module.” Further, she says, ”There was a wide range of marks, from 45 – 88%, with only one student […] failing this module. Given that students can really struggle with R, it was good to see how well the class did overall. I think part of this is the breakdown into the multiple assignments, which allows students to build on their knowledge as the tasks get more difficult, rather than being overwhelmed with one large assignment.”\n22 Prof. Sophie von der Heyden’s feedback about BCB743 in 202223 Prof. Sophie von der Heyden’s feedback about BCB744 in 2022About BCB744,23 she says, “As with BCB743, I was very impressed by this course, particularly how easy it is to navigate around the online component. I am sure that the students will be able to access all the necessary components fairly easily. The course is very much at the level of Honours and I hope that for the final projects the students utilize their learning from this course.”\nHowever, Prof von der Heydon’s comment on the question about whether the marks were assigned appropriately, she said, “This is a little difficult to comment on as I could not see how the marks were awarded, but given the consistency of marks for each student, I think that the marks are all appropriate.”\nSince the module content is continually being developed, expanded, and improved, I addressed Prof. von der Heydon’s concern about mark allocation by providing clear assessment policies for BCB74424, BCB74325, and BDC334.26 Further, the module content on The Tangled Bank has dramatically improved in all aspects since the modules were last evaluated at the end of 2022.\n24 BCB744 assessment policy25 BCB743 assessment policy26 BDC334 assessment policy27 Student feedback about BDC223, BDC334, BCB744, and BCB743 are available at on Google DriveFeedback from students about the modules is also available.27 Six students from a class of 14 responded to the module evaluation forms in 2022. Feedback about students’ experience with the module was positive for most of the questions, but 50% of the respondents felt that better feedback could be given to individual tasks. A third of the sample also indicated they felt uncertain about the module’s expectations.\nEighteen students took BCB744 in 2022, and eight provided feedback on the module. As with BCB743, the feedback was similar. Four students felt they could benefit from more comprehensive feedback, and three respondents felt somewhat uncertain about my expectations of them (including the quality of their work). Additionally, two students felt I could better explain concepts and give them more time to understand them. Another negative comment given by two students was that they could be better empowered to explore a variety of sources better to complete assessment tasks.\nThe BDC334 class comprised 41 students in 2022, and only five students tried to provide feedback. One person felt a mismatch between the assessment and the module’s content. Five students thought feedback on individual assessments could be better. There was also one instance of dissatisfaction with the following: sufficient time for communication, my effort to understand their challenges, and uncertainty about expectations. Feedback on BDC223 in 2022 was poor, with only nine responses. Their satisfaction with the module was mixed and polarised into two distinct groups. About 50% of respondents provided much of the same feedback as I received for BCB744, BCB743, and BDC334, and these people felt that feedback on individual assignments could be better. The other half had more negative experiences and I received negative feedback for several other questions. My experience with this class in 2022 was anomalous, as it is singular as the worst class I have ever taught at University. Ever."
  },
  {
    "objectID": "pages/case_for_promotion.html#tangled-bank-vignettes-and-reproducible-research",
    "href": "pages/case_for_promotion.html#tangled-bank-vignettes-and-reproducible-research",
    "title": "Ad Personam Promotion 2023",
    "section": "4.1.4. Tangled Bank vignettes and reproducible research",
    "text": "4.1.4. Tangled Bank vignettes and reproducible research\nInterdisciplinary research brings together a variety of expertise, resulting in challenges related to teamwork, data sharing, and coding. The importance of transparency in research methodologies, like reproducible research,28 is ever increasing. Conforming to FAIR principles, international standards, and discipline-specific norms is indispensable. Even though software provides solutions, numerous researchers require assistance to stay abreast and capitalise on new expectations and possibilities.\n28 See my essay on eResearch and reproducible researchPhD students typically devote 3-4 months to active thesis writing, which often serves as the only tangible evidence of degree completion. However, the vast majority of the learning and methodological skills developed over the remaining 33-44 months often become lost and unshared, leading to duplicated research efforts and restricted knowledge transfer. This failure to share behind-the-scenes solutions often results in non-reproducible research and collaboration difficulties, sometimes even contributing to public mistrust in science. Furthermore, better scalability is needed as datasets and complexities grow, and inefficiencies due to inadequate documentation of data selection, filtering, metadata tracking, and processing changes need addressing.\nThe Tangled Bank is designed to encourage knowledge retention and transfer, both of which are crucial for success in the information economy. To tackle these issues, my research students craft lab notebooks using tools like RStudio or Jupyter Lab/Notebooks and monitor version changes with git (e.g., GitHub). These notebooks combine code and text, automatically updating results as new data become available, thereby ensuring reproducibility in their work.29 30 31 I emphasise these same principles in both undergraduate and postgraduate courses I teach. The website also includes a series of vignettes32 that capture some of the analytical data workflows that often raise questions. These vignettes will continually be updated, and more examples documenting my own and my colleagues’ data and statistical analysis challenges will be preserved here for posterity.\n29 Dr Robert Schlegel’s GitHub page30 Ms Amieroh Abrahams’s GitHub page31 Mr Ross Coppin’s GitHub page32 Examples of vignettes may be accessed at The Tangled Bank under the ‘vignettes’ menu at the top.33 The heatwaveR website—see the vignettes in the top menu.Other vignettes are at the heatwaveR website.33"
  },
  {
    "objectID": "pages/case_for_promotion.html#successful-and-prolific-funding-attraction",
    "href": "pages/case_for_promotion.html#successful-and-prolific-funding-attraction",
    "title": "Ad Personam Promotion 2023",
    "section": "4.2.1. Successful and prolific funding attraction",
    "text": "4.2.1. Successful and prolific funding attraction\nMy H-index on Google Scholar is currently 2934, which ranks as the second highest in the BCB Department. As of 29 June 2023, the site has recorded a total of 4,167 citations, 2112 of which were garnered since 2018. Since joining UWC in 2014, my annual publication average stands at approximately five; however, this rate has somewhat dropped in light of the COVID-19 pandemic. With the induction of a new cohort of students into my postgraduate research group, I anticipate a resurgence in the publication rate.\n34 See my Google Scholar page35 List of national and international research funding receivedMy leadership and management skills, cultivated over the past eight years, are demonstrated by my significant success in securing funding from national and international research programmes35. Moreover, I’ve successfully seen these programmes through to completion, aligning with well-defined goals and objectives. Since 2014, these research endeavours have cumulatively raised an estimated ZAR 28.74 million, bolstering the sustainability of research efforts for myself, my collaborators, and my students.\nHistorically, I have primarily relied on the NRF for funding. However, in recent years, I have been diversifying my collaborations internationally. This strategy is facilitated by accessing global funding streams, such as those provided by the European Union, the Belmont Forum, and the SANOCEAN programme. These sources not only leverage funding from partnering countries, but they also foster a degree of collaboration that exceeds what is typically feasible with South Africa-centric funding.\nPreviously, I held a C2 rating, but chose to let it lapse after thoughtful consideration. I’ve expanded on my views regarding the rating system elsewhere36. Thus far, I’ve found that having an NRF rating does not necessarily enhance the likelihood of obtaining research funding.\n36 My thoughts about the NRF rating system and maintaining my own rating"
  },
  {
    "objectID": "pages/case_for_promotion.html#development-of-r-packages-in-marine-heatwave-analysis",
    "href": "pages/case_for_promotion.html#development-of-r-packages-in-marine-heatwave-analysis",
    "title": "Ad Personam Promotion 2023",
    "section": "4.2.2. Development of R packages in marine heatwave analysis",
    "text": "4.2.2. Development of R packages in marine heatwave analysis\nOne of my most distinctive and significant research contributions is the creation of two R packages: RmarineHeatWaves37 and heatwaveR38. These tools emerged as a response to the formal definition of marine heatwaves proposed by Alistair Hobday and his team in 2016. The algorithm to detect marine heatwaves based on standardised metrics was first published as an R package under the name RmarineHeatWaves, and later updated to heatwaveR in 2017. This software has since been downloaded more than 32k times39 by the international scientific community and has been cited in over 150 peer-reviewed papers since 201840. I, alongside Dr. Robert Schlegel, my former UWC PhD student, continue to maintain and enhance this package, introducing new functionalities in response to the needs of our user community.\n37 The RmarineHeatWaves documentation.38 heatwaveR. Also see the GitHub page39 The RmarineHeatWaves documentation.40 This number is hard to track, but a search in Google Scholar for the term “heatwaveR” (inverted commas included) yields at least 150 citations. A shorter list of the citations is provided on the heatwaveR website. Notable examples of high-impact publications are provided here41 Examples of cross-discipline research in marine heatwaves promoted by the heatwaveR package are provided here42 Evidence of the application of the heatwaveR package outside of the initially intended field of application, marine science, here.The influence of this R package on the global marine heatwave research community cannot be overstated. The standardisation of metrics it offers facilitates a more consistent global study of these events. Prior to its release, these tools were largely available only to physical oceanographers who primarily use Python; publishing it in R extended its reach to biologists and ecologists. This has sparked interdisciplinary collaboration across fields like oceanography, climatology, and ecology41. Interestingly, it is now being applied in areas beyond its initial intended marine scope, such as public health42, demonstrating its broad and unexpected utility.\nGiven the consistency in reporting Marine Heat Wave (MHW) metrics, the quality of decision-making by policy-makers and resource managers has been significantly enhanced. For instance, gaining a more refined understanding of MHWs aids in devising strategies to mitigate the environmental repercussions of extreme thermal events, as well as adapting to their influences on fisheries and other marine resources43.\n43 For studies that have used metrics calculated by heatwaveR in support of policy development around the management of marine living resources, see this list44 Evidence of examples where such novel research questions and hypotheses have been addressedFurther, heatwaveR also led to the development of novel research questions and hypotheses that better analyse and compare MHWs across different periods and regions and employ the metrics to design creative experiments that better link ecological impacts to precisely quantifiable properties of the temperature record.44\nFinally, the heatwaveR package raises public awareness about MHWs and their impacts on marine ecosystems by making it easier for researchers to communicate their findings to a broader audience. For example, the marine heatwave tracker built by Dr Schlegel uses the heatwaveR package in the background.45\n45 Various online trackers of marine heatwaves use heatwaveR as the underlying processing engine"
  },
  {
    "objectID": "pages/case_for_promotion.html#student-supervision",
    "href": "pages/case_for_promotion.html#student-supervision",
    "title": "Ad Personam Promotion 2023",
    "section": "4.2.3. Student supervision",
    "text": "4.2.3. Student supervision\nMy UWC student supervision record is provided in my e-Portfolio.46 The record indicates 16 BSc (Hons) graduates, 11 MSc/MPhil graduates, and 7 PhD graduates. Appearing on the online NRF online system as active and continuing is Mr Phumlile Cotiyane, a PhD candidate registered with SAEON’s Elwandle Node whom I am co-supervising. Including postgraduate supervision prior to my tenure at the UWC in 2014 brings my career total to 57 graduates, across all levels.\n46 Extract from the NRFOnline system listing most of my post-graduate studentsI have five active MSc students (Ms Cayley Cammel, Mr McQuwaen Moonoosamy, Mr Jesse Philips, Mr Tom Spencer-Hicken, and Ms Carlin Landsberg) and four active BSc (Hons) candidates, Ms Aailyah Samsodien, Ms Zoë-Angelique Petersen, Mr Taine Trimmel, and Mr Isma-eel Jattiem. Since these students receive free-standing bursaries from the NRF, their names do not yet appear in my NRF database under the list of students associated with my research profile. This also applies to Ms Zara Prew, an active PhD student in my research group.\nRoughly 49% of all the individuals, above, are of previously disadvantaged backgrounds, and 12% were with my role as co-supervisor.\nI have had three post-docs in my lab: Dr Rob Williamson, Dr Christo Rautenbach, and Dr David Dyer, and the latter will be with me until December 2023."
  },
  {
    "objectID": "pages/case_for_promotion.html#the-south-african-coastal-seawater-temperature-network-sactn",
    "href": "pages/case_for_promotion.html#the-south-african-coastal-seawater-temperature-network-sactn",
    "title": "Ad Personam Promotion 2023",
    "section": "4.2.4. The South African Coastal Seawater Temperature Network (SACTN)",
    "text": "4.2.4. The South African Coastal Seawater Temperature Network (SACTN)\nRelated to my interest in marine heatwaves, I have also been instrumental in developing the South African Coastal Seawater Temperature Network (SACTN).47 This work brings together, for the first time, the disparate seawater temperature records measured over up to 4 decades by the KwaZulu-Natal Sharks Board (KZNSB), Ezemvelo KZN Wildlife (EKZNW), the South African Weather Service (SAWS), the Department of Forestry, Fisheries and Environment (DFFE), the South African Environmental Observation Network (SAEON), and the UWC. 48 This paper has been cited 166 times and instrumental in several other of my own frequently cited publications49 and stimulated further avenues of research regarding the variability of ocean temperature, including the research on marine heatwaves.\n47 The The South African Coastal Seawater Temperature Network (SACTN) GitHub page from where data can be downloaded48 Smit et al (2013)49 Schlegel et al (2017a) and Schlegel et al (2017b)"
  },
  {
    "objectID": "pages/case_for_promotion.html#editorial-contributions",
    "href": "pages/case_for_promotion.html#editorial-contributions",
    "title": "Ad Personam Promotion 2023",
    "section": "4.2.5. Editorial contributions",
    "text": "4.2.5. Editorial contributions\n2018–present Associate Editor, Aquatic Botany.50\n50 Associate Editor for Aquatic Botany51 My Reviewer’s profile on Loop for editorial contributions to Frontiers in Ecology & Evolution2020–present Associate Editor Frontiers in Ecology & Evolution and Frontiers Topic Editor,51 Managing Deep-sea and Open Ocean Ecosystems at Ocean Basin Scale - Volume 2\n2023–present Guest Editor, Special Issue, Botanica Marina\nIn addition, reviewing done for Frontiers in Marine Science; Plos ONE; Proceedings of the National Academy of Sciences; Journal of Phycology; Estuarine Coastal & Shelf Science; African Journal of Marine Science; Hydrobiologia; Journal of Applied Phycology; Journal of Marine Systems; Marine Biology; Marine Ecology; Diversity & Distributions; Ecology & Evolution; Atmosfera; Big Earth Data; Botanica Marina; Environmental Pollution; Science of the Total Environment; Frontiers Ecology And Evolution; Meteorology and Atmospheric Physics; One Health; International Journal of Environmental Research and Public Health, Marine Pollution Bulletin."
  },
  {
    "objectID": "pages/case_for_promotion.html#future-research",
    "href": "pages/case_for_promotion.html#future-research",
    "title": "Ad Personam Promotion 2023",
    "section": "4.2.6. Future research",
    "text": "4.2.6. Future research\nMy future research endeavours will focus on investigating the interplay between coastal marine extreme events and the shifting climate. The objective is to ensure that this research is both relevant and beneficial to a broad spectrum of actors who gain from nature’s contributions. Building upon the foundation of my BlueConnect and EXEBUS programmes, the scope of my work will increasingly embody a transdisciplinary approach. This will be achieved through collaborations with experts in economics, sociology, and maritime law, rendering the research relevant to both society and industry. Within this field, my specific interests—the biogeochemical function of kelp and the detection and statistical analysis of extreme events in environmental time series—will be deployed to establish links between environmental drivers and their impacts on ecosystems and society."
  },
  {
    "objectID": "pages/case_for_promotion.html#academic-lead-kelp-scientific-collaboration-ppp",
    "href": "pages/case_for_promotion.html#academic-lead-kelp-scientific-collaboration-ppp",
    "title": "Ad Personam Promotion 2023",
    "section": "4.3.1. Academic Lead, Kelp Scientific Collaboration PPP",
    "text": "4.3.1. Academic Lead, Kelp Scientific Collaboration PPP\nI have been the academic lead of the Kelp Scientific Collaboration52 consortium since September 2021 (ongoing). The consortium is a Public-Private-Partnership whose intention is to foster collaboration around kelp ecosystems for the betterment of sustainable practices that concern the industry and for scientific advancement on kelp ecological functioning.\n52 Kelp Scientific Collaboration mission statement"
  },
  {
    "objectID": "pages/case_for_promotion.html#a-research-project-funded-by-sanocean-blueconnect-about-the-perceived-value-of-south-african-kelp",
    "href": "pages/case_for_promotion.html#a-research-project-funded-by-sanocean-blueconnect-about-the-perceived-value-of-south-african-kelp",
    "title": "Ad Personam Promotion 2023",
    "section": "4.3.2. A research project, funded by SANOCEAN BlueConnect, about the perceived value of South African kelp",
    "text": "4.3.2. A research project, funded by SANOCEAN BlueConnect, about the perceived value of South African kelp\nThis project on the perceived value of kelp53 was heavily concerned with people’s relationship with kelp and produced several outputs:\n53 Perceived Value of Kelp\nJanuary 2022 Premier of Akshata Mehta’s movie, Kelp, South Africa’s Golden Forests (funded by myself through BlueConnect, and provided concept and oversight).54 The short film was first shown at the annual PSSA meeting in Arniston and subsequently entered into various nature documentary festivals. It is also on YouTube, where it has received 5.3k views.\nSeptember 2021 Supervise Akshata Mehta’s MPhil Thesis, “Golden Forests” of the Sea: Assessing Values and Perceptions of Kelp in the Western Cape Region of South Africa. This work continues to yield stakeholder engagements with community members and the seaweed industry of Southern Africa.55\n\n54 Kelp, South Africa’s Golden Forests on YouTube55 Akshata Mehta’s MPhil thesis"
  },
  {
    "objectID": "pages/case_for_promotion.html#blueconnect-engagements",
    "href": "pages/case_for_promotion.html#blueconnect-engagements",
    "title": "Ad Personam Promotion 2023",
    "section": "4.3.3. BlueConnect engagements",
    "text": "4.3.3. BlueConnect engagements\n\nContributing author to Chapter 3, UNEP report on global kelp forests.56\nGlobal Ecological Assessment of Kelp, June 15-17, 2022, in Arendal, Norway.57 This work stems directly from the SANOCEAN BlueConnect Programme, of which I am the South African PI. The work intended to bring together global kelp experts to evaluate kelp forests.\nBlueConnect Kelp Ecosystem 10-day Field Course, 16 – 26 March 2020, Cape Town and De Hoop Nature Reserve – this workshop was affected by COVID-19 and all field work was cancelled; it proceeded as an online course. Ten students from South Africa and Norway participated.58\nNovember 2019: Lead workshop with the kelp industry to gain perspectives about challenges they face about environmental and governance concerns they experience.\n\n56 United Nations Environment Programme, & Norwegian Blue Forests Network (2023). Into the Blue: Securing a Sustainable Future for Kelp Forests.57 Invitation letter to the GEAK workshop held in Norway58 BlueConnect March 2020 Field Course"
  },
  {
    "objectID": "pages/case_for_promotion.html#exebus-engagements",
    "href": "pages/case_for_promotion.html#exebus-engagements",
    "title": "Ad Personam Promotion 2023",
    "section": "4.3.4. EXEBUS engagements",
    "text": "4.3.4. EXEBUS engagements\nEXEBUS59 60 undertakes an Integrated Ecosystem Assessment (IEA) to establish the roles, trends, and range of variability and the extremities of natural and anthropogenic geophysical, biological, governance, socio-economic features and phenomena, and assess their impact on ecological, sociological, governance, and macroeconomic systems and processes in the Benguela Current Large Marine Ecosystem (BCLME) of South Africa (SA), Namibia, and Angola. The goal is to strengthen the rational basis for management on relevant spatial and temporal scales (up to 2070).\n59 Video on YouTube about EXEBUS60 EXEBUS websiteTo further these interests, my Team and I have had stakeholder engagements with (ongoing):\n\n2022 The Benguela Current Convention\n2022 The kelp industry in South Africa\n2022 An assortment of stakeholders (academia, the Ministry of Fisheries, University of Namibia academics)\n2023 Users and port operators of the Port of Cape Town"
  },
  {
    "objectID": "pages/case_for_promotion.html#other-community-engagements-and-capacity-building-contributions",
    "href": "pages/case_for_promotion.html#other-community-engagements-and-capacity-building-contributions",
    "title": "Ad Personam Promotion 2023",
    "section": "4.3.5. Other community engagements and capacity-building contributions",
    "text": "4.3.5. Other community engagements and capacity-building contributions\nI am currently involved with Cape Nature in initiatives aimed at building capacities among fishermen in the Helderberg region61. I am also an active participant in the Kogelberg Marine Working Group, which is dedicated to discussing and implementing conservation management initiatives in the Kogelberg region62.\n61 See most recent invitation to participate in a capacity building initiative62 Invitation quarterly Kogelberg Marine Working Group meetingSince 2017, I have been training students and budding scientists from previously disadvantaged Higher Education Institutions (HEIs) and NRF National Facilities. This includes teaching R courses at the University of Zululand, Walter Sisulu University, SAIAB, and SAEON. In the process of these collaborations, I regularly engage with young academics freshly appointed to their positions at these universities. The objective is to foster research proficiency and academic confidence, thereby amplifying their potential to positively influence subsequent generations of graduates.\nI have recently received and accepted an invitation from OceanHub Africa to spearhead a project at the Ocean Hackathon as a Challenge Owner. This platform allows me to interact with professional coders and jointly work towards data-driven solutions to address certain marine conservation and management challenges in the region63.\n63 See invitation letter"
  },
  {
    "objectID": "pages/case_for_promotion.html#covid-19-environmental-research-group",
    "href": "pages/case_for_promotion.html#covid-19-environmental-research-group",
    "title": "Ad Personam Promotion 2023",
    "section": "4.3.6. CoVID-19 Environmental Research Group",
    "text": "4.3.6. CoVID-19 Environmental Research Group\nDuring the first year of CoVID-19 I was part of the CoVID-19 Environmental reference Group (CERG) which aimed to establish the link between seasonality and the prevalence and spread of CoVID-19 in developing countries. An output of the work is the paper Smit et al. (2020).64\n64 Smit et al (2020) about CoVID-19"
  },
  {
    "objectID": "BDC334/Class_tests.html",
    "href": "BDC334/Class_tests.html",
    "title": "Class tests",
    "section": "",
    "text": "Discuss the unimodal species distribution model, and describe how this model can explain the structuring of communities along environmental gradients. In your discussion, also talk about β-diversity.\n\n\nThe unimodal model is an idealised species response curve where a species has only one mode of abundance—i.e. one locality on the landscape where conditions are optimal and it is most abundant (i.e. the fewest ecophysiological and ecological stressors are present there). If any aspect of the environment is suboptimal (greater or lesser than the optimum), the species will perform more poorly and have a lower abundance (a lower fitness). The unimodal model in the most basic sense can be seen as a Gaussian curve, and it offers a convenient heuristic tool for understanding how species can become structured along environmental gradients. Multiple unimodal distributions are often visualised as a coenocline—a graphical display of all species response curves, which shows how a species’ fitness is affected by any one of a multitude of environmental variables e.g. pH in Figure 1.\n\n\n\nA coenocline.\n\n\n\\(\\beta\\)-diversity is a concept that describes how species assemblages (communities) measured within the ecosystem of interest vary from place to place, e.g. along the various transects or among the quadrats used to sample the ecosystem. \\(\\beta\\)-diversity can result from the gradual change in environmental characteristics along gradients. This can be clearly seen in a coenocline, where the modal centre of distribution of many species is arranged at different positions along an environmental gradient. See Figure 1. As Species A becomes less abundant when its physical distance away from the place on the landscape which is most conducive to its fitness increases, so it is replaced by Species B at a distant location where its environmental conditions are optimal. And so on with all the other species along the length of the gradient. This process is called environmental filtering, which results in a decrease in similarity as the distance between sites increases—sometimes this is called the niche difference model. Such patterns are typically visible along steep environmental gradients such as elevation slopes (mountains), latitude, or depth in the ocean, to name only three. It is also the dominant mechanism underlying island biogeography."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-1",
    "href": "BDC334/Class_tests.html#question-1",
    "title": "Class tests",
    "section": "",
    "text": "Discuss the unimodal species distribution model, and describe how this model can explain the structuring of communities along environmental gradients. In your discussion, also talk about β-diversity.\n\n\nThe unimodal model is an idealised species response curve where a species has only one mode of abundance—i.e. one locality on the landscape where conditions are optimal and it is most abundant (i.e. the fewest ecophysiological and ecological stressors are present there). If any aspect of the environment is suboptimal (greater or lesser than the optimum), the species will perform more poorly and have a lower abundance (a lower fitness). The unimodal model in the most basic sense can be seen as a Gaussian curve, and it offers a convenient heuristic tool for understanding how species can become structured along environmental gradients. Multiple unimodal distributions are often visualised as a coenocline—a graphical display of all species response curves, which shows how a species’ fitness is affected by any one of a multitude of environmental variables e.g. pH in Figure 1.\n\n\n\nA coenocline.\n\n\n\\(\\beta\\)-diversity is a concept that describes how species assemblages (communities) measured within the ecosystem of interest vary from place to place, e.g. along the various transects or among the quadrats used to sample the ecosystem. \\(\\beta\\)-diversity can result from the gradual change in environmental characteristics along gradients. This can be clearly seen in a coenocline, where the modal centre of distribution of many species is arranged at different positions along an environmental gradient. See Figure 1. As Species A becomes less abundant when its physical distance away from the place on the landscape which is most conducive to its fitness increases, so it is replaced by Species B at a distant location where its environmental conditions are optimal. And so on with all the other species along the length of the gradient. This process is called environmental filtering, which results in a decrease in similarity as the distance between sites increases—sometimes this is called the niche difference model. Such patterns are typically visible along steep environmental gradients such as elevation slopes (mountains), latitude, or depth in the ocean, to name only three. It is also the dominant mechanism underlying island biogeography."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-2",
    "href": "BDC334/Class_tests.html#question-2",
    "title": "Class tests",
    "section": "Question 2",
    "text": "Question 2\nUsing a clear example that you can easily relate to, discuss the concept of ‘ecological infrastructure.’ In your explanation, mention other (i.e., in addition to the ‘infrastructural services’) ecological services this example ecosystem offers and any other benefits that people might derive from its existence and well-being. In your discussion, explain how the ecological infrastructure works (what it does and how) in a properly functioning ecosystem and, if people destroyed it, how we might replicate its service.\n\nAnswer\n\nWetlands as ecological infrastructure\nWhat is ecological infrastructure? Ecological infrastructure is natural ecosystems that provide services beneficial to people. These services would, in the absence of ecological infrastructure, have to be provided by engineering solutions.\nBenefits people derive from wetlands People tend to develop settlements, towns and cities in low-lying areas such as flood plains around estuaries. These areas are prone to periodic rising water levels, and recently they are also more and more being impacted by extreme floods (associated with climate change). Healthy flood plains often comprise wetlands, which are habitats occupied by dense emergent macrophytes along the edges of estuaries and flood plains. These systems can provide a buffer to rising water levels, and they may reduce the flow rate of water. People can benefit from intact wetlands as this buffer zone provides a level of protection to built structures in the vicinity of the estuaries. Wetlands also purify the water (water filtration removes excessive N, P and POM), which makes for an environment that is more supportive of good human health (fewer water borne diseases and pollutants which may be a public health concern).\nHowever, often wetlands are destroyed by dredging and then filled in to make area available for occupation by people. In such transformed systems, protection against floods and rising water levels can be provided by constructing engineered systems at great cost. Examples of such engineered systems include breakwaters and levees. These systems, however, do not provide the other services required for maintaining good water quality, and additional engineering solutions, costing yet more tax-payers money, need to be provided. Additionally, downstream natural areas on which people depend will also become increasingly impacted due to the deterioration or loss of wetlands, and engineering solutions cannot mitigate against such consequences.\nThus, ecological infrastructure provide services to people simply by virtue of being maintained in a healthy state. This economic cost of achieving this is virtually non-existent, provided people act responsibly to protect these systems.\nEcological services from wetlands Wetlands provide a complex 3D habitat that provides numerous ecological services to a host of associated fauna and flora. These biotic assemblages benefit from their association with wetlands from the feeding/foraging opportunities provided within the habitat structure, the breeding and nursery grounds wetlands provide, attachment surfaces on the wetland plants and the sediments trapped within, and shelter and hiding opportunities from predators. Wetlands also reduce the flow rate of the water passing through them, and as such the still water within is attractive to some species that are unable to tolerate faster flow rates. Typically, healthy wetlands are active in their cycling (uptake) of N and P, and as such the water quality may be better compared to surrounding areas. This is also true for decreasing the water turbidity due to their filtration services. This makes wetlands ideal environments to some species that are sensitive to pollution. &lt;Many more services are provided by the sediments in wetlands, which offer additional opportunities for enhancing biodiversity in these areas&gt;. Overall, the net effect it that it supports species diversity, i.e. higher biodiversity in landscapes with functional wetlands present compared to areas without wetlands. Higher species diversity also offer many bequest services, and offer a potential source of genetic diversity and materials to assay for important bio-active substances that might be useful to people."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-3",
    "href": "BDC334/Class_tests.html#question-3",
    "title": "Class tests",
    "section": "Question 3",
    "text": "Question 3\nDiscuss the general characteristics of species tables, environment tables, and dissimilarity and distance matrices we can derive from these tables.\n\nAnswer\n\nEnvironmental tables Environmental tables have variables down the columns (headings are the names of the env vars) and the sites run across the columns (row names are the names of the sites), with one site in a row. Different kinds of environmental variables can be contained in the table, as many as the researcher thinks is necessary to explain the patterns in the species tables. In the cells are the quantities of the various environmental variables measured at the different sites. The measurement units may differ between columns, so later, before analysis, these data must be standardised.\nSpecies tables The species tables have as many rows as the number of rows in the environmental table—so, for each site where species are recorded, there will be corresponding measurements of the environmental conditions there. Rows in a species table have the same orientation and meaning as in the environmental table. The columns, however, contain the names of the species recorded at the sites. In the cells is some quantity that reflects something about the species at the sites—it might indicate whether a species is there or not (presence/absence), its relative abundance, or biomass. The way in which the species are quantified must be the same across all columns.\nDissimilarity matrix The dissimilarity matrix is derived from the species table by calculating one of the species dissimilarity indices (Bray-Curtis, Sørensen, Jaccard, etc.). It is square and symmetrical, and the diagonals are zero because they are essentially comparing sites with themselves in respect to the kinds of species and their abundance or presence/absence there. A value of 1 would mean that the sites are completely different from each other—this would be seen in a similarity matrix, which is the inverse of a dissimilarity matrix. Each of the other cells represent the community difference between a pair of sites whose names are present as column or row headers.\nDistance matrix A distance matrix is produced from a standardised environmental table. It is square and symmetrical, and there are as many rows and columns as there are variables in the environmental table. This matrix reflects how similar/dissimilar pairs of sites are with regards to the environmental conditions present there. The interpretation of the diagonal is the same as in dissimilarity matrices."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-4",
    "href": "BDC334/Class_tests.html#question-4",
    "title": "Class tests",
    "section": "Question 4",
    "text": "Question 4\nProvide a short explanation, with examples, for what is meant by this statement:\n“Communities often seem to display very strong structural graduation relative to ‘variables’ such as altitude, latitude, and depth; however, these variables are not the actual drivers of the processes that structure communities.”\n\nAnswer\nAltitude, latitude, and depth serve to indicate the position sites on Earth’s surface. They do not have physical properties associated with them. Species cannot require altitude, latitude, or depth to sustain their physiological needs. They are merely proxy variables for other variables that can affect the physiology of the species occurring there. I am less interested in how beta-diversity (turnover, niche models, unimodal models) works, and more interested in how the proxy relationships might play out. For example, …"
  },
  {
    "objectID": "BDC334/Class_tests.html#question-5",
    "href": "BDC334/Class_tests.html#question-5",
    "title": "Class tests",
    "section": "Question 5",
    "text": "Question 5\nIt is the year 2034 and as a result of a decade of campaigning the South African Green Party has become a real contender to be the runner up behind the populist EFF, which has come into power in South Africa in 2029.\nAs the leader of the Green Party, write an Opinion Piece that outlines the ecological solutions your party has to offer for when (if) it becomes the official opposition to the current ruling party. Your party’s ecological solutions offer the promise of solving many of the socio-economic solutions that face South Africans in the 2030s.\n\nAnswer\nThis is an opinion piece and an expected answer is not available.\nIn this answer I am looking for how ecosystems’ ecological services and goods may be used for the betterment of people, the environment, and the economy. I am not looking for a listing of SA’s problems. I am not looking for way in which budgets can be better spent, or how enforcement can be improved. I am also not really looking for the implementation of renewable energy sources as wind or solar (although that will definitely be part of the solution). We know that hunger needs to be alleviated; people must be educated; we need better farming techniques; developments must be sustainable; and people’s economic freedom ensured. But how? How can we use nature’s solutions to do so?\nWe need to build into the various initiatives a reliance on the country’s natural infrastructure. We can also develop novel, fit-for-purpose ‘ecological’ infrastructure that incorporate many of the principles of natural ecosystems with the same kinds of benefits to people (e.g. roof-top gardens, integrated forming and aquaculture, etc.).\nThe essay must consider these kinds of things."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-6",
    "href": "BDC334/Class_tests.html#question-6",
    "title": "Class tests",
    "section": "Question 6",
    "text": "Question 6\nExplain in a short (1/3 page paragraph) what is meant by ‘environmental distance.’\n\nAnswer\nEnvironmental distance encompasses all the characteristics of a landscape, such as measurements of the variables temperature, water content, soil nutrient concentrations, pH, etc., in a manner that makes it possible to provide a single, integrative metric that informs the researcher how similar or different sites across the landscape are to each other. Environmental distances are typically calculated as Euclidian distances (using the Pythagorean Theorem), but others are available such as Gower’s or Manhattan Distances and can be used for specific needs. In R they can be calculated using the vegdist() function in the vegan package. The calculation results in a pairwise distance matrix, with each cell value containing the environmental distance between a pair of sites. All possible combinations of site pairs are represented in this square matrix. The larger the value between two sites—the distance—the more different sites are with respect to their environmental properties. These distances can be used as explanation for how species communities differ across the landscape, such that sites with large environmental distances between them typically develop very different ecological communities."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-7",
    "href": "BDC334/Class_tests.html#question-7",
    "title": "Class tests",
    "section": "Question 7",
    "text": "Question 7\nExplain how the data in the site-by-species matrix can be transformed into species-area curves. What are species area curves, and what explains their characteristic shape? What is the purpose of these curves?\n\nAnswer\nTaken mostly directly from the online resource.\nSpecies accumulation curves (species area relationships, SAR) try and estimate the number of unseen species. These curves can be used to predict and compare changes in diversity over increasing spatial extent. Within an ecosystem type, one would expect that more and more species would be added (accumulates) as the number of sampled sites increases (i.e. extent increases). This continues to a point where no more new species are added as the number of sampled sites continues to increase (i.e. the curve plateaus). It plateaus because if a homogeneous landscape is comprehensively sampled, there will be a point beyond which no new species will be found as we sample even more sites.\nSpecies accumulation curves, as the name suggests, works by adding (accumulation or collecting) more and more sites along \\(x\\) and counting the number of species along \\(y\\) each time a new site is added. In the community matrix (the sites × species table), we can do this by successively adding more rows to the curve (seen along the \\(x\\)-axis). In other words, we plot on \\(y\\) the number of species associated with 1 site (the site on \\(x\\)), then we plot the number of species associated with 2 sites (the sum of the number of species in Site 1 and Site 2), then the number of species in Sites 1, 2, and 3. Etc. We do this until the cumulative sum of the species in all sites has been plotted in this manner. Typically some randomisation procedure is involved (the order in which sites are added up is randomised)."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-8",
    "href": "BDC334/Class_tests.html#question-8",
    "title": "Class tests",
    "section": "Question 8",
    "text": "Question 8\nUsing South African examples, discuss the principle of distance decay of similarity in biogeography and ecology.\n\nAnswer\nTo follow tomorrow (I’m tired now)."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-9",
    "href": "BDC334/Class_tests.html#question-9",
    "title": "Class tests",
    "section": "Question 9",
    "text": "Question 9\nPlease refer to Figure 1: \n\n\n\nAn environmental distance matrix.\n\n\n\nTo graphically represent distance decay, we typically plot the data in the first column or first row (they are the same) of an environmental distance matrix. Why this row/column? What is unique about the first row/column? [3]\nHow does the information in the first row/column differ from that in the subdiagonal? [3]\nWhat information is contained in any other cell in the environmental distance matrix? [2]\nWhat values are in the blanks down the diagonal? Why are these values what they are? [2]\n\n\nAnswer\n\nLooking down the first column, the environmental distance tends to increase the further a site is from Site 1. This is because sites further away from the origin (Site 1) tend to become increasingly dissimilar in terms of their environmental conditions as a host of drivers impact on (e.g. in the Doubs data) the water quality variables—–e.g. near the terminus of the river several pollutants will have perturbed the system (flatter slopes are more conducive to polluting human developments). Typically the increasing environmental distance that develops further away from the origin can directly be attributed to a few very influential variables; again, in the Doubs data, it is the variables nitrate, ammonium, flow rate, and biological oxygen demand that primarily affect the trend in environmental distance. At the source, there are pristine conditions (low DIN and low BOD) and near the terminus sites are polluted. Similar explanations to this one can be developed for a host of environmental gradients (e.g. along the coastline of SA where there is a temperature gradient; across the country along the rainfall gradient; with altitude; with depth; etc.). Any of these can be used as examples.\nWhereas the diagonal compares a site with itself, the subdiagonal (the diagonal row just one up or down from the diagonal filled with zeroes) captures the difference in environmental conditions (environmental distance) between adjoining sites (Site 1 vs Site 2, Site 2 vs Site 3, Site 3 vs Site 4, etc.). These changes are far more gradual than along the first row or down the first column. This is because the physical distance in geographical space is quite small for sites that are positioned next to one-another, and so too will be the environmental distance. Plotting these on a graph with environmental distance on \\(y\\) and the adjacent site pairs on \\(x\\) will generally yield a flat(-ish) line.\nAny other cell simply compares any arbitrary site with any other in terms of the difference in environmental conditions between them. This environmental distance will also be (generally) quite closely related to the physical geographical distance (or altitude, depth, etc.) between the sites.\nThe ‘blanks’ are actually zeroes, which you would get if one would compare a site with itself. There is no difference between a site and itself, so hence no environmental difference between them."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-10",
    "href": "BDC334/Class_tests.html#question-10",
    "title": "Class tests",
    "section": "Question 10",
    "text": "Question 10\n\nGiven a set of environmental data (e.g. pH, temperature, light, total N concentration, conductivity), what is the first step to follow prior to calculating environmental distance? Why is this necessary? [3]\nProvide an equation for how you would accomplish this first step. [2]\nWhat is the name of the equation / procedure to follow in the calculation of ‘environmental distance’? [1]\nDescribe the principle of ‘environmental distance’. [9]\n\n\nAnswer\n\nThe first step would be to standardise the data. This is necessary because the different environmental variables are represented by different measurement scales (units). So, to prevent those with the largest magnitude (e.g. altitude, which is measured in 100s or 1000s of meters) to become the dominant ‘signal’ in the overall response when measured alongside something like temperature (10s of degrees Celsius), they have to be adjusted to comparables scales.\nStandardisation involves calculating the mean of a variable, \\(x\\), and then subtracting this mean from each observation, \\(x_{i}\\). This value is then divided by the standard deviation of \\(x\\). So, something like \\(x_{i} - \\bar{x} / \\sigma_x\\).\nTheorem of Pythagoras, or Euclidian distance.\nEnvironmental distance encompasses all the characteristics of a landscape, such as measurements of the variables temperature, water content, soil nutrient concentrations, pH, etc., in a manner that makes it possible to provide a single, integrative metric that informs the researcher how similar or different sites across the landscape are to each other. Environmental distances are typically calculated as Euclidian distances (using the Pythagorean Theorem), but others are available such as Gower’s or Manhattan Distances and can be used for specific needs. In R they can be calculated using the vegdist() function in the vegan package. The calculation results in a pairwise distance matrix, with each cell value containing the environmental distance between a pair of sites. All possible combinations of site pairs are represented in this square matrix. The larger the value between two sites—the distance—the more different sites are with respect to their environmental properties. These distances can be used as explanation for how species communities differ across the landscape, such that sites with large environmental distances between them typically develop very different ecological communities."
  },
  {
    "objectID": "BDC334/Class_tests.html#question-11",
    "href": "BDC334/Class_tests.html#question-11",
    "title": "Class tests",
    "section": "Question 11",
    "text": "Question 11\nWhat makes macroecology different from the traditional view of ecology?\n\nAnswer\nMacroecology is an all-encompassing view of ecology, which seeks to define the geographical patterns and processes in biodiversity across all spatial scales, from local to global, across time scales from years to millennia, and across all taxonomic hierarchies (from genetic variability within species, up to major higher level taxa, such as families and orders). It attempts to arrive a unifying theory for ecology across all of these scales—e.g. one that can explain all patterns in structure and functioning from microbes to blue whales. Most importantly, perhaps, is that it attempts to offer mechanistic explanations for these patterns. At the heart of all explanation is also deep insights stemming from understanding evolution (facilitated by the growth of phylogenetic datasets—see below).\nThis is a modern development of ecology, whereas up to 20 years ago the focus has been mostly on populations (the dynamics of individuals of one species interacting amongst each other and with their environment) and communities (collections of multiple populations, and how they interact with each other and their environment, and how this affects the structure and dynamics of ecosystems).\nOn a basic data analytical level, population ecology, community ecology, and macroecology all share the same approach as far as the underlying data are concerned. We start with tables of species and environmental conditions (along columns) at a selection of sites (along rows), and these are converted to distance and dissimilarity matrices. From here analyses can show insights into how biodiversity is structured, e.g. species-abundance distributions, occupancy-abundancy curves, species-area curves, distance decay curves, and gradient analyses. In the last decade, modern developments in statistical approaches have contributed towards the development of macroecology, because of the growth of hypotheses-driven multivariate statistical approaches geared to test for the presence of one or several ecological hypotheses—this was not seen in population and community ecology so much. Contributing towards the growth of macroecology and the underlying statistical approaches, the deluge of new data across vast scales has also necessitated deeper analytical development, i.e. leveraging statistical tools and also the power of modern computing infrastructure. These modern approaches are also bringing into the fold of combined computations based on species and environmental tables also data on the phylogenetic relationships amongst organisms (and hence this brings the context of evolution)."
  },
  {
    "objectID": "BDC334/wikis.html",
    "href": "BDC334/wikis.html",
    "title": "The Wiki Assignment",
    "section": "",
    "text": "Wikis are collaborative web platforms that allow many users to co-create, edit, and organise content collectively. Wikis were originally made popular by Wikipedia, and have since become embedded in academia. They are based on a system of the markdown language that allows for easy formatting and linking of content. I’ll discuss a few of the benefits at the start of the assignment.\n\n\nTo access the Wiki software, you need to be logged in to iKamva. Once you are logged in, you can access the Wiki tool from the left-hand menu. I have already set up much of what you need there, and all you need to do is navigate via the ‘Macroecology Wiki’ link to the list of topics. At present they are all empty (as indicated by the ‘?’ at the end of the titles), but you can click on the title (which is the link) to create a new page. Once you have made a new page, added some text, and saved it, you can edit any of the existing pages also from under the ‘Macroecology Wiki’ link.\n\n\n\nOnce you started to contribute portions of text to the Wiki, you will be able to see the changes that you and others make to your work. The editorial changes that others make to your work will help you see how others interpret your work, and how they might improve it. You can then accept or reject these changes, and you can also make changes to the work of others. You can also ask questions about the changes that others make, and you can discuss the changes that you make to others’ work. These are a very powerful learning tools, and I hope that you will use it to its full potential.\nOnce you start editing, I will be able to see the editorial contributions you make to your peers’ Wiki pages. In fact, I will use this facility to allocate marks that will capture how thoroughly and consistently you participate in collaborative editing.\n\n\n\nDuring this project, two things are expected of you to develop a successful collaboration on your Wiki essays:\n\nthat you contribute sections of text to the Wiki, and\nthat you edit the work of others, both within your own essay topic and within that of others.\n\nThis collaborative editing will serve three purposes:\n\nit will improve the language and readability of your own and classmates’ Wiki pages,\nit will raise concerns around the factual, structural, logical, contextual, and content of your own and your colleagues’ Wiki pages, and in this way promote continual editing so that you may submit a polished product at the end of Term 3, and\nit will form the basis of the learning experience itself.\n\nThis collaborative editing will enhance your personal understanding of the breadth of topics that will form part of the Biogeography and Global Ecology theory section. It will necessitate your interaction with the reading material provided (the PDFs of important papers, and other which you will find, use, cite, and upload for others to read) at a deep level.\n\n\n\nEach of the Wiki pages that you create will be open to examination (tests and exams), so it is imperative that all of you read and comment on each other’s work. This will ensure that you have a broad understanding of the topics that will be covered in the course, and that you are able to answer questions on them in the tests and exams.\nMost practical time slots are available for this project (4 remaining weeks, 6 hours per week, and the contributions of 3 team members make for approximately 72 hours of continuous editing), so use this time fully and wisely. Articles must be well researched, referenced (if you cite facts), thorough, in-depth, and coherent, with clear aims and objectives spelt out near the start. I will post more writing tips here as we progress, but for now the various Wikipedia help pages will provide sufficient introductory material to get you started.\nPlagiarism will not be tolerated at all, and the entire group will receive 0% for their effort.\nHow to use it is self-explanatory (after you know what markdown iKamva’s Wiki uses), but I will provide a brief overview of the topics to guide your essays. You can also find help on how to use Wikis on iKamva."
  },
  {
    "objectID": "BDC334/wikis.html#about-wikis",
    "href": "BDC334/wikis.html#about-wikis",
    "title": "The Wiki Assignment",
    "section": "",
    "text": "Wikis are collaborative web platforms that allow many users to co-create, edit, and organise content collectively. Wikis were originally made popular by Wikipedia, and have since become embedded in academia. They are based on a system of the markdown language that allows for easy formatting and linking of content. I’ll discuss a few of the benefits at the start of the assignment.\n\n\nTo access the Wiki software, you need to be logged in to iKamva. Once you are logged in, you can access the Wiki tool from the left-hand menu. I have already set up much of what you need there, and all you need to do is navigate via the ‘Macroecology Wiki’ link to the list of topics. At present they are all empty (as indicated by the ‘?’ at the end of the titles), but you can click on the title (which is the link) to create a new page. Once you have made a new page, added some text, and saved it, you can edit any of the existing pages also from under the ‘Macroecology Wiki’ link.\n\n\n\nOnce you started to contribute portions of text to the Wiki, you will be able to see the changes that you and others make to your work. The editorial changes that others make to your work will help you see how others interpret your work, and how they might improve it. You can then accept or reject these changes, and you can also make changes to the work of others. You can also ask questions about the changes that others make, and you can discuss the changes that you make to others’ work. These are a very powerful learning tools, and I hope that you will use it to its full potential.\nOnce you start editing, I will be able to see the editorial contributions you make to your peers’ Wiki pages. In fact, I will use this facility to allocate marks that will capture how thoroughly and consistently you participate in collaborative editing.\n\n\n\nDuring this project, two things are expected of you to develop a successful collaboration on your Wiki essays:\n\nthat you contribute sections of text to the Wiki, and\nthat you edit the work of others, both within your own essay topic and within that of others.\n\nThis collaborative editing will serve three purposes:\n\nit will improve the language and readability of your own and classmates’ Wiki pages,\nit will raise concerns around the factual, structural, logical, contextual, and content of your own and your colleagues’ Wiki pages, and in this way promote continual editing so that you may submit a polished product at the end of Term 3, and\nit will form the basis of the learning experience itself.\n\nThis collaborative editing will enhance your personal understanding of the breadth of topics that will form part of the Biogeography and Global Ecology theory section. It will necessitate your interaction with the reading material provided (the PDFs of important papers, and other which you will find, use, cite, and upload for others to read) at a deep level.\n\n\n\nEach of the Wiki pages that you create will be open to examination (tests and exams), so it is imperative that all of you read and comment on each other’s work. This will ensure that you have a broad understanding of the topics that will be covered in the course, and that you are able to answer questions on them in the tests and exams.\nMost practical time slots are available for this project (4 remaining weeks, 6 hours per week, and the contributions of 3 team members make for approximately 72 hours of continuous editing), so use this time fully and wisely. Articles must be well researched, referenced (if you cite facts), thorough, in-depth, and coherent, with clear aims and objectives spelt out near the start. I will post more writing tips here as we progress, but for now the various Wikipedia help pages will provide sufficient introductory material to get you started.\nPlagiarism will not be tolerated at all, and the entire group will receive 0% for their effort.\nHow to use it is self-explanatory (after you know what markdown iKamva’s Wiki uses), but I will provide a brief overview of the topics to guide your essays. You can also find help on how to use Wikis on iKamva."
  },
  {
    "objectID": "BDC334/wikis.html#the-topics",
    "href": "BDC334/wikis.html#the-topics",
    "title": "The Wiki Assignment",
    "section": "The Topics",
    "text": "The Topics\nBelow are short overviews for each topic to provide guidance for your wiki essays—they have already been added as link under the ‘Macroecology Wiki’, so find them there. As soon as you have selected a Wiki topic of interest, follow the link and enter your name together with your partners’ names in the ‘Authors’ section. You can then start writing your essay. It is important to be quick in selecting topics so that others do not take the one you want. If you are not quick enough, you can always ask me to add more topics (come with some ideas).\nGroups are also welcome to seek advice from me on how to approach their topics, and I will be available to help you with your research and writing. I will also be available to help you with the editing process, and to provide feedback on your work (to a limited extent—it is yoour work, after all!).\n\nDecoupling Sustainability and Growth: A False Dichotomy or the Key to a Thriving Planet?\n\nCan we make a case for decoupling economic growth from environmental degradation? Or is our future dictated by Malthusian limits? Discuss the concept of decoupling, its feasibility, and implications for global sustainability.\n\nThe Impact of Climate Change on Southern African Species Distribution\n\nInvestigate the specific effects of climate change on species distribution within Southern Africa. Focus on vulnerable ecosystems and endemic species.\n\nClimate Change and Extreme Weather Phenomena\n\nDiscuss how climate change is linked to the increasing frequency and intensity of extreme weather events, such as hurricanes, floods, droughts, storm surges, and wildfire intensity. Delve in their ecological, economic, and social impacts.\n\nUpwelling Ecosystems as Refugia for Biodiversity Threatened by Climate Change\n\nAssess the role of upwelling zones as potential refugia that support biodiversity in the face of climate change by providing stable environmental conditions and abundant resources.\n\nEcologists’ Worldview: Do They Hold a Unique Perspective on Nature and Society?\n\nExplore the philosophical underpinnings of ecology and how they shape ecologists’ perspectives on nature, society, and the environment. How do ecologists view the world differently from other disciplines or society around us?\n\nConservation Biology: Unpacking Its Colonial Roots and Modern Implications\n\nExamine the historical context of conservation biology, its possible colonial origins, and the implications for modern conservation efforts, including the role of indigenous knowledge and community-based conservation. Is conservation biology a Western-centric field and does it have a something to offer to the Global South?\n\nUniversal Truths: Can Science Bridge Cultures and Continents?\n\nDiscuss the role of science in bridging cultural divides and fostering international collaboration to address global challenges, such as climate change and biodiversity loss. Is science in South Africa different from science in the USA?\n\nDevelopment vs. Climate Responsibility: Navigating the Global South’s Quest for Growth Amid Climate Challenges\n\nAnalyse the tensions between development aspirations and climate responsibilities in the Global South and explore the trade-offs, challenges, and opportunities for sustainable development in the face of climate change.\n\nBiogeographical Patterns in the Deep Ocean\n\nExplore the unique biogeographical patterns found in the deep ocean, highlighting the adaptations of deep-sea species and the challenges of studying these environments.\n\nThe Global Nitrogen Cycle and Consequences for Biodiversity\n\nHow have human activities altered the global nitrogen cycle? What are the impacts on ecosystems, biodiversity, and ecological processes?\n\nPleistocene Refugia: Past, Present, and Future\n\nAnalyse the concept of Pleistocene refugia and their role in shaping current biodiversity patterns. Explore how these areas may serve as refuges under future climate change scenarios.\n\nDe-extinction\n\nDiscuss the scientific, ethical, and ecological implications of de-extinction, the process of reviving extinct species, and its potential impact on conservation efforts.\n\nBioengineering for Conservation\n\nExplore how bioengineering technologies, such as genetic modification, can be used to address conservation challenges and enhance the resilience of species to environmental changes.\n\nGeoengineering to Combat Climate Change\n\nWhat potential do geoengineering strategies have to mitigate climate change? Focus on their scientific basis, feasibility, and environmental risks.\n\nAttribution of Climate Change to Human Influence\n\nInvestigate the evidence linking human activities to climate change. What methodologies are used to attribute specific climate impacts to anthropogenic causes?\n\nIndigenous Knowledge and Conservation Practices\n\nDiscuss the role of indigenous knowledge in conservation efforts, highlighting successful practices and potential conflicts with modern scientific approaches.\n\nRenewable Energy Development and Wildlife Conservation\n\nDiscuss the environmental trade-offs associated with renewable energy development, such as wind and solar power, and their impact on wildlife and ecosystems.\n\nDeep-Sea Mining\n\nExplore the emerging industry of deep-sea mining, focusing on its potential environmental impacts and the challenges of balancing resource extraction with marine conservation.\n\nEnvironmental Justice\n\nExamine the concept of environmental justice, addressing how environmental policies and practices can disproportionately affect marginalized communities and ecosystems.\n\nThe Role of Citizen Science in Biodiversity Conservation\n\nExplore the contributions of citizen science to biodiversity monitoring, research, and conservation efforts, highlighting successful projects and challenges."
  },
  {
    "objectID": "BDC334/02a-r_rstudio.html",
    "href": "BDC334/02a-r_rstudio.html",
    "title": "Lab 2a. R & RStudio",
    "section": "",
    "text": "This Lab Accompanies the Following Lecture\n\n\n\n\nLecture 2b: Metrics of Environmental and Species Diversity",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2a. R & RStudio"
    ]
  },
  {
    "objectID": "BDC334/02a-r_rstudio.html#download-and-install-r-and-rstudio",
    "href": "BDC334/02a-r_rstudio.html#download-and-install-r-and-rstudio",
    "title": "Lab 2a. R & RStudio",
    "section": "Download and Install R and RStudio",
    "text": "Download and Install R and RStudio\nR and RStudio are separate programs and need to be installed individually. Follow the instructions on the Posit website.\nRStudio can be seen as the vehicle body, seats, dashboard, and all other bells and whistles you might find in a car. R is the engine. RStudio does not work without R. The analyses, graphics, etc. are done with R (running inside RStudio) and not RStudio.\nFor those of you who will be using your personal laptops, please ensure that you install R and RStudio before the Lab on Monday afternoon. If you have any issues with the installation, please let us know so that we can assist you. We will continue with the instructions below during the Lab session once you have installed R and RStudio.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2a. R & RStudio"
    ]
  },
  {
    "objectID": "BDC334/02a-r_rstudio.html#setting-up-the-workspace",
    "href": "BDC334/02a-r_rstudio.html#setting-up-the-workspace",
    "title": "Lab 2a. R & RStudio",
    "section": "Setting up the Workspace",
    "text": "Setting up the Workspace\nGeneral Settings\nBefore we start using RStudio (which is a code editor and environment that runs R) let’s first set it up properly. Find the ‘Tools’ (‘Preferences’) menu item, navigate to ‘Global Options’ (‘Code Editing’) and select the tick boxes as shown in Figure 1 below.\n\n\n\n\n\nFigure 1: RStudio preferences.\n\n\nCustomising Appearance\nRStudio is highly customisable. Under the Appearance tab under ‘Tools’/‘Global Options’ you can see all of the different themes that come with RStudio. We recommend choosing a theme with a black background (e.g. Chaos) as this will be easier on your eyes and your computer. It is also good to choose a theme with a sufficient amount of contrast between the different colours used to denote different types of objects/values in your code. Refer to Figure 2.\n\n\n\n\n\nFigure 2: Appearance settings.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2a. R & RStudio"
    ]
  },
  {
    "objectID": "BDC334/02a-r_rstudio.html#the-rproject",
    "href": "BDC334/02a-r_rstudio.html#the-rproject",
    "title": "Lab 2a. R & RStudio",
    "section": "The Rproject",
    "text": "The Rproject\nA very nifty way of managing workflow in RStudio is through the built-in functionality of the Rproject. We do not need to install any packages or change any settings to use these. Creating a new project is a very simple task, as well. For this course we will be using the Intro_R_Workshop.Rproj file you downloaded with the course material so that we are all running identical projects. This will prevent a lot of issues by ensuring we are doing things by the same standard. Better yet, an Rproject integrates seamlessly into version control software (e.g. GitHub) and allows for instant world class collaboration on any research project. To initialise the ‘Intro_R_Workshop’ project on your machine please find where you saved Intro_R_Workshop.Rproj file and click on it. We will cover the concepts and benefits of an Rproject more as we move through the course.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2a. R & RStudio"
    ]
  },
  {
    "objectID": "BDC334/02a-r_rstudio.html#installing-packages",
    "href": "BDC334/02a-r_rstudio.html#installing-packages",
    "title": "Lab 2a. R & RStudio",
    "section": "Installing Packages",
    "text": "Installing Packages\nThe most common functions used in R are contained within the base package; this makes R useful ‘out of the box.’ However, there is extensive additional functionality that is being expanded all the time through the use of packages. Packages are simply collections of code called functions that automate complex mathematical or statistical tasks. One of the most useful features of R is that users are continuously developing new packages and making them available for free. You can find a comprehensive list of available packages on the CRAN website. There are currently (2022-04-29) 18907 packages available for R!\nIf the thought of searching for and finding R packages is daunting, a good place to start is the R Task View page. This page curates collections of packages for general tasks you might encounter, such as Experimental Design, Meta-Analysis, or Multivariate Analysis. Go and have a look for yourself, you might be surprised to find a good explanation of what you need.\nAfter clicking ‘Tools’/‘Install Packages’, type in the package name tidyverse in the ‘Packages’ text box (note that it is case sensitive) and select the Install button. The Console will run the code needed to install the package, and then provide some commentary on the installation of the package and any of its dependencies (i.e., other R packages needed to run the required package).\nThe installation process makes sure that the functions within the packages contained within the tidyverse are now available on your computer, but to avoid potential conflicts in the names of functions, it will not load these automatically. To make R ‘know’ about these functions in a particular session, you need either to load the package via ticking the checkbox for that package in the Packages tab, or execute:\n\nlibrary(tidyverse)\n\nTo prepare ourselves for the week ahead, let us also install the following packages. Here I demonstate the command line approach to achieve the same thing that can be done via the menu:\n\ninstall.packages(\"rmarkdown\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"bindrcpp\")\ninstall.packages(\"ggpubr\")\ninstall.packages(\"magrittr\")\ninstall.packages(\"boot\")\ninstall.packages(\"ggsn\")\ninstall.packages(\"scales\")\ninstall.packages(\"maps\")\ninstall.packages(\"ggmap\")\ninstall.packages(\"lubridate\")\ninstall.packages(\"bindrcpp\")\n\nSince we will develop the habit of doing all of our analyses from R scripts, it is best practice to simply list all of the libraries to be loaded right at the start of your script. Comments may be used to remind your future-self (to quote Hadley Wickham) what those packages are for.\n\n\n\n\n\n\nCopying code from RStudio\n\n\n\nHere you saw RStudio execute the R code needed to install (using install.packages()) and load (using library()) the package, so if you want to include these in one of your programs, just copy the text it executes. Note that you need only install the current version of a package once, but it needs to be loaded at the beginning of each R session.\n\n\n\n\n\n\n\n\nLab 2\n\n\n\n\nWhy is it best practice to include packages you use in your R program explicitly?",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2a. R & RStudio"
    ]
  },
  {
    "objectID": "BDC334/02a-r_rstudio.html#the-panes-of-rstudio",
    "href": "BDC334/02a-r_rstudio.html#the-panes-of-rstudio",
    "title": "Lab 2a. R & RStudio",
    "section": "The Panes of RStudio",
    "text": "The Panes of RStudio\nRStudio has four main panes each in a quadrant of your screen ((RStudio_panes?)): Source Editor 🅐, Console 🅑, Workspace Browser 🅒 (and History), and Plots 🅓 (and Files, Packages, Help). These can also be adjusted under the ‘Preferences’ menu. Note that there might be subtle differences between RStudio installations on different operating systems. We will discuss each of the panes in turn.\n\n\n\n\n\nFigure 3: RStudio window panes.\n\n\nSource Editor 🅐\nGenerally we will want to write programs longer than a few lines. The Source Editor can help you open, edit and execute these programs. Let us open a simple program:\n\nUse Windows Explorer (Finder on Mac) and navigate to the file BONUS/the_new_age.R.\nNow make RStudio the default application to open .R files (right click on the file Name and set RStudio to open it as the default if it isn’t already)\nNow double click on the file – this will open it in RStudio in the Source Editor in the top left pane.\n\nNote .R files are simply standard text files and can be created in any text editor and saved with a .R (or .r) extension, but the Source editor in RStudio has the advantage of providing syntax highlighting, code completion, and smart indentation. You can see the different colours for numbers and there is also highlighting to help you count brackets (click your cursor next to a bracket and push the right arrow and you will see its partner bracket highlighted). We can execute R code directly from the Source Editor. Try the following (for Windows machines; for Macs replace Ctrl with Cmd):\n\nExecute a single line (Run icon or Ctrl+Enter). Note that the cursor can be anywhere on the line and one does not need to highlight anything — do this for the code on line 2\nExecute multiple lines (Highlight lines with the cursor, then Run icon or Ctrl+Enter) — do this for line 3 to 6\nExecute the whole script (Source icon or Ctrl+Shift+Enter)\n\nNow, try changing the x and/or y axis labels on line 18 and re-run the script.\nNow let us save the program in the Source Editor by clicking on the file symbol (note that the file symbol is greyed out when the file has not been changed since it was last saved).\nAt this point, it might be worth thinking a bit about what the program is doing. R requires one to think about what you are doing, not simply clicking buttons like in some other software systems which shall remain nameless for now… Scripts execute sequentially from top to bottom. Try and work out what each line of the program is doing and discuss it with your neighbour. Note, if you get stuck, try using R’s help system; accessing the help system is especially easy within RStudio — see if you can figure out how to use that too.\n\n\n\n\n\n\nThe #\n\n\n\nThe hash (#) tells R not to run any of the text on that line to the right of the symbol. This is the standard way of commenting R code; it is VERY good practice to comment in detail so that you can understand later what you have done.\n\n\nConsole 🅑\nThis is where you can type code that executes immediately. This is also known as the command line. Throughout the notes, we will represent code for you to execute in R as a different font.\n\n\n\n\n\n\nType it in!\n\n\n\nAlthough it may appear that one could copy code from this PDF into the Console, you really shouldn’t. The first reason is that you might unwittingly copy invisible PDF formatting errors into R, which will make the code fail. But more importantly, typing code into the Console yourself gives you the practice you need, and allows you to make (and correct) your own errors. This is an invaluable way of learning and taking shortcuts now will only hurt you in the long run.\n\n\nEntering code in the command line is intuitive and easy. For example, we can use R as a calculator by typing into the Console (and pressing Enter after each line). Note that the output for every line of calculation (e.g. 6 * 3) is indicated by R&gt;, as we see here:\n\n6 * 3\n\n[1] 18\n\n\nR&gt; [1] 18\n\n5 + 4\n\n[1] 9\n\n\nR&gt; [1] 9\n\n2 ^ 3\n\n[1] 8\n\n\nR&gt; [1] 8\nNote that spaces are optional around simple calculations.\nWe can also use the assignment operator &lt;- to assign any calculation to a variable so we can access it later (the = sign would work, too, but it’s bad practice to use it… and we’ll talk about this as we go):\n\na &lt;- 2\nb &lt;- 7\na + b\n\n[1] 9\n\n\nR&gt; [1] 9\nTo type the assignment operator (&lt;-) push the following two keys together: alt -. There are many keyboard shortcuts in R and we will introduce them as we go along.\nSpaces are also optional around assignment operators. It is good practice to use single spaces in your R scripts, and the alt - shortcut will do this for you automagically. Spaces are not only there to make the code more readable to the human eye, but also to the machine. Try this:\n\nd&lt;-2\nd &lt; -2\n\n[1] FALSE\n\n\nNote that the first line of code assigns d a value of 2, whereas the second statement asks R whether this variable has a value less than 2. When asked, it responds with FALSE. If we hadn’t used spaces, how would R have known what we meant?\nAnother important question here is, is R case sensitive? Is A the same as a? Figure out a way to check for yourself.\n\n\n\n\n\n\nLab 2 (continue)\n\n\n\n\nWhat are the values after each hashed statement in the following? Use the RStudio Console to determine these values:\n\n\n\n\nmass &lt;- 48\nage &lt;- 78\nmass &lt;- mass * 2.0 # mass? \nage &lt;- age - 17 # age? m\nmass_index &lt;- mass / age # mass_index?\n\n\n\n\n\n\n\nLab 2 (continue)\n\n\n\n\nUse R to calculate some simple mathematical expressions entered. Assign the value of 40 to x and assign the value of 23 to y. Make z the value of x - y Display z in the console.\n\n\n\nWe can create a vector in R by using the combine c() function:\n\napples &lt;- c(5.3, 3.8, 4.5)\n\nA vector is a one-dimensional array (i.e., a list of numbers), and this is the simplest form of data used in R (you can think of a single value in R as just a very short vector). We’ll talk about more complex (and therefore more powerful) types of data structures as we go along.\nIf you want to display the value of apples type:\n\napples\n\n[1] 5.3 3.8 4.5\n\n\nR&gt; [1] 5.3 3.8 4.5\nFinally, there are default functions in R for nearly all basic statistical analyses, including mean() and sd() (standard deviation):\n\nmean(apples)\n\n[1] 4.533333\n\n\nR&gt; [1] 4.533333\n\nsd(apples)\n\n[1] 0.7505553\n\n\nR&gt; [1] 0.7505553\n\n\n\n\n\n\nVariable names\n\n\n\nIt is best not to use c as the name of a value or array. Why? What other words might not be good to use?\n\n\nOr try this:\n\nround(sd(apples), 2)\n\n[1] 0.75\n\n\nR&gt; [1] 0.75\n\n\n\n\n\n\nLab 2 (continue)\n\n\n\n\nWhat did we do above? What can you conclude from those functions?\n\n(Lab 2 continues in Lab 2b.)\n\n\nRStudio supports the automatic completion of code using the Tab key. For example, type the three letters app and then the Tab key. What happens?\nThe code completion feature also provides brief in-line help for functions whenever possible. For example, type mean() and press the Tab key.\nThe RStudio Console automagically maintains a ‘history’ so that you can retrieve previous commands, a bit like your Internet browser or Google. On a blank line in the Console, press the up arrow, and see what happens.\nIf you wish to review a list of your recent commands and then select a command from this list you can use Ctrl+Up to review the list (Cmd+Up on the Mac). If you prefer a ‘bird’s eye’ overview of the R command history, you may also use the RStudio History pane (see below).\nThe Console title bar has a few useful features:\n\nIt displays the current R working directory (more on this later)\nIt provides the ability to interrupt R during a long computation (a stop sign will appear whilst code is running)\nIt allows you to minimise and maximise the Console in relation to the Source pane using the buttons at the top-right or by double-clicking the title bar)\nEnvironment and History Panes 🅒\nThe Environment pane is very useful as it shows you what objects (i.e., dataframes, arrays, values and functions) you have in your environment (workspace). You can see the values for objects with a single value and for those that are longer R will tell you their class. When you have data in your environment that have two dimensions (rows and columns) you may click on them and they will appear in the Source Editor pane like a spreadsheet.\nYou can then go back to your program in the Source Editor by clicking its tab or closing the tab for the object you opened. Also in the Environment is the History tab, where you can see all of the code executed for the session. If you double-click a line or highlight a block of lines and then double-click those, you can send it to the Console (i.e., run them).\nTyping the following into the Console will list everything you’ve loaded into the Environment:\n\nls()\n\n[1] \"a\"          \"age\"        \"apples\"     \"b\"          \"d\"         \n[6] \"mass\"       \"mass_index\"\n\n\nR&gt; [1] \"a\"        \"apples\"   \"b\"        \"pkgs_lst\" \"url\"\nWhat do we have loaded into our environment? Did all of these objects come from one script, or more than one? How can we tell where an object was generated?\nFiles, Plots, Packages, Help, and Viewer Panes 🅓\nThe last pane has a number of different tabs. The Files tab has a navigable file manager, just like the file system on your operating system. The Plot tab is where graphics you create will appear. The Packages tab shows you the packages that are installed and those that can be installed (more on this just now). The Help tab allows you to search the R documentation for help and is where the help appears when you ask for it from the Console.\nMethods of getting help from the Console include…\n\n?mean\n\n…or:\n\nhelp(mean)\n\nWe will go into this in more detail in the next session.\nTo reproduced Figure 4 in the Plot tab, simply copy and paste the following code into the Console:\n\nlibrary(tidyverse)\nx &lt;- seq(0, 2, by = 0.01)\ny &lt;- 2 * sin(2 * pi * (x - 1/4))\nggplot() +\n  geom_point(aes(x = x, y = y), shape = 21, col = \"indianred\", fill = \"steelblue\")+\n  theme_linedraw()\n\n\n\n\n\n\n\nFigure 4: An easy figure.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2a. R & RStudio"
    ]
  },
  {
    "objectID": "BDC334/BDC334_index.html",
    "href": "BDC334/BDC334_index.html",
    "title": "Biogeography & Global Ecology",
    "section": "",
    "text": "Ecosystems form the foundation of life on Earth, encompassing complex interactions between living organisms and their physical environment. This module, BDC334, will explore the fundamental concepts, characteristics, and driving forces that shape and maintain ecosystems across our planet.\n\n\n\n\n\nReuseCC BY-NC-SA 4.0CitationBibTeX citation:@online{j._smit2024,\n  author = {J. Smit, Albertus},\n  title = {Biogeography \\& {Global} {Ecology}},\n  date = {2024-08-02},\n  url = {http://tangledbank.netlify.app/BDC334/BDC334_index.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A (2024) Biogeography & Global Ecology. http://tangledbank.netlify.app/BDC334/BDC334_index.html."
  },
  {
    "objectID": "BDC334/01-introduction.html",
    "href": "BDC334/01-introduction.html",
    "title": "Lab 1. Ecological Data",
    "section": "",
    "text": "BCB743\n\n\n\nThis material must be reviewed by BCB743 students in Week 1 of Quantitative Ecology.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 1. Ecological Data"
    ]
  },
  {
    "objectID": "BDC334/01-introduction.html#about-macroecology",
    "href": "BDC334/01-introduction.html#about-macroecology",
    "title": "Lab 1. Ecological Data",
    "section": "About Macroecology",
    "text": "About Macroecology\nThis course is about community ecology across different spatial and temporal scales. Community ecology underpins the vast fields of biodiversity and biogeography and concerns spatial scales from square meters to all of Earth. We can look at historical, contemporary, and future processes implicated in shaping the distribution of life on our planet.\nEcologists tend to analyse how multiple environmental factors act as drivers that influence the distribution of tens or hundreds of species. These data often are messy and statistical considerations need to be understood within the context of the available data.\nUp to 20 years ago, ecologists focused on populations (the dynamics of individuals of one species interacting among each other and with their environment) and communities (collections of multiple populations, how they interact with each other and their environment, and how this affects the structure and dynamics of ecosystems). This is a modern development of ecology. But ecologists have expanded their horizon regarding the questions they now seek answers for. Today, macroecology offers a broadened view of ecology. Macroecologists seek to find the geographical patterns and processes in biodiversity across all spatial scales, from local to global, across time scales from years to millennia, and across all taxonomic hierarchies (from genetic variability within species up to major higher-level taxa, such as families and orders). It attempts to arrive at a unifying theory for ecology across all of these scales—e.g. one that can explain all patterns in structure and functioning from microbes to blue whales. Perhaps most importantly, it attempts to offer mechanistic explanations for these patterns. At the heart of all ecological answers are also deep insights stemming from understanding evolution (facilitated by the growth of phylogenetic datasets—see below).\nOn a basic data analytical level, population ecology, community ecology, and macroecology all share the same approach regarding the underlying data. We start with data representing the species and the associated environmental conditions at a selection of sites (called species tables and environmental tables). The species tables are then converted to dissimilarity matrices and the environmental tables to distance matrices. From here, basic analyses can offer insights into how biodiversity is structured, e.g. species-abundance distributions, occupancy-abundance curves, species-area curves, distance decay curves, and gradient analyses (as seen in Shade et al. 2018). In the Labs, we will explore some of these properties.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 1. Ecological Data"
    ]
  },
  {
    "objectID": "BDC334/01-introduction.html#ecological-data",
    "href": "BDC334/01-introduction.html#ecological-data",
    "title": "Lab 1. Ecological Data",
    "section": "Ecological Data",
    "text": "Ecological Data\nProperties of Ecological Datasets\nEcological data capture properties of the environment and properties of communities. They are typically stored as separate datasets, but they are analysed together.\nThese data sets are usually arranged in a matrix. In the case of community composition, a matrix has species (or higher level taxa whose resolution depends on the research question) arranged down columns and samples (typically the sites, stations, transects, time, plots, etc.) along rows. We call this a sites × species table. In the case of environmental data, a matrix is a site × environment table. The term ‘sample’ denotes the basic unit of observation. Samples on a map may be quadrats, transects, stations, locations, traps, seine net tows, trawls, grids cells, etc. It is essential to be unambiguous about the basic unit of the samples.\nThe Doubs River Data\nAn obvious example of environmental and species datasets is the Doubs River dataset. Please refer to David Zelený’s website for an explanation of these data. The primary publication outlining this study is Verneaux (1973), and an example analysis is provided by Borcard et al. (2011). These data demonstrate how one of the basic mechanisms of biodiversity patterning—gradients—can be seen operating in a real-world case study. It offers keen insight also into the properties of species and environmental tables and the dissimilarity and distance matrices derived from them.\nLooking at the Files’ Content\nThese data are available in CSV format, but we can open and view it in MS Excel. ‘CSV’ means comma separated value. It is a plain text file that can be edited in any text editor (such as Notepad on MS Windows, or VS Code, VIM, emacs, etc. on all platforms). Figure 1 shows what a CSV file looks like in a plain text editor, VS Code, on my computer. Once imported, it will look similar to the one seen in Figure 3.\n\n\n\n\n\nFigure 1: View of a CSV file inside VS Code.\n\n\n\n\n\n\n\n\nNote About CSV Files and MS Excel\n\n\n\nCSV is a standard format used in the scientific disciplines as it is compatible with many software. Globally, scientists use a period ‘.’ as a decimal point separator. You can see this in the file above. Commas are used exclusively as field separators (you’ll see separate columns once opened in MS Excel).\nCSV files create a bit of a problem for South Africans, who are indoctrinated from a young age to use commas as a decimal point separators—this is to conform with the regional (South African) expectation that dictates commas be used as decimals. So, when you import a CSV file for the first time, you’ll likely see gibberish because your computer will probably be set up to honour the regional (locale) the expectation of commas as decimal points (and ‘R’ for currency, metric units of measurements, etc.). So, you need to know how to fix this to prevent upsetting me (it is a pet peeve and frustrates me endlessly) and yourselves.\nFixing this annoyance is not too tricky, as is demonstrated here. Follow the instruction under ‘Changing commas to decimals and vice versa by changing Excel Options’. Better still, change the global system settings, as the same article explains. Do this before importing the CSV file.\n\n\nAfter importing the Doubs River data, we see something that resembles the following two figures. First, in DoubsSpe.csv, we see the table (or spreadsheet) view of the species data. The species codes for 27 species of fish appear as column headers (not all species’ data are visible as the data are truncated to the right) and in rows 2 through 31 (30 rows) are each of the samples—in this case, there is one sample per site down the length of the river (Figure 2).\n\n\n\n\n\nFigure 2: The Doubs River species data seen in MS Excel.\n\n\nDoubsEnv.csv contains the environmental data, as seen in the following figure. The names of the 11 environmental variables appear as column headers, and there are 30 rows, one for each of the samples—the samples match that of the species data (Figure 3).\n\n\n\n\n\nFigure 3: The Doubs River environmental data in MS Excel.\n\n\nSpecies data may be recorded as various kinds of measurements, such as presence/absence data, biomass, frequency, or abundance. ‘Presence/absence’ of species simply tells us the species is there or is not there. It is binary. ‘Abundance’ generally refers to the the number of individuals per unit of area, volume. ‘Per cent cover’ refers to the proportion of a covered by a species. Per cent cover is used for vegetation, some encrusting species of animals (e.g. sponges), or organisms such as oysters or mussels that can be too numerous to count but whose abundance can be estimated as filling a portion of a sampling unit such as a quadrat. ‘Biomass’ refers to the species’ mass per unit of area or volume. The type of measure will depend on the taxa and the questions under consideration. The critical thing to note is that all species have to be homogeneous in terms of the metric used to quantify them (i.e. all of it as presence/absence, or abundance, or biomass, not mixtures of them). The matrix’s row vectors are the species composition for the corresponding sample. That is to say, a row runs across multiple columns, which tells us that the sample is comprised of all the species whose names are given by the column titles. Note that in the case of the data in the above figures, it is often the case that there are 0s, meaning that not all species are present at all sites. Species composition is frequently expressed in relative abundance, i.e. constrained to a constant total such as 1 or 100%, or biomass, where the upper limit might be arbitrary.\nThe environmental data may be heterogeneous, i.e. the units of measure may differ among the variables. For example, pH has no units, the concentration of some nutrients has a unit of (typically) μM, elevation may be in meters, etc. Because these units have different magnitudes and ranges, we may need to standardise them. To standardise data, we subtract the mean of each column from each data point in the column and then divide each of the resultant values by the standard deviation of the columns.\n\n\n\n\n\n\nLab 1\n\n\n\n(To be reviewed by BCB743 student but not for marks)\n\nStandardise the Doubs River environmental data in MS Excel.\n\n\n\nProperties of Species Datasets\nMany community data matrices share some general characteristics:\n\nMost species occur only infrequently. The majority of species might typically be represented at only a few locations (where they might be pretty abundant). Or some species are simply rare in the sampled region (i.e. when they are present, they are present at a very low abundance). This results in sparse matrices where the bulk of the entries consists of zeros.\nEcologists tend to sample a multitude of factors that they think influence species composition, so the matching environmental data set will also have multiple (10s) columns that will be assessed in various hypotheses about the drivers of species patterning across the landscape. For example, fynbos biomass may be influenced by the fire regime, elevation, aspect, soil moisture, soil chemistry, edaphic features, etc. These datasets are called multi-dimensional matrices, with the ‘dimensions’ referring to the many species or environmental variables.\nEven though we may capture a multitude of information about many environmental factors, the number of important ones is generally relatively low—i.e. a few factors can explain the majority of the explainable variation, and it is our intention to find out which of them is most important.\nMuch of the signal may be spurious, i.e. the matrices have high noise. Variability is a general characteristic of the data, which may result in emerging false patterns. This is because sampling may capture a considerable amount of stochasticity that may mask the actual pattern of interest. Imaginative and creative sampling may reveal some of the ecological patterns we are after, but this requires long years of experience and is not something that can easily be taught as part of our module.\nThere is a significant amount of collinearity. This means that many correlated explanatory variables can explain patterning, but only a few act in a way that implies causation. Collinearity is something we will return to later on.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 1. Ecological Data"
    ]
  },
  {
    "objectID": "BDC334/01-introduction.html#sec-gradients",
    "href": "BDC334/01-introduction.html#sec-gradients",
    "title": "Lab 1. Ecological Data",
    "section": "Ecological Gradients",
    "text": "Ecological Gradients\nAlthough there are many ways in which species can respond to their environment, one of the most striking responses can be seen along with environmental gradients. Next, we will explore this concept by discussing coenoclines and unimodal species distribution models.\nThe Unimodal Model\nThe unimodal model is an idealised species response curve (visualised as a coenocline) where a species has only one mode of abundance. In this species response curve, the species has one optimal environmental condition where it is most abundant (the fewest ecophysiological and ecological stressors). If any aspect of the environment is suboptimal (greater or lesser than the optimum), the species will perform more poorly and have a lower abundance. The unimodal model offers a convenient heuristic tool for understanding how species can become structured along environmental gradients.\nCoenoclines, Coenoplanes, and Coenospaces\nA coenocline is a graphical display of all species response curves (see definition below) simultaneously along one environmental gradient. This is a useful way to display the arrangement of species’ fundamental niches along gradients. It aids our understanding of the species response curve if we imagine the gradient operating in only one geographical direction. The coenoplane concept extends the coenocline to cover two gradients. Again, our visual representation can be facilitated if the two gradients are visualised orthogonal (in this case, at right angles) to each other (e.g. east-west and north-south) and do not interact. A coenospace complicates the model substantially, as it can allow for an unspecified number of gradients to operate simultaneously on multiple species simultaneously. It will probably also capture interactions of environmental drivers on the species.\n\nlibrary(coenocliner)\nset.seed(2)\nM &lt;- 20                                    # number of species\nming &lt;- 3.5                                # gradient minimum...\nmaxg &lt;- 7                                  # ...and maximum\nlocs &lt;- seq(ming, maxg, length = 100)      # gradient locations\nopt  &lt;- runif(M, min = ming, max = maxg)   # species optima\ntol  &lt;- rep(0.25, M)                       # species tolerances\nh    &lt;- ceiling(rlnorm(M, meanlog = 3))    # max abundances\npars &lt;- cbind(opt = opt, tol = tol, h = h) # put in a matrix\n\nmu &lt;- coenocline(locs, responseModel = \"gaussian\", params = pars,\n                 expectation = TRUE)\n\nmatplot(locs, mu, lty = \"solid\", type = \"l\", xlab = \"pH\", ylab = \"Abundance\")\n\n\n\n\n\n\nFigure 4: A coenocline.\n\n\n\n\nAbove is an example of a coenocline using simulated species data. It demonstrates an important idea: that of unimodal species distributions (Figure 4).\n\nset.seed(10)\nN &lt;- 30                                       # number of samples\nM &lt;- 20                                       # number of species\n## First gradient\nming1 &lt;- 3.5                                  # 1st gradient minimum...\nmaxg1 &lt;- 7                                    # ...and maximum\nloc1 &lt;- seq(ming1, maxg1, length = N)         # 1st gradient locations\nopt1 &lt;- runif(M, min = ming1, max = maxg1)    # species optima\ntol1 &lt;- rep(0.5, M)                           # species tolerances\nh    &lt;- ceiling(rlnorm(M, meanlog = 3))       # max abundances\npar1 &lt;- cbind(opt = opt1, tol = tol1, h = h)  # put in a matrix\n## Second gradient\nming2 &lt;- 1                                    # 2nd gradient minimum...\nmaxg2 &lt;- 100                                  # ...and maximum\nloc2 &lt;- seq(ming2, maxg2, length = N)         # 2nd gradient locations\nopt2 &lt;- runif(M, min = ming2, max = maxg2)    # species optima\ntol2 &lt;- ceiling(runif(M, min = 5, max = 50))  # species tolerances\npar2 &lt;- cbind(opt = opt2, tol = tol2)         # put in a matrix\n## Last steps...\npars &lt;- list(px = par1, py = par2)            # put parameters into a list\nlocs &lt;- expand.grid(x = loc1, y = loc2)       # put gradient locations together\n\nmu2d &lt;- coenocline(locs, responseModel = \"gaussian\",\n                   params = pars, extraParams = list(corr = 0.5),\n                   expectation = TRUE)\n\nlayout(matrix(1:4, ncol = 2))\nop &lt;- par(mar = rep(1, 4))\nfor (i in c(2,8,13,19)) {\n  persp(loc1, loc2, matrix(mu2d[, i], ncol = length(loc2)),\n        ticktype = \"detailed\", zlab = \"Abundance\",\n        theta = 45, phi = 30)\n}\n\n\n\n\n\n\nFigure 5: A smoothed coenoplane.\n\n\n\n\n\nsim2d &lt;- coenocline(locs, responseModel = \"gaussian\",\n                    params = pars, extraParams = list(corr = 0.5),\n                    countModel = \"negbin\", countParams = list(alpha = 1))\n\nlayout(matrix(1:4, ncol = 2))\nop &lt;- par(mar = rep(1, 4))\nfor (i in c(2,8,13,19)) {\n  persp(loc1, loc2, matrix(sim2d[, i], ncol = length(loc2)),\n        ticktype = \"detailed\", zlab = \"Abundance\",\n        theta = 45, phi = 30)\n}\n\n\n\n\n\n\nFigure 6: A ‘raw’ coenoplane.\n\n\n\n\nA coenoplane is demonstrated above (Figure 5). We see idealised surfaces (smooth models), and the ‘raw’ species counts are obscured. Plotting the actual count data looks messier (Figure 6) because the measured data are not only a reflection of the underlying species response according to the unimodal model (and hence the fundamental niche), but also of the biotic processes that result in the realised niche, and the stochastic processes that generate some ‘noise’ seen in the data.\nSpecies response curves\nPlotting the abundance of a species as a function of position along a the gradient is called a species response curve. If a long enough the gradient is sampled, a species typically has a unimodal response (one peak resembling a Gaussian distribution) to the gradient. Although the idealised Gaussian response is desired (for statistical purposes, largely), in nature, the curve might deviate quite noticeably from what’s considered ideal. It is probable that a perfectly normal species distribution along a gradient can only be expected when the gradient is perfectly linear in magnitude (seldom true in nature), operates along only one geographical direction (unlikely), and all other potentially additive environmental influences are constant across the ecological (coeno-) space (also not a realistic expectation). Very importantly, also, the species response curve is not a direct measure of the species’ fundamental niche, but rather a reflection of the species’ realised niche.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 1. Ecological Data"
    ]
  },
  {
    "objectID": "BDC334/01-introduction.html#exploring-the-data",
    "href": "BDC334/01-introduction.html#exploring-the-data",
    "title": "Lab 1. Ecological Data",
    "section": "Exploring the Data",
    "text": "Exploring the Data\nAt the start of the analysis, before we go deeper into the patterns in the data, we need to explore the data and compute the various synthetic descriptors. This might involve calculating means and standard deviations for some of the variables we feel are most important. So, we say that we produce univariate summaries, and if there is a need we may also create some graphical summaries like line plots or frequency histograms. Be guided by the research questions as to what is required. Typically, I don’t like to produce too many detailed inferential statistics of the univariate data (there are special statistical techniques available that allow us to do so more efficiently and effectively, but we will get to it in the Honours Module Quantitative Ecology), choosing instead to see which relationships and patterns emerge from the exploratory summary plots before testing their statistical significance using multivariate approaches. But that is me. Sometimes, some hypotheses call for a few univariate inferential analyses (again, this is the topic of an Honours module on Biostatistics).\n\n\n\n\n\n\nLab 1 (continue)\n\n\n\n(To be reviewed by BCB743 student but not for marks)\n\nCreate an \\(x-y\\) plot of the geographical coordinates in DoubsSpa.csv.\nUsing some graphs that plot the trends of the Doubs River environmental variables along the length of the river, describe the patterns in some of the environmental variables and offer explanations for how they might be responsible for affecting species distributions down the length of the Doubs River. Which three variables do you think will be able to explain the trends in the species data?",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 1. Ecological Data"
    ]
  },
  {
    "objectID": "BDC334/01-introduction.html#pairwise-matrices",
    "href": "BDC334/01-introduction.html#pairwise-matrices",
    "title": "Lab 1. Ecological Data",
    "section": "Pairwise Matrices",
    "text": "Pairwise Matrices\nAlthough we typically start our forays into data exploration using sites × species and sites × environment tables, the formal statistical analyses usually require ‘pairwise association matrices.’ Such matrices are symmetrical (sometimes only the lower or upper triangle is displayed) square matrices (i.e. \\(n \\times n\\)). These matrices tell us how related any sample is to any other sample in our pool of samples (i.e. relatedness among rows with respect to whatever populates the columns, be they species information of environmental information).\nLet us consider various kinds of distance matrices under the headings Distances, Correlations, Associations, Similarities, and Dissimilarities.\nDistances\nA frequently used distance metric in ecological and geographical studies is Euclidean distance. Euclidean distance represents the ‘ordinary straight-line’ distance between two points in Euclidean space. When working with geographical coordinates over small areas of Earth’s surface, Euclidean distance is very similar (i.e., almost directly proportional) to the actual geographical distance, making the concept intuitive to understand.\nIn its simplest form, Euclidean distance is calculated in a planar Cartesian area, which is familiar as a graph with \\(x\\)- and \\(y\\)-axes. In 2D and 3D space, it gives distances in Cartesian units between points on a plane (\\(x\\), \\(y\\)) or in volume (\\(x\\), \\(y\\), \\(z\\)). There is a linear relationship between the units in the physical realm and the units in Euclidean space, implying that short distances between pairs of points on a map or graph also represent short geographic distances on Earth.\nEuclidean distance is calculated using the Pythagorean theorem and is typically applied to standardised environmental data (not species data):\n\\[\nd(a,b) = \\sqrt{\\sum_{i=1}^{n} (a_i - b_i)^2}\n\\]\nIn this formula:\n\n\n\\(a\\) and \\(b\\) are two points in Euclidean space; in terms of environmental data, \\(a\\) and \\(b\\) represent two sites.\nEach element \\(i = 1\\) through \\(n\\) in the vectors \\(a\\) and \\(b\\) represents a dimension or variable in the space. For example, if we have three environmental variables, \\(n = 3\\), and the formula calculates the Euclidean distance between the two sites in a three-dimensional space.\nThe summation \\(\\sum_{i=1}^{n}\\) goes over all dimensions from 1 to \\(n\\).\n\nEach coordinate or variable could represent different environmental factors such as temperature, depth, or light intensity (sometimes also called ‘dimensions’ of environmental space). For example, in the case of three environmental variables, the Euclidean distance would be calculated as:\n\\[\nd(a,b) = \\sqrt{(a_{\\text{temp}} - b_{\\text{temp}})^2 + (a_{\\text{depth}} - b_{\\text{depth}})^2 + (a_{\\text{light}} - b_{\\text{light}})^2}\n\\]\nIn the example dataset downloaded earlier (Euclidean_distance_demo_data_xyz.csv), we can calculate the distance between every pair of sites named a to g. The ‘raw’ data representing \\(x\\), \\(y\\) and \\(z\\) dimensions can be viewed in MS Excel, as we see in Figure 7.\n\n\n\n\n\nFigure 7: Data representing three dimensions, \\(x\\), \\(y\\), and \\(z\\).\n\n\nWe can substitute \\(x\\), \\(y\\) and \\(z\\) for environmental ‘dimensions,’ and we have a set of data that resembles what we see in Figure 8. Regardless of whether we have \\(x\\), \\(y\\) and \\(z\\) or environmental dimensions, the application of the Pythagorean Theorem is the same.\n\n\n\n\n\nFigure 8: Data representing three environmental ‘dimensions.’\n\n\nFigure 9 shows how we may calculate Euclidean distance in MS Excel uses some built-in functions. To produce the pairwise matrix, you’d have to do this for every pair of sites. As a minimum, calculate the bottom left triangle. For completeness, calculate the diagonal, which will be all zeros in this instance.\n\n\n\n\n\nFigure 9: Calculating Euclidean distance in MS Excel. The pink shaded cells are the diagonal comprised of 0s, and the blue shaded cells are the lower triangle. The upper triangle remains unshaded but will be a mirror image of the lower triangle.\n\n\nStandardisation\nIn the Euclidean distance calculation, we are comparing the ‘distances’ between sites based on the environmental variables. If the variables are measured in different units, the Euclidean distance will be dominated by the variable with the largest range. To avoid this, we standardise the variables before calculating the Euclidean distance. Standardisation involves subtracting the mean of each variable from the data and dividing by the standard deviation. This process ensures that all variables are on the same scale and have a mean of zero and a standard deviation of one.\nCorrelations\nWe use correlations to establish how environmental variables relate across the sample sites. Therefore, a correlation performed to a sites × variable table is done between columns (variables), not rows, as in the Euclidean distance calculation, which compares the rows (sites). We do not need to standardise as one would for calculating Euclidean distances (but it will do no harm if you do). Correlation coefficients (so-called \\(r\\)-values) vary in magnitude from -1 (a perfect inverse relationship) from 0 (no relationship) to 1 (a perfect positive linear relationship).\n\n\n\n\n\nFigure 10: Calculating pairwise correlations between environmental variables in MS Excel.\n\n\nThe resultant pairwise correlation matrix shows the names of the environmental variables as both column and row names. Contrast this with what is presented as row and column names in the distance matrix (Figure 10).\nAssociations, Similarities, and Dissimilarities\nThus far, we have worked with environmental data. Associations, similarities, and dissimilarities extend the pairwise matrix to species data. We will discuss and calculate these matrices in Lab 3.\nThat’s it for this week, Folks! I’ll leave you with some lovely exercises to take you through the rest of the week.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 1. Ecological Data"
    ]
  },
  {
    "objectID": "BDC334/01-introduction.html#summary-of-species-and-environmental-data",
    "href": "BDC334/01-introduction.html#summary-of-species-and-environmental-data",
    "title": "Lab 1. Ecological Data",
    "section": "Summary of Species and Environmental Data",
    "text": "Summary of Species and Environmental Data\nThe diagram below (Figure 11) summarises the species and environmental data tables, and what we can do with them. These tables are the starting points of many additional analyses, and we will explore some of these ecological relationships later in this module.\n\n\n\n\n\nFigure 11: Species and environmental tables and what to do with them.\n\n\n\n\n\n\n\n\nLab 1 (continue)\n\n\n\n(To be reviewed by BCB743 student but not for marks)\n\nUsing the Doubs River environmental data, calculate the lower left triangle (including the diagonal) distance matrix for every pair of sites in Sites 1, 3, 5, …, 29 (i.e. using only every second site). Explain any patterns or trends in this resultant distance matrix regarding how similar/different sites are relative to each other. Which of the graphs you came up with in Task 3 (if any) do you think are responsible for the patterns seen in the distance matrix?\nUsing the same sites as above (Question 4), calculate a pairwise correlation matrix (lower left and including the diagonal) for the Doubs River environmental data. Explain any patterns or trends in this resultant correlation matrix and offer mechanistic explanations for why these correlations might exist.\nDiscuss in detail the properties of distance and correlation matrices.\nIf you found this exercise annoying, explain why. Or if you loved it, state why. What could be done to ease your experience of the calculations?\n\n\n\n\n\n\n\n\n\nSubmission Instructions\n\n\n\nThe Lab 1 assignment on Ecological Data was discussed on Monday 22 July and is due at 07:00 on Monday 29 July 2024.\nProvide a neat and thoroughly annotated MS Excel spreadsheet which outlines the graphs and all calculations and which displays the resultant distance matrix. Use separate tabs for the different questions. Written answers must be typed in an MS Word document. Please follow the formatting specifications precisely shown in the file BDC334 Example essay format.docx that was circulated at the beginning of the module. Feel free to use the file as a template.\nPlease label the MS Excel and MS Word files as follows:\n\nBDC334_&lt;first_name&gt;_&lt;last_name&gt;_Lab_1.xlsx, and\nBDC334_&lt;first_name&gt;_&lt;last_name&gt;_Lab_1.docx\n\n(the &lt; and &gt; must be omitted as they are used in the example as field indicators only).\nSubmit your appropriately named spreadsheet and MS Word documents on iKamva when ready.\nFailing to follow these instructions carefully, precisely, and thoroughly will cause you to lose marks, which could cause a significant drop in your score as formatting counts for 15% of the final mark (out of 100%).",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 1. Ecological Data"
    ]
  },
  {
    "objectID": "BDC334/01-introduction.html#references",
    "href": "BDC334/01-introduction.html#references",
    "title": "Lab 1. Ecological Data",
    "section": "References",
    "text": "References\n\n\nBorcard D, Gillet F, Legendre P, others (2011) Numerical ecology with R. Springer\n\n\nShade A, Dunn RR, Blowes SA, Keil P, Bohannan BJ, Herrmann M, Küsel K, Lennon JT, Sanders NJ, Storch D, others (2018) Macroecology to unite all life, large and small. Trends in ecology & evolution 33:731–744.\n\n\nVerneaux J (1973) Cours d’eau de Franche-Comté (Massif du Jura). Recherches écologiques sur le réseau hydrographique du Doubs.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 1. Ecological Data"
    ]
  },
  {
    "objectID": "BDC334/L01b-macroecology.html",
    "href": "BDC334/L01b-macroecology.html",
    "title": "Lecture 1b. Macroecology",
    "section": "",
    "text": "BCB743\n\n\n\nThis material must be reviewed by BCB743 students in Week 1 of Quantitative Ecology.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 1b. Macroecology"
    ]
  },
  {
    "objectID": "BDC334/L01b-macroecology.html#ecological-concepts",
    "href": "BDC334/L01b-macroecology.html#ecological-concepts",
    "title": "Lecture 1b. Macroecology",
    "section": "Ecological Concepts",
    "text": "Ecological Concepts\nWhen we talk about ‘ecology’, central to our discussion is the concept of biodiversity. The Convention on Biological Diversity defines biodiversity as:\n\n“The variability among living organisms from all sources including, inter alia, terrestrial, marine and other aquatic ecosystems and the ecological complexes of which they are part; this includes diversity within species, between species and of ecosystems.”\n\nIn this lecture, we will work towards an understanding of macroecology by working through these topics:\n\n‘Traditional’ ecology—focus on the ‘local’ scale.\nThe distinction between populations and communities.\nA definition for what ecology is.\nThe concept of the ‘niche’ (fundamental and realised).\nThe concept of ‘species’.\nDescribe the properties of communities, viz. mainly structure and function.\nUsing measures of diversity to understand structure.\nArrive at the concept of macroecology.\n\nIn this module, we’ll rely on thinking emerging from a unifying field of ecology called macroecology. According to Keith et al. (2012), macroecology is:\n\n“…the study of the mechanisms underlying general patterns of ecology across scales.”",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 1b. Macroecology"
    ]
  },
  {
    "objectID": "BDC334/L01b-macroecology.html#macroecology-ecology-across-scales",
    "href": "BDC334/L01b-macroecology.html#macroecology-ecology-across-scales",
    "title": "Lecture 1b. Macroecology",
    "section": "Macroecology: Ecology Across Scales",
    "text": "Macroecology: Ecology Across Scales\n\nFor a deeper dive into macroecology, please see the paper Shade et al. (2018). I provide some additional views on macroecology to supplement the insights you extract from this publication.\n\nMacroecology explores ecological patterns and processes across a wide range of scales (from microbes to blue whales, from the Cape Flats Nature Reserve to the whole of Earth, and from the Pleistocene to 2100). To the best of my knowledge, the term ‘macroecology’ was coined by Brown and Maurer (1989), who used it to study continental biotas. The term has since then undergone much growth and evolution in recent decades. More recently, it has led to attempts to develop unified theories of ecology Shade et al. (2018), driven by a convergence of technological and methodological advancements, building upon earlier foundations laid by disciplines such as ‘phytosociology.’\nPhytosociology (phytocoenology or plant sociology) studies and classifies plant communities. It has greatly influenced modern ecological research. Phytosociologists emphasise systematic vegetation classification and the understanding of plant community structure, which prepared the ground for many concepts in macroecology. For example, the Braun-Blanquet method, a cornerstone method in phytosociology since its development by Josias Braun-Blanquet (1884-1980) (Dengler et al. 2008; Dengler 2016), still forms a standardised approach to vegetation sampling. The method has been adapted and expanded in the study of, amongst other things, benthic (limnetic and marine) communities, as it is well suited to sampling communities comprised mainly of sessile organisms.\nRecent progress in macroecology was achieved through advances in several key areas. Molecular phylogenetics provided new insights into evolutionary relationships, while high-resolution datasets of abiotic and biotic variables offered unprecedented detail about environmental conditions and species distributions. Today’s vast (and rapidly growing) computational power allows the processing and analysis of these complex datasets, and novel numerical approaches and a robust statistical framework provide tools to extract insightful patterns from the data.\nIncreased knowledge sharing and access to open data have further accelerated the growth of macroecology. Wider collaborative networks of ecologists now provide a more integrated understanding of ecological systems across broad spatial and temporal scales. We can now tackle complex questions that were previously out of reach.\nSome of these fundamental questions include inquiries about variations in body size across species and regions, the patterns of biodiversity at global spatial scales and over geological timescales, abundance distributions across size classes of organisms, geographical range dynamics as we experience the various pressures of global change and the role of neutral processes in shaping ecological communities.\nWhile ‘traditional’ ecology primarily focuses on describing natural patterns, macroecology has shifted towards finding mechanistic explanations for the processes resulting in observed biodiversity patterns. This transition advances our understanding of ecological systems, moving beyond mere description to explanation and prediction. Ecological systems are also increasingly coupled with Earth system models to offer projections of ecological structure and function in the future.\nToday’s ecology students must reconcile their biological observations and knowledge with hypotheses about patterns and processes and understand the statistical models used to explain them. New frameworks are being developed to integrate biological theory with sophisticated statistical techniques, and we can conduct more robust and meaningful analyses of large-scale ecological data.\nA key insight from this approach is the recognition that local species interactions can explain broad-scale patterns in species distributions. This understanding bridges the gap between small-scale ecological studies and large-scale macroecological patterns and provides a more cohesive view of how ecosystems function across different spatial scales.\nThis growing recognition that links local processes to global patterns has led some ecologists to try and find unified theories of ecology. These theories aim to be predictive by offering explanations for observed patterns and the ability to forecast future ecological scenarios. Such unified theories represent a holy grail in ecology and potentially provide an integrated framework for understanding and predicting ecological phenomena across scales and systems.\nThe advancements in macroecology have significantly enhanced our comprehension of biodiversity, ecosystem functioning, and ecological responses to global change. Notably, macroecology has exerted a remarkably wide-ranging and transformative impact at the intersection of scientific research and policy-making. This influence is especially evident in land-use management, climate change mitigation and adaptation strategies, and efforts to address biodiversity loss.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 1b. Macroecology"
    ]
  },
  {
    "objectID": "BDC334/03-biodiversity1.html",
    "href": "BDC334/03-biodiversity1.html",
    "title": "Lab 3. Quantifying Biodiversity",
    "section": "",
    "text": "BCB743\n\n\n\nThis material must be reviewed by BCB743 students in Week 1 of Quantitative Ecology.\nThe IUCN definition considers a diversity of diversity concepts. This module looks at diversity only at the species level (species diversity). However, we can also approach macroecological problems from phylogenetic and functional (and other) diversity concepts of view. Functional and phylogenetic diversity ideas will be introduced in the BDC743 module Quantitative Ecology.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 3. Quantifying Biodiversity"
    ]
  },
  {
    "objectID": "BDC334/03-biodiversity1.html#preparation",
    "href": "BDC334/03-biodiversity1.html#preparation",
    "title": "Lab 3. Quantifying Biodiversity",
    "section": "Preparation",
    "text": "Preparation\n\nThe South African Seaweed Data\nIn these examples, we will use the seaweed data of Smit et al. (2017). Please make sure that you read this paper. An additional file describing the background to the data is available here (Figure 1).\n\n\n\n\n\n\nFigure 1: The coastal sections and associated seawater temperature profile associated with the study by Smit et al. (2017).\n\n\n\nOne of the datasets, \\(Y\\) (in the file SeaweedSpp.csv), comprises updated distribution records of 847 macroalgal species within each of 58 × 50 km-long sections of the South African coast (Bolton and Stegenga 2002). The dataset captures ca. 90% of the known seaweed flora of South Africa, but excludes some very small and/or very rare species for which data are insufficient. The data are from verifiable literature sources and John Bolton and Rob Anderson’s collections, assembled from information collected by teams of phycologists over three decades (Bolton 1986; Stegenga et al. 1997; Bolton and Stegenga 2002; De Clerck et al. 2005). Another file, \\(E\\) (in env.csv), is a dataset of in situ coastal seawater temperatures derived from daily measurements over 40 years (Smit et al. 2013).\n\n\nSetting Up the Analysis Environment\nWe will use R, so first, we must find, install and load various packages. Some packages will be available on CRAN and can be accessed and installed the usual way, but you will need to download others from R Forge.\n\nlibrary(tidyverse)\nlibrary(vegan)\nlibrary(betapart)\nlibrary(BiodiversityR) # this package may at times be problematic to install\n\n\n\nA Look at the Data\nLet’s load the data and see how it is structured:\n\nspp &lt;- read.csv('../data/seaweed/SeaweedSpp.csv')\nspp &lt;- dplyr::select(spp, -1)\n\n# Lets look at the data:\ndim(spp)\n\n[1]  58 847\n\n\nWe see that our dataset has 58 rows and 847 columns. What is in the columns and rows? Start with the first five rows and five columns:\n\nspp[1:5, 1:5]\n\n  ACECAL ACEMOE ACRVIR AROSP1 ANAWRI\n1      0      0      0      0      0\n2      0      0      0      0      0\n3      0      0      0      0      0\n4      0      0      0      0      0\n5      0      0      0      0      0\n\n\nNow the last five rows and five columns:\n\nspp[(nrow(spp) - 5):nrow(spp), (ncol(spp) - 5):ncol(spp)]\n\n   WOMKWA WOMPAC WRAARG WRAPUR WURMIN ZONSEM\n53      0      0      1      0      0      0\n54      0      0      1      0      0      0\n55      0      0      1      0      0      0\n56      0      1      1      0      1      0\n57      1      0      1      0      1      0\n58      0      0      1      0      1      0\n\n\nSo, each row corresponds to a site (i.e. each of the coastal sections), and each column contains a species. We arrange the species alphabetically and use a six-letter code to identify them.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 3. Quantifying Biodiversity"
    ]
  },
  {
    "objectID": "BDC334/03-biodiversity1.html#species-data",
    "href": "BDC334/03-biodiversity1.html#species-data",
    "title": "Lab 3. Quantifying Biodiversity",
    "section": "Species Data",
    "text": "Species Data\nWhen ecologists talk about species diversity, they typically consider the characteristics of biological communities in a specific habitat, ecological community, or ecosystem. Species diversity considers three essential concepts about how species are distributed in space: their richness, abundance, and evenness. We can express each of these as biodiversity metrics that allow us to compare communities in space and time.\nWhen ecologists talk about ‘biodiversity’, they might not necessarily be interested in all the plants and animals and things that are neither plant nor animal that occur at a particular place. Some ecologists are interested in ants and moths. Others might find fish more insightful. Some even like marine mammals! I prefer seaweed. The analysis of biodiversity data might often be constrained to some higher-level taxon, such as all angiosperms in a landscape, reptiles, etc. (but we sample all species in the higher-level taxon). Some ecological questions benefit from comparisons of diversity assessments among selected taxa (avifauna vs small mammals, for example), as this focus might address some particular ecological hypothesis. The bird vs small mammal comparison might reveal how barriers such as streams and rivers structure biodiversity patterns. In our examples, we will use such focused datasets.\nHere we look at the various measures of biodiversity, viz. \\(\\alpha\\)-, \\(\\gamma\\)- and \\(\\beta\\)-diversity. David Zelený, in his Analysis of community data in R, provides deeper analysis and compulsory reading.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 3. Quantifying Biodiversity"
    ]
  },
  {
    "objectID": "BDC334/03-biodiversity1.html#three-measures-of-biodiversity-alpha--gamma--beta-diversity",
    "href": "BDC334/03-biodiversity1.html#three-measures-of-biodiversity-alpha--gamma--beta-diversity",
    "title": "Lab 3. Quantifying Biodiversity",
    "section": "Three Measures of Biodiversity: \\(\\alpha\\)-, \\(\\gamma\\)-, \\(\\beta\\)-Diversity",
    "text": "Three Measures of Biodiversity: \\(\\alpha\\)-, \\(\\gamma\\)-, \\(\\beta\\)-Diversity\nWhittaker (1972) coined three measures of biodiversity, and the concepts were ‘modernised’ by Jurasinski et al. (2009). The concepts represent the measurement of biodiversity across different spatial scales. \\(\\alpha\\)- and \\(\\gamma\\)-diversity express the total number of species in an area. The first, \\(\\alpha\\)-diversity, represents the number of species at the small (local) scale, such as, for example, within a sampling unit like a quadrat, transect, plot, or trawl. Alternatively, maybe the research question represents the local scale by several sampling units nesting within a small patch of landscape and defines the mean species richness within this patch as local. Multiples (sampling units or patches) are nested within a larger region (or ecosystem) and serve as replicates. The complete number of species across all of these replicates indicates the diversity at a larger scale—this is called \\(\\gamma\\)-diversity. \\(\\beta\\)-diversity refers to the change in species composition among samples (sites).\nBy now, you will have received a brief Introduction to R, and we can proceed with looking at some of the measures of biodiversity. We will start by using data on the seaweeds of South Africa to demonstrate some ideas around diversity measures. The vegan1 (for vegetation analysis) package (Oksanen et al. 2022) offers various functions to calculate diversity indices. I will demonstrate some of these functions below.\n1 I am by no means an advocate for veganism.\nAlpha-Diversity\nWe can represent \\(\\alpha\\)-diversity in three ways:\n\nas species richness, \\(S\\);\nas a univariate diversity index, such as the \\(\\alpha\\) parameter of Fisher’s log-series, Shannon diversity, \\(H'\\), Simpson’s diversity, \\(\\lambda\\); or\nSpecies evenness, e.g. Pielou’s evenness, \\(J\\).\n\nWe will work through each in turn.\n\nSpecies Richness, \\(S\\)\nFirst, is species richness, which we denote by the symbol \\(S\\). This is the simplest measure of \\(\\alpha\\)-diversity, counting the number of species (or another taxonomic level) present in a given community or sample. It doesn’t consider the abundance of species.\nIn the seaweed biodiversity data, I count the number of species within each of the sections. This is because we view each coastal section as the local scale (the smallest unit of sampling).\nThe preferred option for calculating species richness is the specnumber() function in vegan:\n\n1specnumber(spp, MARGIN = 1)\n\n\n1\n\nThe MARGIN = 1 argument tells R to calculate the number of species within each row (site).\n\n\n\n\n [1] 138 139 139 140 143 143 143 145 149 148 159 162 208 147 168 204 269 276 280\n[20] 265 265 283 269 279 281 295 290 290 299 295 311 317 298 299 301 315 308 327\n[39] 340 315 315 302 311 280 300 282 283 321 319 319 330 293 291 292 294 313 333\n[58] 316\n\n\nThe data output is easier to understand if we display it as a tibble():\n\nspp_richness &lt;- tibble(section = 1:58,\n                       richness = specnumber(spp, MARGIN = 1))\nhead(spp_richness)\n\n# A tibble: 6 × 2\n  section richness\n    &lt;int&gt;    &lt;int&gt;\n1       1      138\n2       2      139\n3       3      139\n4       4      140\n5       5      143\n6       6      143\n\n\nThe diversityresult() function in the BiodiversityR package can do the same (sometimes this package is difficult to install due to various software dependencies that might be required for the package to load properly—do not be sad if this method does not work):\n\nspp_richness &lt;- diversityresult(spp, index = 'richness',\n                                method = 'each site')\nhead(spp_richness)\n\nNow we make a plot seen in Figure 2:\n\nggplot(data = spp_richness, (aes(x = 1:58, y = richness))) +\n  geom_line(size = 1.2, colour = \"indianred\") +\n  xlab(\"Coastal section, west to east\") +\n  ylab(\"Species richness\") +\n  theme_linedraw()\n\n\n\n\n\n\n\nFigure 2: The seaweed species richness, \\(S\\), within each of the coastal sections along the shore of South Africa.\n\n\n\n\n\nIn other instances, it makes more sense to calculate the mean species richness of all the sampling units (e.g. quadrats) taken inside the ecosystem of interest. How you calculate and present species richness depend on your research question and so you will have to decide based on your data and study.\nIn the seaweed study, the mean ± SD species richness across all of the 58 coastal sections is:\n\nround(mean(spp_richness$richness), 2)\n\n[1] 259.24\n\nround(sd(spp_richness$richness), 2)\n\n[1] 68.03\n\n\n\n\nUnivariate Diversity Indices\nThe second way we can express \\(\\alpha\\)-diversity is to use one of the univariate diversity indices. The choice of which index to use should be informed by the extent to which one wants to emphasise richness or evenness. Species richness, \\(S\\), does not consider evenness as it is all about richness (obviously). Simpson’s \\(\\lambda\\) emphasises evenness a lot more. Shannon’s \\(H'\\) is somewhere in the middle.\nShannon’s \\(H'\\) is sometimes called Shannon’s diversity, the Shannon-Wiener index, the Shannon-Weaver index, or the Shannon entropy. This is a more nuanced measure that considers both species richness and evenness (how evenly individuals are distributed across different species).\nIt is calculated as:\n\\[H' = -\\sum_{i=1}^{S} p_{i} \\ln p_{i}\\] where \\(p_{i}\\) is the proportion of individuals belonging to the \\(i\\)th species, and \\(S\\) is the species richness.\nSimpson’s \\(\\lambda\\), or simply the Simpson index, is a measure that represents the probability that two individuals randomly selected from a sample will belong to the same species. It is calculated as:\n\\[\\displaystyle \\lambda = \\sum_{i=1}^{S} p_{i}^{2}\\] where \\(S\\) is the species richness and \\(p_{i}\\) is the relative abundance of the \\(i\\)th species.\nFisher’s \\(\\alpha\\) estimates the \\(\\alpha\\) parameter of Fisher’s logarithmic series (see functions fisher.alpha() and fisherfit()). The estimation is possible only for actual counts (i.e. integers) of individuals, so it will not work for per cent cover, biomass, and other measures that real numbers can express. It’s especially useful for comparing the diversity of samples with different total abundances. We will get to this function later under Fisher’s logarithmic series.\nExcept for Fisher’s-\\(\\alpha\\), we cannot calculate these for the seaweed data, because, in order to do so, we require abundance data—the seaweed data are presence-absence only. Let us load a fictitious dataset of the diversity of three different communities of plants, with each community corresponding to a different light environment (dim, mid, and high light):\n\nlight &lt;- read.csv(\"../data/light_levels.csv\")\nlight\n\n        Site    A    B    C    D    E    F\n1  low_light 0.75 0.62 0.24 0.33 0.21 0.14\n2  mid_light 0.38 0.15 0.52 0.57 0.28 0.29\n3 high_light 0.08 0.15 0.18 0.52 0.54 0.56\n\n\nWe can see above that instead of having data with 1s and 0s for presence-absence, here we have some values that indicate the relative number of individuals belonging to each of the species in the three light environments. We calculate species richness (as before), and also the Shannon and Simpson indices using vegan’s diversity() function:\n\nlight_div &lt;- tibble(\n  site = c(\"low_light\", \"mid_light\", \"high_light\"),\n  richness = specnumber(light[, 2:7], MARGIN = 1),\n  shannon = round(diversity(light[, 2:7], MARGIN = 1, index = \"shannon\"), 2),\n  simpson = round(diversity(light[, 2:7], MARGIN = 1, index = \"simpson\"), 2)\n)\nlight_div\n\n# A tibble: 3 × 4\n  site       richness shannon simpson\n  &lt;chr&gt;         &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 low_light         6    1.62    0.78\n2 mid_light         6    1.71    0.81\n3 high_light        6    1.59    0.77\n\n\n\n\n\n\n\n\n\n\n\n\nEvenness refers to the shape of a species abundance distribution, which suggests the relative abundance of different species.\nOne index for evenness is Pielou’s evenness, \\(J\\):\n\\[J = \\frac{H^{\\prime}} {log(S)}\\]\nwhere \\(H'\\) is Shannon’s diversity index, and \\(S\\) the number of species (i.e. \\(S\\)).\nTo calculate Pielou’s evenness index for the light data, we can do this:\n\nH &lt;- diversity(light[, 2:7], MARGIN = 1, index = \"shannon\")\n\nJ &lt;- H/log(specnumber(light[, 2:7]))\nround(J, 2)\n\n[1] 0.91 0.95 0.89\n\n\nBerger-Parker Index indicates the proportion of the community that the most abundant species represents. It is given by the formula:\n\\[d = \\frac{N_{max}}{N}\\] where \\(N_{max}\\) is the number of individuals of the most common species and \\(N\\) is the total number of individuals in the sample.\nChao1 and ACE are estimators often used to predict the total species richness in a community based on the number of rare species observed in samples.\n\n\n\nGamma-Diversity\nReturning to the seaweed data, \\(Y\\), let us now look at \\(\\gamma\\)-diversity—this would be the total number of species along the South African coastline in all 58 coastal sections. Since each column represents one species, and the dataset contains data collected at each of the 58 sites (the number of rows), we can do:\n\n1ncol(spp)\n\n\n1\n\nThe number of columns gives the total number of species in this example.\n\n\n\n\n[1] 847\n\n\nWe can also use:\n\ndiversityresult(spp, index = 'richness', method = 'pooled')\n\n       richness\npooled      846\n\n\n\n\n\n\n\n\n\n\n\nLab 3\n\n\n\n(To be reviewed by BCB743 student but not for marks)\n\nWhy is there a difference between the two?\nWhich is correct?\n\n\n\nThink before you calculate \\(\\gamma\\)-diversity for your own data as it might not be as simple as here!\n\n\nBeta-Diversity\n\nWhittaker’s \\(\\beta\\)-Diversity\nThe first measure of \\(\\beta\\)-diversity comes from Whittaker (1960) and is called true \\(\\beta\\)-diversity. In this instance, divide the \\(\\gamma\\)-diversity for the region by the \\(\\alpha\\)-diversity for a specific coastal section. We can calculate it all at once for the whole dataset and make a graph (Figure 3):\n\ntrue_beta &lt;- data.frame(\n  beta = specnumber(spp, MARGIN = 1) / ncol(spp),\n  section_no = c(1:58)\n)\n# true_beta\nggplot(data = true_beta, (aes(x = section_no, y = beta))) +\n  geom_line(size = 1.2, colour = \"indianred\") +\n  xlab(\"Coastal section, west to east\") +\n  ylab(\"True beta-diversity\") +\n  theme_linedraw()\n\n\n\n\n\n\n\nFigure 3: Whittaker’s true β-diversity shown in the seaweed data.\n\n\n\n\n\nThe second measure of \\(\\beta\\)-diversity is absolute species turnover, and to calculate this, we subtract \\(\\alpha\\)-diversity for each section from the region’s \\(\\gamma\\)-diversity (Figure 4):\n\nabs_beta &lt;- data.frame(\n  beta = ncol(spp) - specnumber(spp, MARGIN = 1),\n  section_no = c(1:58)\n)\n# abs_beta\nggplot(data = abs_beta, (aes(x = section_no, y = beta))) +\n  geom_line(size = 1.2, colour = \"indianred\") +\n  xlab(\"Coastal section, west to east\") +\n  ylab(\"Absolute beta-diversity\") +\n  theme_linedraw()\n\n\n\n\n\n\n\nFigure 4: Whittaker’s absolute species turnover shown in action in the seaweed data.\n\n\n\n\n\n\n\nContemporary Definitions \\(\\beta\\)-Diversity\nContemporary definitions of \\(\\beta\\)-diversity rely on pairwise dissimilarity indices such as Bray-Curtis, Jaccard, or Sørensen dissimilarities—see Koleff et al. (2003) for many more; also see ?vegdist. However, discussing pairwise dissimilarities with \\(\\beta\\)-diversity makes more sense.\n\nDissimilarity indices\nDissimilarity indices are special cases of diversity indices that use pairwise comparisons between sampling units, habitats, or ecosystems.\nSpecies dissimilarities result in pairwise matrices similar to the pairwise correlation or Euclidian distance matrices we have seen in Lab 1. In Lab 2b you will have also learned how to calculate these ecological distances in R. These dissimilarity indices are multivariate and compare between sites, sections, plots, etc., and must therefore not be confused with the univariate diversity indices.\nWe use the Bray-Curtis and Jaccard indices with abundance data and the Sørensen dissimilarity with presence-absence data. The seaweed dataset is a presence-absence dataset that necessitates using the Sørensen index. The interpretation of the resulting square (number of rows = number of columns) dissimilarity matrices is the same regardless of whether we calculate it for an abundance or presence-absence dataset. The values in the matrix range from 0 to 1. A 0 means that the pair of sites we compare is identical (all species in common) but 1 means they are completely different (no species in common). In the square dissimilarity matrix, the diagonal is 0, which essentially (and obviously) means that any site is identical to itself. Elsewhere the values will range from 0 to 1. Since this is a pairwise calculation (each site compared to every other site), our seaweed dataset will contain (58 × (58 - 1))/2 = 1653 values, each one ranging from 0 to 1.\nThe first step involves the species table, \\(Y\\). First, we compute the Sørensen dissimilarity index, \\(\\beta_{\\text{sør}}\\), to compare the dissimilarity of all pairs of coastal sections using presence-absence data. The dissimilarity in species composition between two sections is calculated from three parameters, viz., b and c, which represent the number of species unique to each of the two sites, and a, the number of species in common between them. It is given by:\n\\[\\beta_\\text{sør}=\\frac{2a}{2a+b+c}\\] Where \\(a\\) is the number of species in common between two sites, and \\(b\\) and \\(c\\) are the number of species unique to each site. The Sørensen dissimilarity index ranges from 0 to 1, where 0 means that the pair of sites we compare is identical (all species in common) and 1 means they are completely different (no species in common).\nThe vegan function vegdist() provides access to the dissimilarity indices. We calculate the Sørensen dissimilarity index:\n\nsor &lt;- vegdist(spp, binary = TRUE) # makes the lower triangle matrix\nsor_df &lt;- round(as.matrix(sor), 4)\ndim(sor_df)\n\n[1] 58 58\n\nsor_df[1:10, 1:10] # the first 10 rows and columns\n\n        1      2      3      4      5      6      7      8      9     10\n1  0.0000 0.0036 0.0036 0.0072 0.0249 0.0391 0.0391 0.0459 0.0592 0.0629\n2  0.0036 0.0000 0.0000 0.0036 0.0213 0.0355 0.0355 0.0423 0.0556 0.0592\n3  0.0036 0.0000 0.0000 0.0036 0.0213 0.0355 0.0355 0.0423 0.0556 0.0592\n4  0.0072 0.0036 0.0036 0.0000 0.0177 0.0318 0.0318 0.0386 0.0519 0.0556\n5  0.0249 0.0213 0.0213 0.0177 0.0000 0.0140 0.0140 0.0208 0.0342 0.0378\n6  0.0391 0.0355 0.0355 0.0318 0.0140 0.0000 0.0000 0.0069 0.0205 0.0241\n7  0.0391 0.0355 0.0355 0.0318 0.0140 0.0000 0.0000 0.0069 0.0205 0.0241\n8  0.0459 0.0423 0.0423 0.0386 0.0208 0.0069 0.0069 0.0000 0.0136 0.0171\n9  0.0592 0.0556 0.0556 0.0519 0.0342 0.0205 0.0205 0.0136 0.0000 0.0034\n10 0.0629 0.0592 0.0592 0.0556 0.0378 0.0241 0.0241 0.0171 0.0034 0.0000\n\n\nWhat we see above is a square dissimilarity matrix. The most important characteristics of the matrix are:\n\nwhereas the raw species data, \\(Y\\), is rectangular (number rows ≠ number columns), the dissimilarity matrix is square (number rows = number columns);\nthe diagonal is filled with 0;\nthe matrix is symmetrical—it is comprised of symetrical upper and lower triangles.\n\nCreate a data.frame suitable for plotting:\n\nsor_df &lt;- data.frame(round(as.matrix(sor), 4))\n\n\n\n\n\n\n\nLab 3\n\n\n\n(To be reviewed by BCB743 student but not for marks)\nThese questions concern matrices produced from species data using any of the indices available in vegdist():\n\nWhy is the matrix square, and what determines the number of rows/columns?\nWhat is the meaning of the diagonal?\nWhat is the meaning of the non-diagonal elements?\nReferring to the seaweed species data specifically, take the data in row 1 or column 1 and create a line graph showing these values as a function of the section number.\nProvide a mechanistic (ecological) explanation for why this figure takes the shape that it does. Which community assembly process does this hint at? \n\n\n\n\n\n\n\n\n\n\nThere are different interpretations linked to \\(\\beta\\)-diversity, each telling us something different about community formation processes.\n\n\nSpecies turnover and nestedness-resultant \\(\\beta\\)-diversity\nThere are two kinds of \\(\\beta\\)-diversity: species turnover and nestedness-resultant \\(\\beta\\)-diversity. The former is the result of species replacement between sites, whereas the latter is the result of species loss or gain between sites. The Sørensen dissimilarity index, \\(\\beta_\\text{sør}\\), can be decomposed into these two components.\nHow do we calculate the turnover and nestedness-resultant components of \\(\\beta\\)-diversity? The betapart package (Baselga et al. 2022) comes to the rescue. We decompose the dissimilarity into the \\(\\beta_\\text{sim}\\) and \\(\\beta_\\text{sne}\\) components (Baselga 2010) using the betapart.core() and betapart.pair() functions. The outcomes of this partitioning calculation are placed into the matrices \\(Y1\\) and \\(Y2\\). These data can then be analysed further—e.g. we can apply a principal components analysis (PCA) or another multivariate analysis on \\(Y\\) to find the major patterns in the community data—we will do this in BCB743.\n\n# Decompose total Sørensen dissimilarity into turnover and nestedness-resultant\n# components:\nY.core &lt;- betapart.core(spp)\nY.pair &lt;- beta.pair(Y.core, index.family = \"sor\")\n\n# Let Y1 be the turnover component (beta-sim):\nY1 &lt;- data.frame(round(as.matrix(Y.pair$beta.sim), 3))\n\n# Let Y2 be the nestedness-resultant component (beta-sne):\nY2 &lt;- data.frame(round(as.matrix(Y.pair$beta.sne), 3))\n\nA portion of the turnover component matrix:\n\nY1[1:10, 1:10]\n\n      X1    X2    X3    X4    X5    X6    X7    X8    X9   X10\n1  0.000 0.000 0.000 0.000 0.007 0.022 0.022 0.022 0.022 0.029\n2  0.000 0.000 0.000 0.000 0.007 0.022 0.022 0.022 0.022 0.029\n3  0.000 0.000 0.000 0.000 0.007 0.022 0.022 0.022 0.022 0.029\n4  0.000 0.000 0.000 0.000 0.007 0.021 0.021 0.021 0.021 0.029\n5  0.007 0.007 0.007 0.007 0.000 0.014 0.014 0.014 0.014 0.021\n6  0.022 0.022 0.022 0.021 0.014 0.000 0.000 0.000 0.000 0.007\n7  0.022 0.022 0.022 0.021 0.014 0.000 0.000 0.000 0.000 0.007\n8  0.022 0.022 0.022 0.021 0.014 0.000 0.000 0.000 0.000 0.007\n9  0.022 0.022 0.022 0.021 0.014 0.000 0.000 0.000 0.000 0.000\n10 0.029 0.029 0.029 0.029 0.021 0.007 0.007 0.007 0.000 0.000\n\n\nA portion of the nestedness-resultant matrix:\n\nY2[1:10, 1:10]\n\n      X1    X2    X3    X4    X5    X6    X7    X8    X9   X10\n1  0.000 0.004 0.004 0.007 0.018 0.017 0.017 0.024 0.037 0.034\n2  0.004 0.000 0.000 0.004 0.014 0.014 0.014 0.021 0.034 0.030\n3  0.004 0.000 0.000 0.004 0.014 0.014 0.014 0.021 0.034 0.030\n4  0.007 0.004 0.004 0.000 0.011 0.010 0.010 0.017 0.030 0.027\n5  0.018 0.014 0.014 0.011 0.000 0.000 0.000 0.007 0.020 0.017\n6  0.017 0.014 0.014 0.010 0.000 0.000 0.000 0.007 0.021 0.017\n7  0.017 0.014 0.014 0.010 0.000 0.000 0.000 0.007 0.021 0.017\n8  0.024 0.021 0.021 0.017 0.007 0.007 0.007 0.000 0.014 0.010\n9  0.037 0.034 0.034 0.030 0.020 0.021 0.021 0.014 0.000 0.003\n10 0.034 0.030 0.030 0.027 0.017 0.017 0.017 0.010 0.003 0.000\n\n\nA portion of the nestedness-resultant matrix reformatted as a tibble()2:\n2 Note that the rows are no longer numbered in the tibble view, but it can easily be recreated by seq(1:58).\nY2_tib &lt;- as_tibble(Y2)\nhead(Y2_tib)\n\n# A tibble: 6 × 58\n     X1    X2    X3    X4    X5    X6    X7    X8    X9   X10   X11   X12   X13\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0     0.004 0.004 0.007 0.018 0.017 0.017 0.024 0.037 0.034 0.069 0.078 0.196\n2 0.004 0     0     0.004 0.014 0.014 0.014 0.021 0.034 0.03  0.065 0.074 0.193\n3 0.004 0     0     0.004 0.014 0.014 0.014 0.021 0.034 0.03  0.065 0.074 0.193\n4 0.007 0.004 0.004 0     0.011 0.01  0.01  0.017 0.03  0.027 0.062 0.071 0.19 \n5 0.018 0.014 0.014 0.011 0     0     0     0.007 0.02  0.017 0.052 0.061 0.181\n6 0.017 0.014 0.014 0.01  0     0     0     0.007 0.021 0.017 0.053 0.062 0.184\n# ℹ 45 more variables: X14 &lt;dbl&gt;, X15 &lt;dbl&gt;, X16 &lt;dbl&gt;, X17 &lt;dbl&gt;, X18 &lt;dbl&gt;,\n#   X19 &lt;dbl&gt;, X20 &lt;dbl&gt;, X21 &lt;dbl&gt;, X22 &lt;dbl&gt;, X23 &lt;dbl&gt;, X24 &lt;dbl&gt;,\n#   X25 &lt;dbl&gt;, X26 &lt;dbl&gt;, X27 &lt;dbl&gt;, X28 &lt;dbl&gt;, X29 &lt;dbl&gt;, X30 &lt;dbl&gt;,\n#   X31 &lt;dbl&gt;, X32 &lt;dbl&gt;, X33 &lt;dbl&gt;, X34 &lt;dbl&gt;, X35 &lt;dbl&gt;, X36 &lt;dbl&gt;,\n#   X37 &lt;dbl&gt;, X38 &lt;dbl&gt;, X39 &lt;dbl&gt;, X40 &lt;dbl&gt;, X41 &lt;dbl&gt;, X42 &lt;dbl&gt;,\n#   X43 &lt;dbl&gt;, X44 &lt;dbl&gt;, X45 &lt;dbl&gt;, X46 &lt;dbl&gt;, X47 &lt;dbl&gt;, X48 &lt;dbl&gt;,\n#   X49 &lt;dbl&gt;, X50 &lt;dbl&gt;, X51 &lt;dbl&gt;, X52 &lt;dbl&gt;, X53 &lt;dbl&gt;, X54 &lt;dbl&gt;, …\n\n\n\n\n\n\n\n\nLab 3 (continue)\n\n\n\n(To be reviewed by BCB743 student but not for marks)\n\nPlot species turnover as a function of Section number, and provide a mechanistic explanation for the pattern observed.\nBased on an assessment of literature on the topic, provide a discussion of nestedness-resultant \\(\\beta\\)-diversity. Use either a marine or terrestrial example to explain this mode of structuring biodiversity (i.e. assembly of species into a community). \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubmission Instructions\n\n\n\nThe Lab 3 assignment is due at 07:00 on Monday 12 August 2022.\nProvide a neat and thoroughly annotated R file which can recreate all the graphs and all calculations. Written answers must be typed in the same file as comments.\nPlease label the R file as follows:\n\nBDC334_&lt;first_name&gt;_&lt;last_name&gt;_Lab_3.R\n\n(the &lt; and &gt; must be omitted as they are used in the example as field indicators only).\nSubmit your appropriately named R documents on iKamva when ready.\nFailing to follow these instructions carefully, precisely, and thoroughly will cause you to lose marks, which could cause a significant drop in your score as formatting counts for 15% of the final mark (out of 100%).",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 3. Quantifying Biodiversity"
    ]
  },
  {
    "objectID": "BCB744/intro_r/04-graphics.html#geom_-the-pipe-or-and-the-sign",
    "href": "BCB744/intro_r/04-graphics.html#geom_-the-pipe-or-and-the-sign",
    "title": "4. Graphics with ggplot2",
    "section": "\ngeom_*(), the pipe (%>% or |>), and the + sign",
    "text": "geom_*(), the pipe (%&gt;% or |&gt;), and the + sign\nAs part of the tidyverse (as we saw briefly on Day 1, and will go into in depth on Day 4), the ggplot2 package endeavours to use a clean, easy for humans to understand syntax that relies heavily on functions that do what they say. For example, the function geom_point() makes points on a figure. Need a line plot? geom_line() is the way to go! Need both at the same time? No problem. In ggplot2 we may seamlessly merge a nearly limitless number of objects together to create startlingly sophisticated figures. Before we go over the code below, it is very important to note the use of the + signs. This is different from the pipe symbol (|&gt; or %&gt;%) used elsewhere in the tidyverse. The + sign indicates that one set of geometric features is added to another, each building on top of what came before. In other words, we add one geometry on top of the next, and in such a way we can arrive at complex graphical representations of data. Effectively, each line of code represents one new geometric feature with its own aesthetic appearance of the figure. It is designed this way so as to make it easier for the human eye to read through the code.\n\n\n\n\n\n\n+ signs in ggplot() code\n\n\n\nOne may see below that the code naturally indents itself if the previous line ended with a + sign. This is because R knows that the top line is the parent line and the indented lines are it’s children. This is a concept that will come up again when we learn about tidying data. What we need to know now is that a block of code that has + signs, like the one below, must be run together. As long as lines of code end in +, R will assume that you want to keep adding lines of code (more geometric features). If we are not mindful of what we are doing we may tell R to do something it cannot and we will see in the console that R keeps expecting more + signs. If this happens, click inside the console window and push the esc button to cancel the chain of code you are trying to enter.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "4. Graphics with ggplot2"
    ]
  },
  {
    "objectID": "BCB744/intro_r/04-graphics.html#aes",
    "href": "BCB744/intro_r/04-graphics.html#aes",
    "title": "4. Graphics with ggplot2",
    "section": "aes()",
    "text": "aes()\nAnother recurring function within the parent ggplot() function or the associated geom_*() is aes(). The aes() function in ggplot2 is used to specify the mapping between variables in a dataframe and visual properties of a plot. aes() stands for ‘aesthetic,’ which refers to the visual elements of a plot, such as colour, size, shape, etc. In ggplot2, the aesthetics of a plot are defined inside the aes() function, which is passed as an argument to the base ggplot() function or its associated geometry.\nFor example, if you have a dataframe with two variables x and y, you can create a scatterplot of x against y by calling ggplot(data, aes(x, y)) + geom_point(). The aes(x, y) function maps the variables (columns) in the dataframe to the x and y positions of the points in the scatterplot. Similarly, we can map variables in the dataframe to aesthetic properties of the geometric features, such as colour (e.g. a colour might be more internse as the magnitude of the values in a column increase), size (larger symbols for bigger values), transparency, etc.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "4. Graphics with ggplot2"
    ]
  },
  {
    "objectID": "BCB744/intro_r/09-mapping_rnaturalearth.html",
    "href": "BCB744/intro_r/09-mapping_rnaturalearth.html",
    "title": "9. Mapping With Natural Earth and the sf Package",
    "section": "",
    "text": "“In the beginning there was nothing, which exploded.”\n— Terry Pratchett\n\n\n“Biology is the study of complicated things that have the appearance of having been designed with a purpose.”\n— Richard Dawkins\n\nWeb resources about R for Spatial Applications\nNow that we are upgrading to better, more powerful maps, you’ll need to refer to industrial-strength documentation for detailed help. Please refer to links below for information about the vast array of functions available for spatial computations and graphics.\n\n\n\n\n\n\nWeb resources about spatial methods in R\n\n\n\n\n\nAUTHOR\nTITLE\n\n\n\nSpatial R\n\n\n\nEdzer Pebesma\nSimple Features for R\n\n\nEdzer Pebesma, Roger Bivand\nSpatial Data Science with applications in R\n\n\nRobin Lovelace et al.\nGeocomputation with R\n\n\nManuel Gimond\nIntro to GIS and Spatial Analysis\n\n\nWasser et al.\nIntroduction to Geospatial Raster and Vector Data with R\n\n\nTaro Mieno\nR as GIS for Economists\n\n\n\n\n\nThe sf package\nThe sf package in R is a package for handling and processing spatial data. In recent years it has become the de facto package to use for many mapping application, replacing older packages such as sp and including the C libraries GEOS 3, GDAL, and PROJ. It provides classes for storing and manipulating simple feature geometries, and functions for working with spatial data. ‘Simple features’ refer to a standardised way of encoding vector data, including points, lines, and polygons, that are widely used in geographic information systems (GIS).\nThe sf package was created to provide a fast and efficient way to work with vector data in R, and it is designed to integrate with other packages in the tidyverse, such as dplyr and ggplot2, allowing for seamless processing and visualisation of spatial data. The package provides a variety of functions for data import, transformation, manipulation, and analysis, making it a valuable tool for working with spatial data in R.\nIn addition to its core functionality, the sf package also provides a set of methods for converting between different data representations, such as data frames, matrices, and lists, making it a versatile tool for working with spatial data in a variety of formats.\nWhile sf works with vector data, raster data require the well-known but old raster package, or its modern replacements terra and stars. I will not work with raster data in this Chapter.\nMaps with rnaturalearth\n\nNatural Earth is a public domain map dataset that provides high-quality, general-purpose base maps for the world at various scales. It was designed to be a visually pleasing alternative to other public domain datasets, and its creators aim to provide the data in a form that is useful for a wide range of applications and to make it easy to use and integrate with other data.\nThe dataset includes a variety of geographic features, including coastlines, rivers, lakes, and political boundaries, as well as cultural features like cities, roads, and railways. The data are available in several different formats, including vector and raster, and it can be used with a variety of software, including GIS and mapping applications. Within R we can access these map layers using the rnaturalearth package.\nOne of the key benefits of Natural Earth is its public domain status, which means that anyone can use and distribute the data without restrictions or licensing fees. This makes it an ideal choice for individuals who need high-quality base maps for their projects but may not have the resources or expertise to create them from scratch. I am not convinced that students actually read this. The first person to send me a WhatsApp mentioning the phrase “Know your maps” will get a Lindt chocolate.\nIn addition to its public domain status, Natural Earth is also regularly updated with new data to ensure that the maps remain accurate and up-to-date. This makes it a valuable resource for anyone who needs reliable and up-to-date geographic data.\nInstall packages and set things up\n\n# install.packages(\"rnaturalearth\", \"rnaturalearthdata\", \"sf\")\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\n\n# for the buffer to work as I expect, swith off\n# the functions for spherical geometry:\nsf_use_s2(FALSE)\n\nFirst, I define the extent of the map region:\n\n# the full map extent:\nxmin &lt;- 12; ymin &lt;- -36.5; xmax &lt;- 40.5; ymax &lt;- -10\nxlim &lt;- c(xmin, xmax); ylim &lt;- c(ymin, ymax)\n\n# make a bounding box for cropping:\nbbox &lt;- st_bbox(c(xmin = xmin, ymin = ymin,\n  xmax = xmax, ymax = ymax))\n\n# might be useful for zooming into a smaller region (False Bay and \n# the Cape Peninsula):\nxlim_zoom &lt;- c(17.8, 19); ylim_zoom &lt;- c(-34.5, -33.2)\n\nLoad the data and make maps\n\n# load the countries:\nsafrica_countries &lt;- ne_countries(returnclass = 'sf',\n  continent = \"Africa\",\n  country = c(\"South Africa\", \"Mozambique\",\n    \"Namibia\", \"Zimbabwe\", \"Botswana\",\n    \"Lesotho\", \"Eswatini\"),\n  scale = \"large\")\n\nLet us see what is inside the safrica_countries object:\n\nclass(safrica_countries)\n\nR&gt; [1] \"sf\"         \"data.frame\"\n\n# safrica_countries\n\nAs you can see, it is a data.frame and tbl (tibble), amongst other classes, and so you can apply many of the tidyverse functions to it, including select(), filter(), summarise() and so on. The class() argument additionally indicates that it has some simple features properties, so some functions provided by the sf package also becomes available to use. You can see some of these functions in action, below.\n\n\n\n\n\n\nThe sf class\n\n\n\nsf indicates that the object is of class simple features. In sf language, what would be called columns (variables) in normal tidyverse speak becomes known as attributes—these are the properties of the map features, with the features being the types of geometrical representations of geographical objects.\n\n\nLet us plot the entire safrica_countries object to see all the attributes of all of the features. This kind of figure a called a choropleth map:\n\nplot(safrica_countries)\n\n\n\n\n\n\n\nYou probably don’t want to plot all of them. Let us select one:\n\nplot(safrica_countries[\"sovereignt\"])\n\n\n\n\n\n\n\nYou might achieve the same in a more familiar way:\n\nsafrica_countries |&gt; \n  select(sovereignt) |&gt; \n  plot()\n\n\n\n\n\n\n\nOr you may want to plot the estimate of the population size, which is contained in the attribute pop_est:\n\nsafrica_countries |&gt; \n  select(pop_est) |&gt; \n  plot()\n\n\n\n\n\n\n\nThe names of the countries are in the rows down the safrica_countries object, and so they become accessible with filter(). Let us only plot some attribute for South Africa:\n\nsafrica_countries |&gt; \n  dplyr::filter(sovereignt == \"South Africa\") |&gt; \n  select(sovereignt) |&gt; \n  plot()\n\n\n\n\n\n\n\nYou can continue to add additional operations to create a new map:\n\nsafrica_countries_new &lt;- safrica_countries |&gt; \n  group_by(continent) |&gt; \n  summarise() |&gt; \n  st_crop(bbox) |&gt;\n  st_combine()\n\nplot(safrica_countries_new)\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask F\n\n\n\n\nPlease explain in English what the code above does, line by line.\n\n\n\nSo far you have relied on the base R plot function made for the simple features. You can also plot the map in ggplot using a more familiar and more customisable interface:\n\nggplot() +\n  geom_sf(data = safrica_countries,\n    colour = \"indianred\", fill = \"beige\") +\n  coord_sf(xlim = xlim,\n           ylim = ylim)\n\n\n\n\n\n\n\nNow you can layer another feature:\n\nbuffer &lt;- safrica_countries_new %&gt;%\n  st_buffer(0.4)\n\nggplot() +\n  geom_sf(data = buffer, fill = \"lightblue\", col = \"transparent\") +\n  geom_sf(data = safrica_countries, colour = \"indianred\", fill = \"beige\") +\n  theme_minimal()\n\n\n\n\n\n\n\nExample\nHere are examples that use the built-in Fiji earthquake data or the Kaggle earthquake data.\n\n\n\n\n\n\nTask F\n\n\n\nWhat’s going on in the above figure?\n\nWhy are we now again plotting the full, original map extent to the south?\nWhat does st_buffer(0.4) do?\nWith the above map, zoom into False Bay and the Cape Peninsula.\nCreate your own map of your favourite country (not South Africa).\n\n\nMake sure that the country is displayed inside of the continent where it is located, and ensure that the border of your country stands out from the surrounding countries.\nIndicate on the map using points the names of three places you want to visit there.\n\nCreate the most beautiful graphs you can.\n\n\n\n\n\n\n\n\nBonus Task\n\n\n\nSuccessfully completing on of the options available in this task will earn you a bonus of up to 8 or 10% onto your CA mark.\nYou have until 1 April 2023 to complete it.\n\nA map that is worthy of display will become a large format poster to display in the BCB Department. Your name displayed next to it will immortalise you for continued fame and glory amongst future BCB students.\nThe winner of each category of map (hypometric and non-hypsometric) will also get a box of Lindt chocolate.\n\nOption 1 [up to 10% bonus]: Create a hypsometric map based on these examples\n\nThe maps show the locations of linefish catches along the SA coast as per a DFFE dataset. I do not expect that you add these data points as you don’t have access to this dataset. However, the location of the 58 coastal sections indicated by circles can be plotted using the data provided here. You are also welcome to create a map of any topographically-interesting region on Earth, but be sure to include a few data points of some kind to draw our attention to some interesting features or statistics. Be creative!\nSince I think a few of you might actually accomplish this, best add a few improvements to it to make your map even better than mine and stand out from that of your peers. There can be only one winner in each category, and the best one wins (although everyone can benefit from the bonus marks).\nWarning: You’ll need a fairly beefy computer to accomplish this task.\nOption 2 [up to 8% bonus]: Create an artistic map of your choice\nAlternatively, if you cannot access a powerful computer, for a bonus of up to 8% onto your CAM, create any (non-hypsometric) map of your choice of any region on Earth. Make something that you would be proud to display as a large format poster. The map may draw attention to an interesting regional geophysical, ecological, or socio-ecological (etc.) phenomena, or it may simply showcase your unique (but tasteful!) artistic ability. Show me some examples of what you wish to create before you start to avoid wasting your time on something too simple or entirely tasteless. There are many examples of beautiful maps on the internet that you may use as source of inspiration.\nWhichever option you choose, please also submit your code together with the final product in a well-described Quarto .html document. Explain each step of the way and describe the rationale for the approach you take.\nGood luck!\n\n\n\n\n\n\nReuseCC BY-NC-SA 4.0CitationBibTeX citation:@online{j._smit2021,\n  author = {J. Smit, Albertus},\n  title = {9. {Mapping} {With} {Natural} {Earth} and the **Sf**\n    {Package}},\n  date = {2021-01-01},\n  url = {http://tangledbank.netlify.app/BCB744/intro_r/09-mapping_rnaturalearth.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A (2021) 9. Mapping With Natural Earth and the **sf** Package.\nhttp://tangledbank.netlify.app/BCB744/intro_r/09-mapping_rnaturalearth.html.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "9. Mapping With Natural Earth and the **sf** Package"
    ]
  },
  {
    "objectID": "BCB744/intro_r/02-working-with-data.html",
    "href": "BCB744/intro_r/02-working-with-data.html",
    "title": "2. Working With Data and Code",
    "section": "",
    "text": "In this Chapter we will cover:",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "2. Working With Data and Code"
    ]
  },
  {
    "objectID": "BCB744/intro_r/02-working-with-data.html#comma-separated-value-files",
    "href": "BCB744/intro_r/02-working-with-data.html#comma-separated-value-files",
    "title": "2. Working With Data and Code",
    "section": "Comma separated value files",
    "text": "Comma separated value files\nCSV stands for ‘Comma Separated Value’. A CSV file is a simple text file that stores data in a tabular format, with each row representing a record and each column representing a field of data. In a CSV file, each data value is separated by a comma (or sometimes another delimiter such as a semicolon or tab), and each row is terminated by a new line.\nCSV files are widely used in data analysis and can be opened and edited by most spreadsheet software, such as MS Excel and Google Sheets. Being comprised of plain text (ASCII), they are often used to import and export data between different applications or systems, as they provide a standardised format that can be easily parsed by software.\nCSV files are easy to create and use, and they have the advantage of being lightweight and easy to read and write by both humans and machines. However, they can be limited in their ability to represent complex data structures or to handle large amounts of data efficiently. Additionally, if our data contain certain kinds of special characters, this can cause problems with parsing the file correctly.\nWe will most frequently use the functions read.csv() or readr::read_csv() (and related forms) for reading in CSV data. We can write CSV files to disk with the write.csv() or readr::write_csv() commands. For very large datasets that might take a long time to read in or save, data.table::fread() or data.table::fwrite() are faster alternatives to the aforementioned base R or tidyverse options. Even faster options are feather::read_feather() and feather::write_feather(); although feather saves tabular data, the format is not actually an ASCII CSV, however.\n\n\n\n\n\n\nASCII files\n\n\n\nASCII stands for “American Standard Code for Information Interchange”. An ASCII file is a plain text file that contains ASCII characters. ASCII is a character encoding standard that assigns a unique numeric code to each character, including letters, numbers, punctuation, and other symbols commonly used in the English language.\nASCII files are the most basic type of text file and are supported by virtually all operating systems and applications. We can create and edit ASCII files using any text editor, such as Notepad, TextEdit, or VS Code. ASCII files are typically used for storing and sharing simple text-based information, such as program source code, configuration files, and other types of data that do not require special formatting or rich media content.\nASCII files are limited in their ability to represent non-English characters or symbols that are not included in the ASCII character set. To handle these types of characters, other character encoding standards such as UTF-8 or Unicode are used. However, ASCII files remain an important and widely used format for storing and sharing simple text-based data.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "2. Working With Data and Code"
    ]
  },
  {
    "objectID": "BCB744/intro_r/02-working-with-data.html#tab-separated-value-files",
    "href": "BCB744/intro_r/02-working-with-data.html#tab-separated-value-files",
    "title": "2. Working With Data and Code",
    "section": "Tab separated value files",
    "text": "Tab separated value files\nThe primary difference between a ‘tab-separated value’ (TSV) file and a ‘comma-separated values’ (CSV) file lies in the delimiter used to separate data fields. Both file formats are plain text ASCII files used to store data in a tabular format, but they employ different characters to distinguish individual fields within each row.\nIn a TSV file, the fields are separated by tab characters (represented as \\t in many programming languages). This format is particularly useful when dealing with data that include commas within the values, as it avoids potential conflicts and parsing issues.\nCSV files are more common and widely supported than TSV files. However, they can present difficulties when the data itself contains commas, potentially causing confusion between actual field separators and commas within the data. To mitigate this issue, values containing commas are often enclosed in quotation marks.\nLike CSV files, TSV can also be imported into and exported from spreadsheet software like Excel, or read and manipulated using programming languages like Python, R, and many others. The choice between TSV and CSV largely depends on the nature of the data and personal preferences, but it’s crucial to be aware of the delimiter used in order to accurately parse the files. The same functions that read or write CSV files in R can be used for TSV, but one has to set the arguments sep = \"\\t\" or delim = \"\\t\" for the functions read.csv() and read_csv() respectively.\n\n\n\n\n\n\nMissing values and CSV and TSV files\n\n\n\nWhere we have missing data (blanks), the CSV format separates these by commas with empty field in-between. However, there can be problems with blanks if we read in a space-delimited format file. If we are having trouble reading in missing data as blanks, try replacing them in the spreadsheet with NA, the missing data code in R. In Excel, highlight the area of the spreadsheet that includes all the cells we need to fill with NA. Do an ‘Edit/Replace…’ and leave the ‘Find what:’ text box blank and in the ‘Replace with:’ text box enter NA. Once imported into R, the NA values will be recognised as missing data.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "2. Working With Data and Code"
    ]
  },
  {
    "objectID": "BCB744/intro_r/02-working-with-data.html#microsoft-excel-files",
    "href": "BCB744/intro_r/02-working-with-data.html#microsoft-excel-files",
    "title": "2. Working With Data and Code",
    "section": "Microsoft Excel files",
    "text": "Microsoft Excel files\nMicrosoft Excel files are a type of file format that is used to store data in a tabular form, much like CSV files. However, Excel files are proprietary and are specifically designed to work with Excel software. Excel files can contain more advanced formatting features such as colours, fonts, and formulas, which make them a popular choice for people who like embellishments. But, as much as I dislike Excel as a software for data analysis, Excel files are definitely a good option for data entry.\nUsing MS Excel for data analysis can be a terrible idea for a number of reasons:\n\nCompatibility Excel files may not be compatible with all data science tools and programming languages. For example, R cannot read Excel files directly.\nData integrity Excel files can be prone to errors and inconsistencies in the data. For example, if a user changes a formula or formatting, it could affect the entire dataset. Also, it is possible for Excel to change the data types of certain columns, or to mix the class of data within a column, which can cause issues with data processing and analysis.\nFile size Excel files can quickly become very large when dealing with large datasets, which can lead to performance issues and storage problems.\nVersion control Excel files can make it difficult to keep track of changes and versions of the data, particularly when multiple people are working on the same file.\n\nIn contrast, CSV files are a simple, lightweight, and widely supported file format that can be easily used with most data science tools and programming languages. CSV files are also less prone to errors and inconsistencies than Excel files, making them a more reliable choice for data science tasks.\nSo, while Excel files may be useful for certain tasks such as initial data entry, they are generally not recommended for use in data science due to their potential for errors (see box “Well-known Excel errors”), incompatibility, and other issues. I recommend exporting data deliberately to CSV files. This not only avoids complications, but also allows us to unambiguously identify the data we based our analysis on. This last statement should give us the hint that it is good practice to name our .csv slightly differently each time we export it from Excel, perhaps by appending a reference to the date it was exported. Also, for those of us who use commas in Excel as the decimal separator, or to separate 1000s, undo these features now.\n\n\n\n\n\n\nWell-known Excel errors\n\n\n\nExcel is a widely used spreadsheet application, but it has been responsible for several serious errors in data analysis, science, and data science. Some of these errors include:\n\nGene name errors In 2016, researchers discovered that Excel automatically converted gene symbols to dates or floating-point numbers. For example, gene symbols like SEPT2 (Septin 2) were converted to “2-Sep” and gene symbols like MARCH1 (Membrane Associated Ring-CH-Type Finger 1) were converted to “1-Mar”. This led to errors and inconsistencies in genetic data, affecting nearly 20% of published papers in leading genomic journals.\nReinhart-Rogoff controversy In 2010, economists Carmen Reinhart and Kenneth Rogoff published a paper arguing that high levels of public debt were associated with lower economic growth. Their findings influenced policy decisions worldwide. However, in 2013, other researchers found that Reinhart and Rogoff’s results were affected by an Excel spreadsheet error that excluded some data points, causing them to overstate the relationship between debt and growth.\nLondon Whale incident In 2012, JPMorgan Chase, a leading financial institution, suffered a trading loss of over $6 billion, partially due to an Excel error. The bank’s model for calculating the risk of their trades, implemented in Excel, used incorrect formulas that significantly underestimated the risk involved. The event, which became known as the “London Whale” incident, highlighted the potential consequences of relying on Excel for complex financial models.\nTruncation of large numbers Excel can handle only a limited number of digits for large numbers, truncating any value that exceeds this limit. This truncation has lead to a loss of precision and inaccurate calculations in scientific and data analysis contexts, where exact values were important.\nIssues with floating-point arithmetic Excel uses floating-point arithmetic, which can cause rounding errors and imprecise results when working with very large or very small numbers. These inaccuracies can lead to incorrect conclusions or predictions in data analysis and scientific research.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "2. Working With Data and Code"
    ]
  },
  {
    "objectID": "BCB744/intro_r/02-working-with-data.html#rdata-files",
    "href": "BCB744/intro_r/02-working-with-data.html#rdata-files",
    "title": "2. Working With Data and Code",
    "section": "Rdata files",
    "text": "Rdata files\nRdata files are a file format used by the R programming language to store data objects. These files can contain any type of R object, such as vectors, matrices, dataframes, lists, and more. Rdata files are binary files, which means they are not human-readable like text files such as CSV files. Binary R data files have a .rda or .Rdata file extension and can be created or read using the save() and load(), respectively, functions in R.\nRdata files are convenient for a number of reasons:\n\nEfficient storage Rdata files can be more compact (they can be compressed) and efficient than other file formats, such as CSV files, because they are stored in a binary format. This means they take up less disk space and can be read and written to faster.\nEasy access to R objects Rdata files make it easy to save and load R objects, which can be useful for preserving data objects for future analysis or sharing them with others. This is especially useful for complex datasets or objects that would be difficult to recreate.\nPreserve metadata Rdata files can preserve metadata such as variable names, row and column names, and other attributes of R objects. This makes it easier to work with the data objects in the future without having to recreate this metadata.\nConvenient for reproducibility Rdata files can be used to save and load data objects as part of a reproducible research workflow. This can help ensure that data objects are preserved and can be easily accessed in the future, even if the data sources or code have changed.\n\nOn the downside, they can only be used within R, making them a less than ideal proposition when you intend sharing your data with colleagues who sadly do not use R.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "2. Working With Data and Code"
    ]
  },
  {
    "objectID": "BCB744/intro_r/02-working-with-data.html#other-binary-files",
    "href": "BCB744/intro_r/02-working-with-data.html#other-binary-files",
    "title": "2. Working With Data and Code",
    "section": "Other binary files",
    "text": "Other binary files\nAs a biostatistician, you may encounter several other binary data files in your work. Such binary data files may be software-specific and can be used to store large datasets or data objects that are not easily represented in a text format. For example, a binary data file might contain a large matrix or array of numeric data that would be difficult to store in a text file. Binary data files can also be used to store images, audio files, and other types of data that are not represented as text.\nOne common type of binary data file that you may encounter as a statistician is a SAS data file. SAS is a statistical software package that is widely used in data analysis, and SAS data files are a binary format used to store datasets in SAS. These files typically have a .sas7bdat file extension and contain metadata such as variable names and formats in addition to the data itself. Another type of binary data file you may encounter is a binary .mat data file, which is a file format used to store Matlab data.\nWhen working with binary data files, it is important to be aware of the specific format of the file and the tools and software needed to read and manipulate the data. Some statistical software packages may have built-in functions for reading and writing certain types of binary data files, while others may require additional libraries or packages.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "2. Working With Data and Code"
    ]
  },
  {
    "objectID": "BCB744/intro_r/02-working-with-data.html#netcdf-grib-and-hdf-files",
    "href": "BCB744/intro_r/02-working-with-data.html#netcdf-grib-and-hdf-files",
    "title": "2. Working With Data and Code",
    "section": "NetCDF, Grib, and HDF files",
    "text": "NetCDF, Grib, and HDF files\nNetCDF, HDF, and GRIB are file formats commonly used in the scientific and research communities to store and share large and complex datasets. While CSV files are a simple and widely used format, they can become impractical for large datasets with complex structures or metadata. Here’s a brief overview of each file format:\n\nNetCDF (Network Common Data Form) is a binary file format that is designed for storing and sharing scientific data. It can store multidimensional arrays and metadata, such as variable names and units, in a self-describing format. NetCDF files are commonly used in fields such as atmospheric science, oceanography, and climate modelling.\nHDF (Hierarchical Data Format) is a file format that is designed to store and organise large and complex data structures. It can store a wide variety of data types, including multidimensional arrays, tables, and hierarchical data. HDF files are commonly used in fields such as remote sensing, astronomy, and engineering.\nGRIB (GRIdded Binary) is a binary file format used to store meteorological and oceanographic data. It can store gridded data, such as atmospheric or oceanic model output, in a compact and efficient binary format. GRIB files are commonly used by weather forecasting agencies and research organisations.\n\nCompared to CSV files, these file formats offer several benefits for storing and sharing complex datasets:\n\nSupport for multidimensional arrays These file formats can store and handle multidimensional arrays, which cannot be represented in a CSV file.\nEfficient storage Binary file formats can be more compact and efficient than text-based formats such as CSV files, which can save disk space and make it easier to share and transfer large datasets.\nMemory use efficiency NetCDF, GRIB, and HDF files are better for memory use efficiency compared to CSV files because they can store multidimensional arrays and metadata in a compact binary format, which can save disk space and memory when working with large and complex datasets. Also, they do not have to be read into memory all at once.\nSelf-describing metadata These file formats can include metadata, such as variable names and units, which are self-describing and can be easily accessed and understood by other researchers and software.\nSupport for compression Binary file formats can support compression, which can further reduce file size and make it easier to share and transfer large datasets.\n\nThe various efficiencies mention above may be offset by them being quite challenging to work with, and as such novices might experience steep learning curves.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "2. Working With Data and Code"
    ]
  },
  {
    "objectID": "BCB744/intro_r/02-working-with-data.html#larger-than-memory-data",
    "href": "BCB744/intro_r/02-working-with-data.html#larger-than-memory-data",
    "title": "2. Working With Data and Code",
    "section": "Larger than memory data",
    "text": "Larger than memory data\nAbove we dealt with data that fit into your computer’s memory (RAM). However, there are many datasets that are too large to fit into memory, and as such, we need to use alternative methods to work with them. These methods include:\n\nApache Arrow in the arrow package in R, which has support for the ‘feather’ file format and ‘parquet’ files\nDuckDB in the duckdb package in R, which create a database on disk and can be queried using SQL\n\nI will develop vignettes for these in the future. We will not use these in this course, but it is important to be aware of them.",
    "crumbs": [
      "Home",
      "BCB744 Intro R",
      "2. Working With Data and Code"
    ]
  },
  {
    "objectID": "BDC334/02b-env_dist.html",
    "href": "BDC334/02b-env_dist.html",
    "title": "Lab 2b. Environmental Distance",
    "section": "",
    "text": "BCB743\n\n\n\nThis material must be reviewed by BCB743 students in Week 1 of Quantitative Ecology.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2b. Environmental Distance"
    ]
  },
  {
    "objectID": "BDC334/02b-env_dist.html#set-up-the-analysis-environment",
    "href": "BDC334/02b-env_dist.html#set-up-the-analysis-environment",
    "title": "Lab 2b. Environmental Distance",
    "section": "Set Up the Analysis Environment",
    "text": "Set Up the Analysis Environment\n\nlibrary(vegan)\nlibrary(ggplot2)\nlibrary(geodist) # to calculate geographic distances between lats/lons\nlibrary(ggpubr) # to arrange the multipanel graphs",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2b. Environmental Distance"
    ]
  },
  {
    "objectID": "BDC334/02b-env_dist.html#revisiting-euclidean-distance",
    "href": "BDC334/02b-env_dist.html#revisiting-euclidean-distance",
    "title": "Lab 2b. Environmental Distance",
    "section": "Revisiting Euclidean Distance",
    "text": "Revisiting Euclidean Distance\nThe toy data have arbitrary columns to demonstrate the Euclidean distance calculation:\n\\[ d(a,b) = \\sqrt{(a_x - b_x)^2 + (a_y - b_y)^2 + (a_z - b_z)^2} \\]\nThe distance is found between every pair of sites named a to g whose locations are marked by the ‘coordinates’ \\(x\\), \\(y\\), and \\(z\\)—i.e. this is an example of 3-dimensional data (a space or volume, as opposed to 2D data situated on a \\(x\\), \\(y\\) place). We might also call each coordinate a ‘variable’ (sometimes called a ‘dimension’) and hence we have multivariate or multidimensional data.\nLet’s load the dataset and find the size of the dataframe:\n\nxyz &lt;- read.csv(\"../data/Euclidean_distance_demo_data_xyz.csv\")\ndim(xyz)\n\n[1] 7 4\n\n\nThere are seven rows and four columns.\nThe data look like:\n\nxyz\n\n  site x y z\n1    a 4 1 3\n2    b 5 5 5\n3    c 6 6 4\n4    d 1 4 9\n5    e 2 3 8\n6    f 8 3 1\n7    g 9 1 5\n\n\nThe first column contains the site names and it must be excluded from subsequent calculations. The remaining three columns will be used below.\nCalculate the Euclidean distance using vegan’s vegdist() function and view the lower triangle with the diagonal:\n\nxyz_euc &lt;- round(vegdist(xyz[, 2:4], method = \"euclidian\",\n                         upper = FALSE, diag = TRUE), 4)\n# selected only cols 2, 3 and 4\nxyz_euc\n\n        1       2       3       4       5       6       7\n1  0.0000                                                \n2  4.5826  0.0000                                        \n3  5.4772  1.7321  0.0000                                \n4  7.3485  5.7446  7.3485  0.0000                        \n5  5.7446  4.6904  6.4031  1.7321  0.0000                \n6  4.8990  5.3852  4.6904 10.6771  9.2195  0.0000        \n7  5.3852  5.6569  5.9161  9.4340  7.8740  4.5826  0.0000\n\n\nConvert to a dataframe and view it:\n\nxyz_df &lt;- as.data.frame(as.matrix(xyz_euc))\nxyz_df\n\n       1      2      3       4      5       6      7\n1 0.0000 4.5826 5.4772  7.3485 5.7446  4.8990 5.3852\n2 4.5826 0.0000 1.7321  5.7446 4.6904  5.3852 5.6569\n3 5.4772 1.7321 0.0000  7.3485 6.4031  4.6904 5.9161\n4 7.3485 5.7446 7.3485  0.0000 1.7321 10.6771 9.4340\n5 5.7446 4.6904 6.4031  1.7321 0.0000  9.2195 7.8740\n6 4.8990 5.3852 4.6904 10.6771 9.2195  0.0000 4.5826\n7 5.3852 5.6569 5.9161  9.4340 7.8740  4.5826 0.0000\n\n\nDistance matrices have the same properties as dissimilarity matrices, i.e.:\n\nThe distance matrix is square (number rows = number columns).\nThe diagonal is filled with 0.\nThe matrix is symmetrical—it is comprised of symmetrical upper and lower triangles.\n\nIn terms of the meaning of the cell values, their interpretation is also analogous with that of the species dissimilarities. A value of 0 means the properties of the sites (or sections, plots, transects, quadrats, etc.) in terms of their environmental conditions are identical (this is always the case the the diagonal). The larger the number (which may be &gt;1) the more different sites are in terms of their environmental conditions.\nSince each column, \\(x\\), \\(y\\), and \\(z\\), is a variable, we can substitute them for actual variables or properties of the environment within which species are present. Let’s load such data (again fictitious):\n\nenv_fict &lt;- read.csv(\"../data/Euclidean_distance_demo_data_env.csv\")\nhead(env_fict, 2) # print first two rows only\n\n  site temperature depth light\n1    a           4     1     3\n2    b           5     5     5\n\n\nThese are the same data as in Euclidean_distance_demo_data_xyz.csv but I simply renamed the columns to names of the variables temperature, depth, and light intensity. I won’t repeat the analysis here as the output remains the same.\nNow apply vegdist() as before. The resultant distances are called ‘environmental distances’.\nLet us now use some real data.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2b. Environmental Distance"
    ]
  },
  {
    "objectID": "BDC334/02b-env_dist.html#a-look-at-the-seaweed-environmental-data",
    "href": "BDC334/02b-env_dist.html#a-look-at-the-seaweed-environmental-data",
    "title": "Lab 2b. Environmental Distance",
    "section": "A Look at the Seaweed Environmental Data",
    "text": "A Look at the Seaweed Environmental Data\nThese data accompany the analysis of the South African seaweed flora (Smit et al. 2017).\n\nload(\"../data/seaweed/SeaweedEnv.RData\")\n\n# lets look at the data\ndim(env)\n\n[1] 58 18\n\n\nWe see that the data have 58 rows and 18 columns… the same number of rows as the seaweed.csv data. What is in the first five rows?\n\nround(env[1:5, 1:5], 4)\n\n  febMean  febMax  febMed  febX95 febRange\n1 13.0012 18.7204 12.6600 16.8097   6.0703\n2 13.3795 18.6190 13.1839 17.0724   5.8893\n3 13.3616 17.8646 13.2319 16.6111   5.4314\n4 13.2897 17.1207 13.1028 16.1214   5.0490\n5 12.8113 16.3783 12.4003 15.5324   4.9779\n\n\nAnd the last five rows?\n\nround(env[(nrow(env) - 5):nrow(env), (ncol(env) - 5):ncol(env)], 4)\n\n   annRange  febSD  augSD annChl augChl febChl\n53   4.3707 1.0423 0.7735 4.3420 4.3923 4.6902\n54   4.3358 1.1556 0.9104 1.6469 2.2654 1.6930\n55   4.4104 1.1988 0.8427 0.2325 0.6001 0.5422\n56   4.6089 1.1909 0.6631 0.1321 0.4766 0.3464\n57   4.9693 1.1429 0.4994 0.1339 0.5845 0.3185\n58   5.5743 1.0000 0.3494 0.1486 0.7363 0.4165\n\n\nSo, each of the rows corresponds to a site (i.e. each of the coastal sections), and the columns each contains an environmental variable. The names of the environmental variables are:\n\ncolnames(env)\n\n [1] \"febMean\"  \"febMax\"   \"febMed\"   \"febX95\"   \"febRange\" \"augMean\" \n [7] \"augMin\"   \"augMed\"   \"augX5\"    \"augRange\" \"annMean\"  \"annSD\"   \n[13] \"annRange\" \"febSD\"    \"augSD\"    \"annChl\"   \"augChl\"   \"febChl\"  \n\n\nAs we have seen, there are 18 variables (or dimensions). These data are truly multidimensional in a way that far exceeds our brains’ limited ability to spatially visualise. For mathematicians these data define an 18-dimensional space, but all we can do is visualise 3-dimensions.\nWe select only some of the thermal variables; the rest are collinear with some of the ones I import:\n\n  env1 &lt;- dplyr::select(env, febMean, febRange, febSD, augMean,\n                    augRange, augSD, annMean, annRange, annSD)\n\nLet us make a quick graph of annMean as a function of distance along the coast (Figure 1).\n\nggplot(env1, aes(x = 1:58, y = annMean)) +\n  geom_line(colour = \"indianred\", size = 1.2) +\n  labs(x = \"Coastal section (west to east)\",\n       y = \"Temperature (°C)\") +\n  theme_linedraw()\n\n\n\n\n\n\nFigure 1: Line plot showing the trend in the mean annual seawater temperature along the coast from the west at Section 1 to Section 58 in the East.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2b. Environmental Distance"
    ]
  },
  {
    "objectID": "BDC334/02b-env_dist.html#z-scores",
    "href": "BDC334/02b-env_dist.html#z-scores",
    "title": "Lab 2b. Environmental Distance",
    "section": "\nz-Scores",
    "text": "z-Scores\nHere we need to do something new that was not necessary with the toy data. We calculate z-scores, and the process is called ‘standardisation’. Standardisation is necessary when the variables are measured in different units—e.g. the unit for temperature is °C whereas Ch-a is measured in mg Chl-a/m3.\n\nE1 &lt;- round(decostand(env1, method = \"standardize\"), 4)\nE1[1:5, 1:5]\n\n  febMean febRange   febSD augMean augRange\n1 -1.4915  -0.0443 -0.2713 -1.3765  -0.4735\n2 -1.4014  -0.1432 -0.1084 -1.4339  -0.0700\n3 -1.4057  -0.3932 -0.1720 -1.5269   0.0248\n4 -1.4228  -0.6020 -0.3121 -1.5797  -0.0508\n5 -1.5368  -0.6408 -0.4096 -1.5464  -0.0983\n\n\nFor comparison with the previous plot showing the raw data, let us now plot the standardised annMean data (Figure 2).\n\nggplot(E1, aes(x = 1:58, y = annMean)) +\n  geom_line(colour = \"indianred\", size = 1.2) +\n  labs(x = \"Coastal section (west to east)\",\n       y = \"Standardised temperature\")+\n  theme_linedraw()\n\n\n\n\n\n\nFigure 2: Line plot showing the trend in the standardised mean annual seawater temperature along the coast from the west at Section 1 to Section 58 in the East.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2b. Environmental Distance"
    ]
  },
  {
    "objectID": "BDC334/02b-env_dist.html#euclidean-distance",
    "href": "BDC334/02b-env_dist.html#euclidean-distance",
    "title": "Lab 2b. Environmental Distance",
    "section": "Euclidean Distance",
    "text": "Euclidean Distance\n\nE1_euc &lt;- round(vegdist(E1, method = \"euclidian\", upper = TRUE), 4)\nE1_df &lt;- as.data.frame(as.matrix(E1_euc))\nE1_df[1:10, 1:10]\n\n        1      2      3      4      5      6      7      8      9     10\n1  0.0000 0.7040 1.0006 1.1132 0.9902 0.9124 0.7849 0.7957 2.7901 2.0327\n2  0.7040 0.0000 0.3769 0.6126 0.6553 0.7726 0.6291 0.5565 2.2733 1.7509\n3  1.0006 0.3769 0.0000 0.2818 0.4729 0.7594 0.7164 0.7939 2.2692 1.8055\n4  1.1132 0.6126 0.2818 0.0000 0.3662 0.7566 0.7911 0.9708 2.4523 1.9019\n5  0.9902 0.6553 0.4729 0.3662 0.0000 0.4094 0.5261 0.9860 2.4847 2.1376\n6  0.9124 0.7726 0.7594 0.7566 0.4094 0.0000 0.2862 1.0129 2.4449 2.3483\n7  0.7849 0.6291 0.7164 0.7911 0.5261 0.2862 0.0000 0.7678 2.3035 2.1656\n8  0.7957 0.5565 0.7939 0.9708 0.9860 1.0129 0.7678 0.0000 2.2251 1.5609\n9  2.7901 2.2733 2.2692 2.4523 2.4847 2.4449 2.3035 2.2251 0.0000 2.8476\n10 2.0327 1.7509 1.8055 1.9019 2.1376 2.3483 2.1656 1.5609 2.8476 0.0000\n\n\nWe already know how to read this matrix. Let’s plot it as a function of the coastal section’s number (Figure 3).\n\nggplot(data = E1_df, (aes(x = 1:58, y = `1`))) +\n  geom_line(colour = \"indianred\", size = 1.2) +\n  xlab(\"Coastal section, west to east\") +\n  ylab(\"Environmental distance\")+\n  theme_linedraw()\n\n\n\n\n\n\nFigure 3: Line plot showing the trend in environmental distance along the coast from the west at Section 1 to Section 58 in the East.\n\n\n\n\n\n\n\n\n\n\nLab 2\n\n\n\n(To be reviewed by BCB743 student but not for marks)\nUse the Doubs River environmental data for this exercise.\n\nStandardise these data using R and display a portion of the resultant standardised data file.\nDiscuss why standardisation was necessary for these data. Use the content of the actual ‘raw’ data file in your discussion.\nUsing R, calculate the Euclidean distances for these data and display a portion of the resultant distance matrix.\nDiscuss the ecological conclusions you are able to draw from these Euclidean distances. Provide a few graphs to substantiate your answer.\n\n\n\nWe will explore distance and dissimilarity matrices in more detail in later sections.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2b. Environmental Distance"
    ]
  },
  {
    "objectID": "BDC334/02b-env_dist.html#pairwise-correlations",
    "href": "BDC334/02b-env_dist.html#pairwise-correlations",
    "title": "Lab 2b. Environmental Distance",
    "section": "Pairwise Correlations",
    "text": "Pairwise Correlations\nIt is easy to calculate pairwise correlation matrices for the above data:\n\nenv1_cor &lt;- round(cor(env1), 2)\nenv1_cor\n\n         febMean febRange febSD augMean augRange augSD annMean annRange annSD\nfebMean     1.00    -0.27 -0.28    0.90    -0.10 -0.16    0.98     0.74  0.41\nfebRange   -0.27     1.00  0.79   -0.32     0.14  0.14   -0.29    -0.08  0.48\nfebSD      -0.28     0.79  1.00   -0.16     0.35  0.46   -0.26    -0.33  0.31\naugMean     0.90    -0.32 -0.16    1.00    -0.01 -0.05    0.96     0.37  0.13\naugRange   -0.10     0.14  0.35   -0.01     1.00  0.91   -0.10    -0.20  0.06\naugSD      -0.16     0.14  0.46   -0.05     0.91  1.00   -0.17    -0.27  0.08\nannMean     0.98    -0.29 -0.26    0.96    -0.10 -0.17    1.00     0.60  0.29\nannRange    0.74    -0.08 -0.33    0.37    -0.20 -0.27    0.60     1.00  0.68\nannSD       0.41     0.48  0.31    0.13     0.06  0.08    0.29     0.68  1.00\n\n\n\n\n\n\n\n\nLab 2 (continue)\n\n\n\n(To be reviewed by BCB743 student but not for marks)\n\nExplain in s short (1/3 page paragraph) what is meant by ‘environmental distance’.\nDescribe to your grandmother how to interpret the above correlation matrix, and also mention what the major conclusions are that can be drawn from studying the matrix. Add a mechanistic explanation to demonstrate to her what your thought processes are for reaching your conclusion.\nExplain why the same general trend is seen in the raw or standardised environmental data for annMean (Figure 1 and 2) and that of environmental distance (Figure 3).",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2b. Environmental Distance"
    ]
  },
  {
    "objectID": "BDC334/02b-env_dist.html#euclidean-distance-of-geographical-data",
    "href": "BDC334/02b-env_dist.html#euclidean-distance-of-geographical-data",
    "title": "Lab 2b. Environmental Distance",
    "section": "Euclidean Distance of Geographical Data",
    "text": "Euclidean Distance of Geographical Data\nWhen we calculate Euclidean distances between geographic lat/lon coordinate, the relationship between sections will be the same (but scaled) as actual geographic distances.\n\ngeo &lt;- read.csv(\"../data/seaweed/SeaweedSites.csv\")\ndim(geo)\n\n[1] 58  2\n\n\n\nhead(geo)\n\n   Latitude Longitude\n1 -28.98450  16.72429\n2 -29.38053  16.94238\n3 -29.83253  17.08194\n4 -30.26426  17.25928\n5 -30.67874  17.47638\n6 -31.08580  17.72167\n\n\n\nCalculate geographic distances (in meters) between coordinate pairs (Figure 4).\n\ndists &lt;- geodist(geo, paired = TRUE, measure = \"geodesic\")\ndists_df &lt;- as.data.frame(as.matrix(dists))\ncolnames(dists_df) &lt;- seq(1:58)\ndists_df[1:5, 1:5]\n\n          1         2         3         4         5\n1      0.00  48752.45 100201.82 151021.75 201380.00\n2  48752.45      0.00  51894.01 102638.03 152849.90\n3 100201.82  51894.01      0.00  50822.71 101197.22\n4 151021.75 102638.03  50822.71      0.00  50457.53\n5 201380.00 152849.90 101197.22  50457.53      0.00\n\n\n\nplt1 &lt;- ggplot(data = dists_df, (aes(x = 1:58, y = `1`/1000))) +\n  geom_line(colour = \"indianred\", size = 1.2) +\n  xlab(\"Coastal section, west to east\") +\n  ylab(\"Distance (km)\") +\n  ggtitle(\"Actual geographic distance\")+\n  theme_linedraw()\n\n\ndists_euc &lt;- vegdist(geo, method = \"euclidian\")\ndists_euc_df &lt;- round(as.data.frame(as.matrix(dists_euc)), 4)\ndists_euc_df[1:5, 1:5]\n\n       1      2      3      4      5\n1 0.0000 0.4521 0.9204 1.3871 1.8537\n2 0.4521 0.0000 0.4731 0.9388 1.4037\n3 0.9204 0.4731 0.0000 0.4667 0.9336\n4 1.3871 0.9388 0.4667 0.0000 0.4679\n5 1.8537 1.4037 0.9336 0.4679 0.0000\n\n\n\nplt2 &lt;- ggplot(data = dists_euc_df, (aes(x = 1:58, y = `1`))) +\n  geom_line(colour = \"indianred\", size = 1.2) +\n  xlab(\"Coastal section, west to east\") +\n  ylab(\"Euclidean distance\") +\n  ggtitle(\"Euclidean distance\")+\n  theme_linedraw()\n\nggarrange(plt1, plt2, ncol = 2)\n\n\n\n\n\n\nFigure 4: Line plots showing the relationship between Euclidean and geographical distance.\n\n\n\n\n\n\n\n\n\n\nLab 2 (continue)\n\n\n\n(To be reviewed by BCB743 student but not for marks)\n\nDo a full analysis of the Doubs River environmental data using Euclidean distances and correlations. Demonstrate graphically any clear spatial patterns that you might find, and offer a full suite of mechanistic explanations for the patterns you see. It is sufficient to submit a fully annotated R script (not a MS Word or Excel file).\n\n\n\n\n\n\n\n\n\nSubmission Instructions\n\n\n\nThe Lab 2 assignment on Ecological Data was discussed on Monday 8 August and is due at 07:00 on Monday 5 August 2024.|\nProvide a neat and thoroughly annotated R file which can recreate all the graphs and all calculations. Written answers must be typed in the same file as comments.\nPlease label the R file as follows:\n\nBDC334_&lt;first_name&gt;_&lt;last_name&gt;_Lab_2.R\n\n(the &lt; and &gt; must be omitted as they are used in the example as field indicators only).\nSubmit your appropriately named R documents on iKamva when ready.\nFailing to follow these instructions carefully, precisely, and thoroughly will cause you to lose marks, which could cause a significant drop in your score as formatting counts for 15% of the final mark (out of 100%).",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 2b. Environmental Distance"
    ]
  },
  {
    "objectID": "BDC334/L01a-introduction.html",
    "href": "BDC334/L01a-introduction.html",
    "title": "Lecture 1a. About Biogeography & Global Ecology",
    "section": "",
    "text": "BCB743\n\n\n\nThis material must be reviewed by BCB743 students in Week 1 of Quantitative Ecology.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 1a. About Biogeography & Global Ecology"
    ]
  },
  {
    "objectID": "BDC334/L01a-introduction.html#introduction-to-biogeography-and-global-ecology",
    "href": "BDC334/L01a-introduction.html#introduction-to-biogeography-and-global-ecology",
    "title": "Lecture 1a. About Biogeography & Global Ecology",
    "section": "Introduction to Biogeography and Global Ecology",
    "text": "Introduction to Biogeography and Global Ecology\n\nMain Outcomes\nOn completion of this module the student should be able to:\n\nDiscuss the past, present and projected future patterns of global biogeography.\nExamine the distribution of past floras, faunas and climate with respect to plate tectonics and compare them with current distributions.\nExplain the role that the major environmental drivers play in driving these biogeographical patterns.\nUnderstand the physical basis underpinning the components of global change.\nRecognise the central importance that humans play in bringing about global change.\nUnderstand the ecological, physiological and behavioural basis for biogeographical change.\nContrast the fundamental differences between ecological biogeography and historical biogeography.\nConsider the biogeography of key extant plant and animal lineages.\nApply the appropriate concepts to collect, analyse and interpret multivariate environmental and ecological data.\nPresent their position on the above in discussion or in written format.\n\n\n\nMain Content\nProfessor Boatwright:\n\nGlobal biogeography: key principles and concepts.\nContinental drift and glaciation.\nTheories of biogeography and biogeographic reconstruction.\nPhylogeography\nIsland biogeography theory and its applications for conservation.\n\nProfessor Smit:\n\nLatitudinal gradients in diversity.\nInteractions of body and population size on diversity and distribution.\nEarth as a system\nThe physical nature of environmental drivers of biogeography.\nGlobal change: the distinction between natural variability and anthropogenically-driven change.\nOverview of the biological responses to global change.\nBasic data collection and analytical methods in biogeography.\n\n\n\nExploration of Concepts\nEcosystems form the foundation of life on Earth, encompassing complex interactions between living organisms and their physical environment. This lecture series will explore the fundamental concepts, characteristics, and driving forces that shape and maintain ecosystems across our planet.\nWe’ll begin by defining ecosystems and examining their basic structure, including both biotic and abiotic components. Next, we’ll investigate key ecosystem characteristics such as energy flow, nutrient cycling, biodiversity, and community structure. Throughout the course, we’ll explore the various drivers influencing ecosystem dynamics, including natural factors like climate and geological processes, as well as anthropogenic influences related to global change.\nOur study will cover diverse ecosystem types, ranging from terrestrial to aquatic, and from microscopic to global scales. The practical component of this module will focus on quantifying ecosystem processes across various spatial scales. We’ll also discuss the importance of ecosystem services and their critical role in supporting human well-being and planetary health.\nBy the end of this series, you’ll have gained a comprehensive understanding of ecosystem concepts. You’ll better appreciate the natural world around us and the factors that shape it. This knowledge will serve as a foundation for more advanced studies in ecology, environmental science, and conservation biology.\nFor those interested in further study, I teach a course called Quantitative Ecology in the BCB Department for Honours students. This advanced course focuses on analysing ecosystem data across different scales.\nWe will focus on some important topics that integrate many of the above ideas:\n1. Conceptual overview of ecosystems and their characteristics and drivers\nThis topic explores the conceptual overview of ecosystems, including their characteristics and drivers. This will equip you to answer questions such as:\n\nWhat is an ecosystem?\nWhat are the main components of ecosystems?\nWhat is ‘macroecology’?\nWhat are ecosystem’s functional and structural properties?\nHow do we measure and describe these properties?\nWhat drives ecosystems?\nHow do we measure these drivers?\nHow do we measure the responses of ecosystems to these drivers?\nDoes it all matter? How? For whom?\n\n2. Gradients in diversity\nWe will examine how ecosystem function and structure become arranged across Earth’s surface. In Labs we will use data to quantify biodiversity structure. At the end, you should be equipped to answer questions such as:\n\nWhat are gradients?\nWhy do gradients exist?\nWhat are the main environmental gradients?\nHow do these gradients affect biodiversity? Why do biodiversity, ecosystem properties, and ecological function change along these gradients?\nWhat are the main gradients in diversity, globally and regionally?\nHow are gradients (environment and species) being affected by global change?\n\n3. The role of humans in driving global change\nHumans have drastically altered ecosystem function and structure across space and time. Here, we emphasise the main drivers and their impacts on ecosystems. You will answer questions such as:\n\nWhat are the main drivers of global change?\nHow do humans affect these drivers?\nWhat are the main impacts of these drivers on ecosystems?\nHow do these impacts affect biodiversity, ecosystem properties, and ecological function?\nWhat are the main consequences of these impacts for humans?\nWhat can we do to mitigate these impacts?\n\n4. Anthropogenic and natural impacts on ecosystem integrity\nFollowing on from the previous topic, we now focus on the definition of ‘anthropogenic’ and look at these effects of human activities. Question such as the following will arise:\n\nWhat is ecosystem integrity?\nHow do humans affect ecosystem integrity?\nWhat are the main impacts of humans on ecosystem integrity?\nHow do these impacts affect biodiversity, ecosystem properties, and ecological function?\nWhat are the main consequences of these impacts for humans?\nWhat can we do to mitigate these impacts?\n\n5. Exploration of selected marine and terrestrial ecosystems\nNow we explore selected marine and terrestrial ecosystems of South Africa focus).\n\nWhat are the main characteristics of these ecosystems?\nWhat are the main drivers of these ecosystems?\nHow do these drivers affect biodiversity, ecosystem properties, and ecological function?\nWhat are the main consequences of these impacts for humans?\nWhat can we do to mitigate these impacts?\n\n6. Develop an understanding of the importance of biodiversity and ecosystem services\nLearn about the importance of biodiversity and ecosystem services. In the process, we unpack some modern frameworks that help us understand the importance of biodiversity and ecosystem services.\n\nWhat does biodiversity do?\nWhy does biodiversity matter?\nWhat are sustainability and resilience, and how do they relate to biodiversity and ecosystem services?\nWhat are ecosystem services?\nWhat are the main ecosystem services?\nHow do biodiversity and ecosystem properties affect these services?\nWhat are the main consequences of these impacts for humans?\n\nAs we work through this module, check your understand by seeing if you can answer the above questions. If you can, you are well on your way to understanding the main content of this module.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 1a. About Biogeography & Global Ecology"
    ]
  },
  {
    "objectID": "BDC334/04-biodiversity2.html",
    "href": "BDC334/04-biodiversity2.html",
    "title": "Lab 4. Species Distribution Patterns",
    "section": "",
    "text": "BCB743\n\n\n\nThis material must be reviewed by BCB743 students in Week 1 of Quantitative Ecology.\nIn this Lab, we will calculate the various species distribution patterns included in the paper by Shade et al. (2018).",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 4. Species Distribution Patterns"
    ]
  },
  {
    "objectID": "BDC334/04-biodiversity2.html#the-data",
    "href": "BDC334/04-biodiversity2.html#the-data",
    "title": "Lab 4. Species Distribution Patterns",
    "section": "The Data",
    "text": "The Data\nWe will calculate each for the Barro Colorado Island Tree Counts data that come with vegan. See ?vegan::BCI for a description of the data contained with the package, as well as a selection of publications relevant to the data and analyses. The primary publication of interest is Condit et al. (2002).\n\nlibrary(tidyverse)\nlibrary(vegan)\n\n\n#library(vegan) # already loaded\n#library(tidyverse) # already loaded\ndata(BCI) # data contained within vegan\n\n# make a head-tail function\nht &lt;- function(d) rbind(head(d, 7), tail(d, 7))\n\n# Lets look at a portion of the data:\nht(BCI)[1:7,1:7]\n\n  Abarema.macradenia Vachellia.melanoceras Acalypha.diversifolia\n1                  0                     0                     0\n2                  0                     0                     0\n3                  0                     0                     0\n4                  0                     0                     0\n5                  0                     0                     0\n6                  0                     0                     0\n7                  0                     0                     0\n  Acalypha.macrostachya Adelia.triloba Aegiphila.panamensis\n1                     0              0                    0\n2                     0              0                    0\n3                     0              0                    0\n4                     0              3                    0\n5                     0              1                    1\n6                     0              0                    0\n7                     0              0                    1\n  Alchornea.costaricensis\n1                       2\n2                       1\n3                       2\n4                      18\n5                       3\n6                       2\n7                       0\n\n\nSpecies-Abundance Distribution\nThe species abundance distribution (SAD) is a fundamental pattern in ecology. Typical communities have a few species that are very abundant, whereas most of them are quite rare; indeed—this is perhaps a universal law in ecology. SAD represents this relationship graphically by plotting the abundance rank on the \\(x\\)-axis and the number of species (or some other taxonomic level) along \\(y\\), as was first done by Fisher et al. (1943). He then fitted the data by log series that ideally capture situations where most of the species are quite rare with only a few very abundant ones—called Fisher’s log series distribution—and is implemented in vegan by the fisherfit() function (Figure 1). The curve in Fisher’s logarithmic series shows the expected number of species \\(f\\) with \\(n\\) observed individuals. In fact, the interpretation of the curve is the same for all species-abundance models shown below, and it is only the math and rationale that differ.\n\n# take one random sample of a row (site):\n# for this website's purpose, this function ensure the same random\n# sample is drawn each time the web page is recreated\nset.seed(13) \nk &lt;- sample(nrow(BCI), 1)\nfish &lt;- fisherfit(BCI[k,])\nfish\n\n\nFisher log series model\nNo. of species: 95 \nFisher alpha:   39.87659 \n\nplot(fish)\n\n\n\n\n\n\nFigure 1: Fisher’s log series distribution calculated for the Barro Colorado Island Tree Counts data.\n\n\n\n\nPreston (1948) showed that when data from a thoroughly sampled population are transformed into octaves along the \\(x\\)-axis (number of species binned into intervals of 1, 2, 4, 8, 16, 32 etc.), the SAD that results is approximated by a symmetric Gaussian distribution. This is because more thorough sampling makes species that occur with a high frequency more common and those that occur only once or are very rare become either less common will remain completely absent. This SAD is called Preston’s log-normal distribution. In the vegan package there is an updated version of Preston’s approach with a mathematical improvement to better handle ties. It is called prestondistr() (Figure 2):\n\npres &lt;- prestondistr(BCI[k,])\npres\n\n\nPreston lognormal model\nMethod: maximized likelihood to log2 abundances \nNo. of species: 95 \n\n      mode      width         S0 \n 0.9234918  1.6267630 26.4300640 \n\nFrequencies by Octave\n                0        1        2        3        4        5         6\nObserved 19.00000 27.00000 21.50000 17.00000 7.000000 2.500000 1.0000000\nFitted   22.49669 26.40085 21.23279 11.70269 4.420327 1.144228 0.2029835\n\nplot(pres)\n\n\n\n\n\n\nFigure 2: Preston’s log-normal distribution demonstrated for the BCI data.\n\n\n\n\nWhittaker (1965) introduced rank abundance distribution curves (RAD; sometimes called a dominance-diversity curve or Whittaker plots). Here the \\(x\\)-axis has species ranked according to their relative abundance, with the most abundant species at the left and rarest at the right. The \\(y\\)-axis represents relative species abundances (sometimes log-transformed). The shape of the profile as—influenced by the steepness and the length of the tail—indicates the relative proportion of abundant and scarce species in the community. In vegan we can accomplish fitting this type of SAD with the radfit() function. The default plot is somewhat more complicated as it shows broken-stick, preemption, log-Normal, Zipf and Zipf-Mandelbrot models fitted to the ranked species abundance data (Figure 3):\n\nrad &lt;- radfit(BCI[k,])\nrad\n\n\nRAD models, family poisson \nNo. of species 95, total abundance 392\n\n           par1      par2     par3    Deviance AIC      BIC     \nNull                                   56.3132 324.6477 324.6477\nPreemption  0.042685                   55.8621 326.1966 328.7504\nLognormal   0.84069   1.0912           16.1740 288.5085 293.6162\nZipf        0.12791  -0.80986          21.0817 293.4161 298.5239\nMandelbrot  0.66461  -1.2374   4.1886   6.6132 280.9476 288.6093\n\nplot(rad)\n\n\n\n\n\n\nFigure 3: Whittaker’s rank abundance distribution curves demonstrated for the BCI data.\n\n\n\n\nWe can also fit the rank abundance distribution curves to several sites at once (previously we have done so on only one site) (Figure 4):\n\nm &lt;- sample(nrow(BCI), 6)\nrad2 &lt;- radfit(BCI[m, ])\nrad2\n\n\nDeviance for RAD models:\n\n                  3       37       10       13        6       22\nNull        86.1127  93.5952  77.2737  52.6207  72.1627 114.1747\nPreemption  58.9295 104.0978  62.7210  57.7372  54.7709 110.5156\nLognormal   29.2719  19.0653  20.4770  15.8218  19.5788  26.2510\nZipf        50.1262  11.3048  39.7066  22.8006  32.4630  15.5222\nMandelbrot   5.7342   8.9107   9.8353  12.1701   5.5973   9.6047\n\nplot(rad2)\n\n\n\n\n\n\nFigure 4: Rank abundance distribution curves fitted to several sites.\n\n\n\n\nAbove, we see that the model selected for capturing the shape of the SAD is the Mandelbrot, and it is plotted individually for each of the randomly selected sites. Model selection works through Akaike’s or Schwartz’s Bayesian information criteria (AIC or BIC; AIC is the default—select the model with the lowest AIC).\nBiodiversityR (and here and here) also offers options for rank abundance distribution curves; see rankabundance() (Figure 5):\n\nlibrary(BiodiversityR)\nrankabund &lt;- rankabundance(BCI)\nrankabunplot(rankabund, cex = 0.8, pch = 0.8, col = \"indianred4\")\n\n\n\n\n\n\nFigure 5: Rank-abundance curves for the BCI data.\n\n\n\n\nRefer to the help files for the respective functions to see their differences.\nOccupancy-Abundance Curves\nOccupancy refers to the number or proportion of sites in which a species is detected. Occupancy-abundance relationships are used to infer niche specialisation patterns in the sampling region. The hypothesis (almost a theory) is that species that tend to have high local abundance within one site also tend to occupy many other sites (Figure 6).\n\nlibrary(ggpubr)\n\n# A function for counts:\n# count number of non-zero elements per column\ncount_fun &lt;- function(x) {\n  length(x[x &gt; 0])\n}\n\nBCI_OA &lt;- data.frame(occ = apply(BCI, MARGIN = 2, count_fun),\n                     ab = apply(BCI, MARGIN = 2, mean))\n\nggplot(BCI_OA, aes(x = ab, y = occ/max(occ))) +\n  geom_point(colour = \"indianred3\") +\n  scale_x_log10() +\n  # scale_y_log10() +\n  labs(title = \"Barro Colorado Island Tree Counts\",\n     x = \"Log (abundance)\", y = \"Occupancy\") +\n  theme_linedraw()\n\n\n\n\n\n\nFigure 6: Occupancy-abundance relationships seen in the BCI data.\n\n\n\n\nSpecies-Area (Accumulation)\nSpecies accumulation curves (species area relationships, SAR) try and estimate the number of unseen species. These curves can be used to predict and compare changes in diversity over increasing spatial extent. Within an ecosystem type, one would expect that more and more species would be added (accumulates) as the number of sampled sites increases (i.e. extent increases). This continues to a point where no more new species are added as the number of sampled sites continues to increase (i.e. the curve plateaus). Species accumulation curves, as the name suggests, accomplishes this by adding (accumulation or collecting) more and more sites and counting the average number of species along \\(y\\) each time a new site is added. See Roeland Kindt’s description of how species accumulation curves work (on p. 41). In the community matrix (the sites × species table), we can do this by successively adding more rows to the curve (seen along the \\(x\\)-axis). The specaccum() function has many different ways of adding the new sites to the curve, but the default ‘exact’ seems to be a sensible choice. BiodiversityR has the accumresult() function that does nearly the same. Let’s demonstrate using vegan’s function (Figure 7, Figure 8, and Figure 9):\n\nsp1 &lt;- specaccum(BCI)\nsp2 &lt;- specaccum(BCI, \"random\")\n\n# par(mfrow = c(2,2), mar = c(4,2,2,1))\n# par(mfrow = c(1,2))\nplot(sp1, ci.type = \"polygon\", col = \"indianred4\", lwd = 2, ci.lty = 0,\n     ci.col = \"steelblue2\", main = \"Default: exact\",\n     ylab = \"No. of species\")\n\n\n\n\n\n\nFigure 7: Species-area accumulation curves seen in the BCI data.\n\n\n\n\n\nmods &lt;- fitspecaccum(sp2, \"arrh\")\nplot(mods, col = \"indianred\", ylab = \"No. of species\")\nboxplot(sp2, col = \"yellow\", border = \"steelblue2\", lty = 1, cex = 0.3, add = TRUE)\nsapply(mods$models, AIC)\n\n  [1] 311.4642 303.7835 346.3668 320.0786 338.7978 320.2538 325.6968 346.2671\n  [9] 320.3900 343.8570 318.2509 369.8303 335.9936 350.8711 327.9831 348.1287\n [17] 328.2393 347.8133 324.3837 314.8555 333.1390 340.5678 332.6836 360.5208\n [25] 335.3660 325.3150 347.4324 336.7498 336.6374 276.1878 349.9283 295.0268\n [33] 308.4656 315.8304 303.0776 329.8425 356.2393 368.4302 318.0514 359.5975\n [41] 327.4228 335.7604 259.8340 318.0063 335.7753 285.8790 323.5174 300.3546\n [49] 327.1448 355.2747 288.2583 366.5995 287.4120 327.5877 362.6487 323.5904\n [57] 339.5650 321.2264 336.6331 353.1295 317.9578 311.6528 336.3613 337.8327\n [65] 328.4787 311.6842 345.8035 367.5620 319.0269 305.6546 338.7805 321.8859\n [73] 330.6029 326.7097 345.8923 338.4755 352.8710 355.8038 307.7327 329.2355\n [81] 341.6628 340.1687 333.4771 348.3144 321.4417 317.4331 339.2211 313.1990\n [89] 305.3069 342.4581 318.0308 299.7067 294.7851 324.3237 333.5849 349.2749\n [97] 369.8287 323.0041 332.6820 329.3875\n\n\n\n\n\n\n\nFigure 8: Fit Arrhenius models to all random accumulations\n\n\n\n\n\naccum &lt;- accumresult(BCI, method = \"exact\", permutations = 100)\naccumplot(accum)\n\n\n\n\n\n\nFigure 9: A species accumulation curve.\n\n\n\n\nSpecies accumulation curves can also be calculated with the alpha.accum() function of the BAT package (Figure 10). In addition, the BAT package can also apply various diversity and species distribution assessments to phylogenetic and functional diversity. See the examples provided by Cardoso et al. (2015).\n\nlibrary(BAT)\nBCI.acc &lt;- alpha.accum(BCI, prog = FALSE)\n\npar(mfrow = c(1,2))\nplot(BCI.acc[,2], BCI.acc[,17], col = \"indianred\",\n     xlab = \"Individuals\", ylab = \"Chao1P\")\nplot(BCI.acc[,2], slope(BCI.acc)[,17], col = \"indianred\",\n     xlab = \"Individuals\", ylab = \"Slope\")\n\n\n\n\n\n\nFigure 10: A species accumulation curve made with the alpha.accum() function of BAT.\n\n\n\n\nRarefaction Curves\nLike species accumulation curves, rarefaction curves also try to estimate the number of unseen species. Rarefaction, meaning to scale down (Heck Jr et al. 1975), is a statistical technique used by ecologists to assess species richness (represented as S, or diversity indices such as Shannon diversity, \\(H'\\), or Simpson’s diversity, \\(\\lambda\\)) from data on species samples, such as that which we may find in site × species tables. Rarefaction can be used to determine whether a habitat, community, or ecosystem has been sufficiently sampled to fully capture the full complement of species present.\nRarefaction curves may seem similar to species accumulation curves, but there is a difference as I will note below. Species richness, S, accumulates with sample size or with the number of individuals sampled (across all species). The first way that rarefaction curves are presented is to show species richness as a function of number of individuals sampled. Here the principle demonstrated is that when only a few individuals are sampled, those individuals may belong to only a few species; however, when more individuals are present more species will be represented. The second approach to rarefaction is to plot the number of samples along \\(x\\) and the species richness along the \\(y\\)-axis (as in SADs too). So, rarefaction shows how richness accumulates with the number of individuals counted or with the number of samples taken. Rarefaction curves rise rapidly at the start when few species have been sampled and the most common species have been found; the slope then decreases and eventually plateaus suggesting that the rarest species remain to be sampled.\nBut what really distinguishes rarefaction curves from SADs is that rarefaction randomly re-samples the pool of \\(N\\) samples (that is equal or less than the total community size) a number of times, \\(n\\), and plots the average number of species found in each resample (1,2, …, \\(n\\)) as a function of individuals or samples. The rarecurve() function draws a rarefaction curve for each row of the species data table. All these plots are made with base R graphics Figure 11, but it will be a trivial exercise to reproduce them with ggplot2.\n\n# Example provided in ?vegan::rarefy\n# observed number of species per row (site)\nS &lt;- specnumber(BCI) \n\n# calculate total no. individuals sampled per row, and find the minimum\n(raremax &lt;- min(rowSums(BCI)))\n\n[1] 340\n\nSrare &lt;- rarefy(BCI, raremax, se = FALSE)\npar(mfrow = c(1,2))\nplot(S, Srare, col = \"indianred3\",\n     xlab = \"Sample size\\n(observed no. of individuals)\", ylab = \"No. species found\")\nrarecurve(BCI, step = 20, sample = raremax, col = \"indianred3\", cex = 0.6,\n          xlab = \"Sample size\\n(observed no. of individuals)\", ylab = \"No. species found\")\n\n\n\n\n\n\nFigure 11: Rarefaction curves for the BCI data.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\niNEXT\nWe can also use the iNEXT package for rarefaction curves. From the package’s Introduction Vignette:\niNEXT focuses on three measures of Hill numbers of order q: species richness (q = 0), Shannon diversity (q = 1, the exponential of Shannon entropy) and Simpson diversity (q = 2, the inverse of Simpson concentration). For each diversity measure, iNEXT uses the observed sample of abundance or incidence data (called the “reference sample”) to compute diversity estimates and the associated 95% confidence intervals for the following two types of rarefaction and extrapolation (R/E):\n\nSample‐size‐based R/E sampling curves: iNEXT computes diversity estimates for rarefied and extrapolated samples up to an appropriate size. This type of sampling curve plots the diversity estimates with respect to sample size.\nCoverage‐based R/E sampling curves: iNEXT computes diversity estimates for rarefied and extrapolated samples with sample completeness (as measured by sample coverage) up to an appropriate coverage. This type of sampling curve plots the diversity estimates with respect to sample coverage.\n\niNEXT also plots the above two types of sampling curves and a sample completeness curve. The sample completeness curve provides a bridge between these two types of curves.\nFor information about Hill numbers see David Zelený’s Analysis of community data in R and Jari Oksanen’s coverage of diversity measures in vegan.\nThere are four datasets distributed with iNEXT and numerous examples are provided in the Introduction Vignette. iNEXT has an ‘odd’ data format that might seem foreign to vegan users. To use iNEXT with dataset suitable for analysis in vegan, we first need to convert BCI data to a species × site matrix (Figure 12):\n\nlibrary(iNEXT)\n\n# transpose the BCI data: \nBCI_t &lt;- list(BCI = t(BCI))\nstr(BCI_t)\n\nList of 1\n $ BCI: int [1:225, 1:50] 0 0 0 0 0 0 2 0 0 0 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:225] \"Abarema.macradenia\" \"Vachellia.melanoceras\" \"Acalypha.diversifolia\" \"Acalypha.macrostachya\" ...\n  .. ..$ : chr [1:50] \"1\" \"2\" \"3\" \"4\" ...\n\nBCI_out &lt;- iNEXT(BCI_t, q = c(0, 1, 2), datatype = \"incidence_raw\")\nggiNEXT(BCI_out, type = 1, color.var = \"Order.q\")\n\n\n\n\n\n\n\n\n\nThe warning is produced because the function expects incidence data (presence-absence), but I’m feeding it abundance (count) data. Nothing serious, as the function converts the abundance data to incidences.\n\n\n\nFigure 12: Demonstration of iNEXT capabilities.\nDistance-Decay Curves\nThe principles of distance decay relationships are clearly captured in analyses of \\(\\beta\\)-diversity—see specifically turnover, \\(\\beta_\\text{sim}\\). Distance decay is the primary explanation for the spatial pattern of \\(\\beta\\)-diversity along the South African coast in Smit et al. (2017). A deeper dive into distance decay calculation can be seen in Deep Dive into Gradients.\nElevation and Other Gradients\nIn once sense, an elevation gradient can be seen as specific case of distance decay. The Doubs River dataset offer a nice example of data collected along an elevation gradient. Elevation gradients have many similarities with depth gradients (e.g. down the ocean depths) and latitudinal gradients.\n\n\n\n\n\n\nLab 4\n\n\n\n(To be reviewed by BCB743 student but not for marks)\n\n\nProduce the following figures for the species data indicated in [square brackets]:\n\nspecies-abundance distribution [mite];\noccupancy-abundance curves [mite];\nspecies-area curves [seaweed]—note, do not use the BAT package’s alpha.accum() function as your computer might fall over;\nrarefaction curves [mite].\n\nAnswer each under its own heading. For each, also explain briefly what the purpose of the analysis is (i.e. what ecological insights might be provided), and describe the findings of your own analysis as well as any ecological implications that you might be able to detect.\n\nUsing the biodiversityR package, find the most dominant species in the Doubs River dataset.\nDiscuss how elevation, depth, or latitudinal gradients are similar in many aspects to distance decay relationships.\n\n\n\n\n\n\n\n\n\nSubmission Instructions\n\n\n\nThe Lab 4 assignment is due at 07:00 on Monday 19 August 2024.\nProvide a neat and thoroughly annotated R file which can recreate all the graphs and all calculations. Written answers must be typed in the same file as comments.\nPlease label the R file as follows:\n\nBDC334_&lt;first_name&gt;_&lt;last_name&gt;_Lab_4.R\n\n(the &lt; and &gt; must be omitted as they are used in the example as field indicators only).\nSubmit your appropriately named R documents on iKamva when ready.\nFailing to follow these instructions carefully, precisely, and thoroughly will cause you to lose marks, which could cause a significant drop in your score as formatting counts for 15% of the final mark (out of 100%).",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lab 4. Species Distribution Patterns"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html",
    "href": "BDC334/BDC334_syllabus.html",
    "title": "Syllabus & Policies",
    "section": "",
    "text": "“Knowledge is not a resource we simply stumble upon. It’s not something that we pluck out of the air. Knowledge is created. It is coaxed into existence by thoughtful, creative people. It is not a free good. It comes only to the prepared mind.”\n— Frank H. T. Rhodes, Speed Bumps on the Road Ahead, Trusteeship, May/June 1999",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#timetable",
    "href": "BDC334/BDC334_syllabus.html#timetable",
    "title": "Syllabus & Policies",
    "section": "Timetable",
    "text": "Timetable\nMy part of the BDC334 module runs in the 3rd term, from 22 July to 30 August 2024.\n\nLecture Timetable\n\n\n\n\n\n\n\n\n\nDay\nPeriods\nLocation\nNotes\n\n\n\n\nMonday\n3rd period\n5th Floor BCB Dept\nself-study\n\n\nTuesday\n2nd period\n5th Floor BCB Dept\nself-study\n\n\nWednesday\n1st period\n5th Floor BCB Dept\nunused\n\n\nThursday\nperiods 6-8\n5th Floor BCB Dept\ndiscussion\n\n\n\nBelow, you are provided with reading material (lecture slides, PDFs for reading) and pre-recorded video lectures that you are expected to consume before the discussion classes on Thursdays. The weekly face-to-face sessions are essential for discussing the work you covered the previous two days, and it also allows you to be like real students, attending actual lectures, for real, in person. The discussion session is for free talk and bouncing of ideas. We can talk about anything related to the topic of biodiversity but will try and focus on the issues at hand.\nTypically, we will meet weekly, on Thursdays, in person on campus. The rest of the time, we will proceed with pre-recorded lecture material from wherever in the world you choose to be.\nHowever, on the first Monday of Term 3, we will all meet in person on campus in the lecture venue (again on the first Wednesday of Term 3). You can then meet me for the first time (even if you saw me online last year), and I will give an outline of my portion of the course. Prof Boatwright will take over in Term 4.\n\n\nLabs\n\n\n\nDay\nPeriods\nLocation\n\n\n\n\nMonday\nPeriods 6-8\n5th Floor BCB Dept\n\n\n\nThe Labs take place on Mondays during Periods 6-8 (starting at 13:30) in the 5th floor computer lab in Biodiversity and Conservation Biology Department (starts 22 July 2024).\nLabs are compulsory, and failing to attend will result in a penalty of 20% taken from your mark for the week.\nPlease ensure that you read through each Lab (accessible in the sidebar) before the start the Labs. You have until the following Monday at 07:00 to complete and submit all the material.\n\n\nClass Tests\nThere will be two class tests:\n\nThursday, 8 August 2024, 13:30-15:30\nThursday, 29 August 2024, 13:30-15:30",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#instructor-and-lab-assistant",
    "href": "BDC334/BDC334_syllabus.html#instructor-and-lab-assistant",
    "title": "Syllabus & Policies",
    "section": "Instructor and Lab Assistant",
    "text": "Instructor and Lab Assistant\nTerm 3 of BDC334 is taught by me, Professor AJ Smit. You may find me in Office 4.103 in the BCB Department (4th floor). You’ll receive an introductory email from me, and you are welcome to contact me at that email address with questions or concerns. Please also use the WhatsApp group set up for this module to ask questions and share information.\nThe Lab Assistant for Term 3 is Ms. Zoë-Angelique Petersen. She will be available in the Lab during the Lab periods to assist you with any questions you may have.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#syllabus-overview-and-expectations",
    "href": "BDC334/BDC334_syllabus.html#syllabus-overview-and-expectations",
    "title": "Syllabus & Policies",
    "section": "Syllabus, Overview, and Expectations",
    "text": "Syllabus, Overview, and Expectations\n\nSyllabus\nThese links point to online resources such as reading material in the form of publications, lecture slides, example workflows, datasets, and R scripts in support of the video and PDF lecture material. Note that the video material is housed on iKamva from where you may download it without incurring Internet costs; various PDFs for reading can also be found there. It is essential that you work through these examples and workflows.\n\n\n\nWk\nType\nTopic\nPDFs etc.\nClass/Lab\nExercise Due\n\n\n\n\nW1\nL\nLecture 1a. About Biogeography & Global Ecology\nSlides\n22-24 Jul\n\n\n\n\nL\nLecture 1b. Macroecology\nSlides\n\n\n\n\n\nL\nKeith et al. (2012)\nReading\n\n\n\n\n\nL\nBDC334_Intro_Day_1_Module_Info_720p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Intro_Day_1_Pracs_Tests_720p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Intro_Day_1_Lecture_1a_720p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Intro_Day_1_Lecture_1b_720p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Intro_Day_1_Lecture_1c_720p30.mp4\niKamva\n\n\n\n\n\nP1\nLab 1. Ecological Data\nSlides\n22 Jul\n29 Jul\n\n\nW2\nL\nLecture 2a. Ecological Gradients\nSlides\n29-31 Jul\n\n\n\n\nL\nLecture 2b. Metrics of Environmental & Species Diversity\nSlides\n\n\n\n\n\nL\nNekola and White (1999)\nReading\n\n\n\n\n\nL\nSmit et al. (2017)\nReading\n\n\n\n\n\nL\nTittensor et al. (2010)\nReading\n\n\n\n\n\nL\nBDC334_Lecture_2a_720p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Lecture_2b_720p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Lecture_2c_720p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Lecture_2d_720p30.mp4\niKamva\n\n\n\n\n\nP2\nLab 2a. R & RStudio\n\n29 Jul\n5 Aug\n\n\n\nP2\nLab 2b. Environmental Distance\n\n29 Jul\n5 Aug\n\n\n\nP2\nIntroduction to Wiki Assignment\nAbout the Wiki\n1 Aug\n26 Aug\n\n\n\nL\nBDC334_Lecture_3a_1080p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Lecture_3b_1080p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Lecture_3c_1080p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Lecture_4a_1080p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Lecture_4b_1080p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Lecture_4c_1080p30.mp4\niKamva\n\n\n\n\nW3\nL\nUnified Accounting: Patterns in Diversity Over Space and Time\n\n5-7 Aug\n\n\n\n\nL\nShade et al. (2018)\nReading\n\n\n\n\n\nL\nBDC334_Lecture_5a_1080p30.mp4\niKamva\n\n\n\n\n\nL\nBDC334_Lecture_5b_1080p30.mp4\niKamva\n\n\n\n\n\nP3\nLab 3. Quantifying Biodiversity\nSlides\n5 Aug\n12 Aug\n\n\n\nT1\nClass Test 1\n\n8 Aug\n\n\n\nW4\nL\nImpacts on Biodiversity\n\n12-14 Aug\n\n\n\n\nL\nChapin III et al. (2000)\nReading\n\n\n\n\n\nL\nGotelli and Chao (2013)\nReading\n\n\n\n\n\nL\nMaxwell et al. (2016)\nReading\n\n\n\n\n\nL\nTilman et al. (2017)\nReading\n\n\n\n\n\nP4\nLab 4. Species Distribution Patterns\nSlides\n12 Aug\n19 Aug\n\n\nW5\nL\nNature’s Contribution to People\n\n19-21 Aug\n\n\n\n\nL\nCostanza et al. (1997)\nReading\n\n\n\n\n\nL\nCostanza et al. (2014)\nReading\n\n\n\n\n\nL\nBurger et al. (2012)\nReading\n\n\n\n\n\nP5\nWorksheet Completion (Prac Assessment)\n\n22 Aug\n22 Aug\n\n\nW6\nL\nRevision\n\n26-28 Aug\n\n\n\n\nFIN\nWiki Essay due\n\n\n26 Aug\n\n\n\nT2\nClass Test 2\n\n29 Aug\n\n\n\n\n\n\nReading in support of the syllabus\nIn the table above, there are links to several key papers to read in preparation for each week’s theory. You must read these papers.\nI cite many other references in each chapter. These serve several functions in that they:\n\nadd additional theory relevant to some ecological concepts;\nprovide background to some of the datasets used in my examples;\ndiscuss derivations of some equations used to calculate diversity concepts;\nprovide example walkthroughs of some of the computational aspects of the methods covered in the Labs;\ncollectively supplement the discussion about these concepts covered in the lectures.\n\nActively engaging with these reading materials will make the difference between a 60% average mark for the module and a mark in excess of 80%.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#graduate-attributes",
    "href": "BDC334/BDC334_syllabus.html#graduate-attributes",
    "title": "Syllabus & Policies",
    "section": "Graduate Attributes",
    "text": "Graduate Attributes\nThe graduate attributes resulting from completion of this modules alignment with the expectations of the workspace across diverse organisations and institutions where graduates typically find employment.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#course-resources-on-ikamva",
    "href": "BDC334/BDC334_syllabus.html#course-resources-on-ikamva",
    "title": "Syllabus & Policies",
    "section": "Course Resources on iKamva",
    "text": "Course Resources on iKamva\nAll the lecture material for this module is on iKamva. You will find there the following under Course Resources:\n\nInteractive Sessions—These are screen recordings belonging to previous years’ teaching where I address some class questions. They might be interesting or helpful.\nPDF_Reading—The bulk of the ’teaching’ will happen in the form of reading material. In other words, learning will occur because you read the papers and understand them. My job will be to facilitate understanding, not to convey the content, which you can access yourselves by reading. Yes, reading is an important life skill.\nSlides—Some meagre slides to accompany your learning process… for what it’s worth.\nVideo—These are the actual video of me talking. I might record more as we work through the course.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#computer-access",
    "href": "BDC334/BDC334_syllabus.html#computer-access",
    "title": "Syllabus & Policies",
    "section": "Computer Access",
    "text": "Computer Access\nYou are encouraged to provide your own laptops and install the necessary software before the module starts. Limited support can be provided if required. There are also computers with R and RStudio (and the essential add-on libraries) available in the 5th-floor lab in the BCB Department.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#attendance",
    "href": "BDC334/BDC334_syllabus.html#attendance",
    "title": "Syllabus & Policies",
    "section": "Attendance",
    "text": "Attendance\n\nLabs\nThese Labs are hands-on. They can only deliver acceptable outcomes if you attend all Lab sessions. Sometimes an occasional absence cannot be avoided. Still, you need to provide evidence (affidavit, doctor’s note, or death certificate) for why you did not attend to avoid a non-attendance penalty. Please be courteous and notify the tutor or me before any absence. If you work with a partner in class, inform them too. Keep up with the reading assignments while you are away, and we will all work with you to get you back up to speed on what you miss. If you do miss a class, however, the assignments must still be submitted on time (also see Late submission of CA).\nSince you may decide to work in collaboration with a peer on tasks and assignments, please keep this person informed at all times in case some emergency makes you unavailable for some time. Someone might depend on your input and contributions—do not leave someone in the lurch so that they cannot complete a task in your absence.\n\n\nGeneral Considerations\nThe schedule is set and will not be changed. Sometimes an occasional absence cannot be avoided. Please be courteous and notify the tutor or me before any absence. If you work with a partner in class, inform them too. Keep up with the reading assignments while you are away, and we will all work with you to get you back up to speed on what you miss. However, if you miss a class, the assignments must still be submitted on time (also see ‘Late submissions’ below).\nSince you may decide to work in collaboration with a peer on tasks and assignments, please keep this person informed at all times in case some emergency makes you unavailable for some time. Someone might depend on your input and contributions—do not leave someone in the lurch so they cannot complete a task in your absence.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#sec-policy",
    "href": "BDC334/BDC334_syllabus.html#sec-policy",
    "title": "Syllabus & Policies",
    "section": "Assessment",
    "text": "Assessment\nThe syllabus for Term 3 is comprised of the following mark-carrying components for Continuous Assessment (CA):\n\nWorksheet Completion (Prac Assessment) — [20%]\nWiki Essay — [20%]\nQuizzes — [10%]\nTest 1 — [15%]\nTest 2 — [15%]\n\nThe CA and an exam will provide a final mark for the module. The weighting of the CA and the exam is 0.6 and 0.4, respectively.\n\nThursday 8 August\nThursday 29 August\n\nFor interest sake, I provide the questions and answers to previous years’ class tests.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#late-submission-of-ca",
    "href": "BDC334/BDC334_syllabus.html#late-submission-of-ca",
    "title": "Syllabus & Policies",
    "section": "Late Submission of CA",
    "text": "Late Submission of CA\nLate assignments will be penalised 10% per day late. They will not be accepted more than 48 hours late unless evidence such as a doctor’s note, a death certificate or another documented emergency can be provided. If you know a submission will be late, please discuss this and seek prior approval. Class time is allocated to work on assignments, and students are expected to continue working on the projects outside class. Successfully completing (and passing) this module requires that you finish tasks based on what we have covered in the course by the following class period. Work diligently from the onset so that even if something unexpected happens at the last minute, you should already be close to done. This approach also allows rapid feedback to be provided to you, which can only be accomplished by returning assignments quickly and punctually.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#support",
    "href": "BDC334/BDC334_syllabus.html#support",
    "title": "Syllabus & Policies",
    "section": "Support",
    "text": "Support\nIt’s expected that some tricky aspects of the module will take time to master, and the best way to master problematic material is to practice, practice some more, and then ask questions. Trying for 10 minutes and then giving up is not good enough. I’ll be more sympathetic to your cause if you can demonstrate having tried for a full day before giving up and asking me. When you ask questions about some challenges, this is the way to do it—explain to me your numerous attempts to solve the problem and how these various attempts have failed. I will not help you if you have not tried to help yourself first (maybe with advice from friends). There will be a time in class to do this, typically before we embark on a new topic.\nShould you require more time with me, find out when I am ‘free’ and set an appointment by sending me a calendar invitation. I am happy to have a personal meeting with you via Zoom, but I prefer face-to-face in my office.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#communication",
    "href": "BDC334/BDC334_syllabus.html#communication",
    "title": "Syllabus & Policies",
    "section": "Communication",
    "text": "Communication\nAd-hoc communication is encouraged. Subscribe to the BDC334 WhatsApp group to openly discuss module content.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/BDC334_syllabus.html#advice-for-success",
    "href": "BDC334/BDC334_syllabus.html#advice-for-success",
    "title": "Syllabus & Policies",
    "section": "Advice for Success",
    "text": "Advice for Success\nYour success on this course depends very much on you and the effort you put into it. The module has been organised so that the burden of learning is on you, mainly by reading scientific publications on the week’s lecture topics. Your TAs and I will help you by providing you with materials and answering questions, and setting a pace, but for this to work you must do the following:\n\nComplete all the preparation work before class. This includes reading and working through the lecture slides.\nAsk questions. Engage with your peers and me. In a class or away from it. Use the WhatsApp group set up for this module and the comments section on the website. Surround yourself with people who are brighter than you, and make your conversations about ideas, not people and things. If you get a question wrong on an assessment, ask why. If you’re not sure about the Lab assignments, ask. If you hear something on the news that sounds related to what we discussed, raise it as a topic for discussion in class. If the reading is confusing, ask.\nDo all assignments and Labs, attend, and don’t be late. The earlier you start, the better. You should ask yourself how these exercises relate to earlier material and imagine how they might be changed (to make questions for an exam, for example.) It’s not enough to just mechanically plough through the exercises.\nTo learn how to translate your human thoughts into computer language (coding), you should work with computer and R multiple times each week—ideally daily.\nDon’t procrastinate. If something is confusing to you in Week 2, Week 3 will become more confusing, Week 4 even worse, and eventually, you won’t know where to begin asking questions. Don’t end a week with unanswered questions. But if you fall behind and don’t know where to start asking, come to my office, and let me help you identify a good (re)starting point.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Syllabus & Policies"
    ]
  },
  {
    "objectID": "BDC334/L03-structure.html",
    "href": "BDC334/L03-structure.html",
    "title": "Lecture 3: Species Distribution Patterns",
    "section": "",
    "text": "BCB743\n\n\n\nThis material must be reviewed by BCB743 students in Week 1 of Quantitative Ecology.\nUnivariate diversity measures such as Simpson and Shannon diversity have already been prepared from species tables, and we have also calculated measures of \\(\\beta\\)-diversity that looked at pairwise comparisons and offered insight into community structure across a landscape and hinted at the processes that might have resulted in these structures. These ways of expressing biodiversity only gets us so far in understanding the structure of communities. A much deeper insight into the processes responsible for community formation can be obtained by looking at how the species patterns are distributed across sites. This is the focus of this lecture.\nLet’s shine the spotlight to additional views on ecological structures and the ecological processes that structure the communities—sometimes we will see reference to ‘community or species formation processes’ to offer mechanistic views on how species come to be arranged into communities (the aforementioned turnover and nestedness-resultant \\(\\beta\\)-diversity are examples of other formation processes). Let’s develop views that are based on all the information contained in the species tables, i.e. abundance, the number of sites, and the diversity of the biota. This deeper view is not necessarily captured if we limit our toolkit to the various univariate and pairwise descriptors of biodiversity.\nYou will already be familiar with the paper by Shade et al. (2018). Several kinds of ecological patterns are mentioned in the paper, and they can be derived from a species table with abundance data (but not presence-absence data!). The patterns that can be derived from such a table include (see Figure 1 below), and they are as follows:",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 3: Species Distribution Patterns"
    ]
  },
  {
    "objectID": "BDC334/L03-structure.html#species-abundance-distribution",
    "href": "BDC334/L03-structure.html#species-abundance-distribution",
    "title": "Lecture 3: Species Distribution Patterns",
    "section": "Species Abundance Distribution",
    "text": "Species Abundance Distribution\nSpecies Abundance Distribution (SAD) describes how individuals are distributed among all the species within our sampled community. It tells us about the patterns of species dominance and rarity—this information relates to a more nuanced understanding of ecological dynamics, community structure, and the mechanisms driving biodiversity. SAD curves can be made for any community for which we have species lists with their abundances.\nThe first form of SAD is the one given by Shade et al. (2018), which shows the number of individuals (N) of each species in a sample. It is formed by log(N) (on y) as a function of species rank (on x), with species ranked 1 most abundant and plotted on the left and decreasing to less abundant species on the right. Matthews and Whittaker (2015) call this form of SAD a Rank Abundance Distribution (RAD) curve. The profile of this relationship can be variable, but in general it shows that only a few species attain a high abundance while the majority of them are rare. This is a typical pattern in most communities and is often referred to as a log-normal distribution, but some other models can also be used to describe these SADs. The type of model applied to a SAD curve may reveal different ecological processes and mechanisms. Matthews and Whittaker (2015) argue that the form of the SAD and the model that describes its form can be used to develop suitable ecosystem health assessment insights and develop applicable conservation and management strategies.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 3: Species Distribution Patterns"
    ]
  },
  {
    "objectID": "BDC334/L02b-biodiversity.html",
    "href": "BDC334/L02b-biodiversity.html",
    "title": "Lecture 2b: Metrics of Environmental & Species Diversity",
    "section": "",
    "text": "BCB743\n\n\n\nThis material must be reviewed by BCB743 students in Week 1 of Quantitative Ecology.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2b: Metrics of Environmental & Species Diversity"
    ]
  },
  {
    "objectID": "BDC334/L02b-biodiversity.html#quantifying-diversity",
    "href": "BDC334/L02b-biodiversity.html#quantifying-diversity",
    "title": "Lecture 2b: Metrics of Environmental & Species Diversity",
    "section": "Quantifying Diversity",
    "text": "Quantifying Diversity\nWhen we talk about ‘biodiversity,’ we usually refer to the variety of species present in a given area or ecosystem. This includes the diversity of species, genetic diversity within species, and the diversity of ecosystems or habitats. To quantify biodiversity, we need metrics that say something about the:\n\nVariability and properties of the environment.\nSpecies present in a given area (species lists).\nRelative abundance of each species.\nDistribution (spatial configuration) of species across different habitats or ecosystems.\n\nIn this lecture, we will discuss some of the most common metrics used to quantify biodiversity. We will also discuss the concept of species richness, evenness, and diversity, and how these metrics can be used to compare different habitats or ecosystems.\nThe metrics used to quantify biodiversity can be broadly classed into three groups depending on the kind of information they provide:\n\nBiodiversity metrics (\\(\\alpha\\)-diversity, \\(\\beta\\)-diversity, \\(\\gamma\\)-diversity).\nDiversity indices (Shannon’s Entropy, Gini Index, Herfindahl-Hirschman Index (HHI))\nDistance measures (e.g. Euclidean, Manhattan).\nDissimilarity indices (e.g. Bray-Curtis, Jaccard, Sørensen).",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2b: Metrics of Environmental & Species Diversity"
    ]
  },
  {
    "objectID": "BDC334/L02b-biodiversity.html#biodiversity-metrics",
    "href": "BDC334/L02b-biodiversity.html#biodiversity-metrics",
    "title": "Lecture 2b: Metrics of Environmental & Species Diversity",
    "section": "Biodiversity Metrics",
    "text": "Biodiversity Metrics\n\n\\(\\alpha\\)-Diversity (Species Richness)\nAlpha diversity quantifies the diversity of species within a specific, localised area or community. This could be a site, plot, quadrat, a field, or any other small unit of (typically) replication in the study. This measure provides information about the ecological structure and complexity of a given habitat at a fine scale.\nThere are several ways to represent \\(\\alpha\\)-diversity. The simplest and most straightforward measure is species richness, which is simply a count of the number of different species present in the sampling area. Simply put, this is a list of species within the local scale. If we have multiple local scale sites, we can calculate the average species richness across all sites (Figure 1).\n\n\n\n\n\n\nFigure 1: Alpha-diversity in one sense is the simple expression of the average species richness (number of species) across a landscape.\n\n\n\nSpecies richness is easy to understand and implement, but it doesn’t account for the relative abundance of each species within the community. To address this limitation we make use of univariate indices. Shannon’s H’ (Shannon’s Diversity Index) and Simpson’s \\(\\lambda\\) (Simpson’s Diversity Index) are such univariate diversity indices. These indices place various amounts of emphasis on the abundance and evenness of species present.\nChoosing Shannon’s or Simpson’s is a bit controversial and it often depends on who is using it. According to Jari Oksanen, author of the vegan package in R, the choice between Shannon’s and Simpson’s index is a matter of personal preference. He writes:\n\nBetter stories can be told about Simpson’s index than about Shannon’s index, and still grander narratives about rarefaction (Hurlbert 1971). However, these indices are all very closely related (Hill 1973), and there is no reason to despise one more than others (but if you are a graduate student, don’t drag me in, but obey your Professor’s orders). In particular, the exponent of the Shannon index is linearly related to inverse Simpson (Hill 1973) although the former may be more sensitive to rare species.\n\nBoth Shannon’s H’ or Simpson’s \\(\\lambda\\) can be applied to the local scale, or averaged across multiple sites to get a regional scale measure of the average \\(\\alpha\\)-diversity. We will revisit Shannon’s H’ or Simpson’s \\(\\lambda\\) lower down in this section as they also crop up in under the heading of Diversity Indices (another logical place to classify the same concepts).\n\n\n\\(\\beta\\)-Diversity (Variation in Diversity)\nA related concept of diversity is one that considers the variation between sites (Figure 2). This is known as \\(\\beta\\)-diversity. \\(\\beta\\)-diversity refers to the measure of diversity between different communities or ecosystems within a larger region. It quantifies the variation in species composition from one habitat or site to another and captures the degree of differentiation or turnover of species across spatial scales. \\(\\beta\\)-diversity helps to understand how species diversity is distributed across different environments and can indicate the impact of environmental gradients, habitat fragmentation, and ecological processes on community composition. It links local (\\(\\alpha\\)-diversity) and regional (\\(\\gamma\\)-diversity) scales and offers a processed-based view on biodiversity formation.\n\n\n\n\n\n\nFigure 2: Beta-diversity quantifies the variation in species richness (number of species) and composition (number of individuals of a particular species) across the landscape.\n\n\n\n\\(\\beta\\)-diversity has a long history in ecology and has undergone several conceptual revisions over the years. The concept was first introduced by Whittaker (1960) to describe the variation in species composition between different sites.\nWhittaker’s initial idea was that of true \\(\\beta\\)-diversity (hence it sometimes being called Whittaker’s \\(\\beta\\)-diversity), which is often defined as the effective number of distinct communities in a region. It can be calculated as the ratio of \\(\\gamma\\)-diversity to \\(\\alpha\\)-diversity when these are expressed as Hill numbers or effective numbers of species. Mathematically, this is expressed as:\n\\[\\beta = \\frac{\\gamma}{\\alpha}\\]\nwhere \\(\\beta\\) is true \\(\\beta\\)-diversity, \\(\\gamma\\) is the total diversity of the region, and \\(\\alpha\\) is the mean diversity of the individual communities.\nAnother approach is absolute species turnover, which is a measure of the total amount of species change between communities or along environmental gradients. It can be calculated in various ways, but one common approach is to use the Whittaker’s \\(\\beta\\)-diversity index:\n\\[\\beta_w = \\frac{S}{\\alpha} - 1\\]\nwhere \\(S\\) is the total number of species in all communities combined (\\(\\gamma\\)-diversity), and \\(\\alpha\\) is the average number of species found in all the local scale samples that comprise the region.\nThis measure of turnover ranges from 0 (when all communities have identical species composition) to a maximum value that depends on the number of communities being compared. It provides a quantitative measure of how much species composition changes across communities or sites.\nContemporary views of \\(\\beta\\)-diversity were developed by Nekola and White (1999), Baselga (2010), and Anderson et al. (2011). This information is encapsulated with pairwise matrices of dissimilarity indices (see the section below on dissimilarity indices where the various dissimilarity indices are presented in more detail) calculated for each pair of sites within the studied system. The broad implication is the same as how it was traditionally applied: that is, \\(\\beta\\)-diversity describes how species formation (into communities) measured within the ecosystem of interest vary from place to place, e.g. between the various transects or quadrats used to sample the ecosystem. But, these modern interpretations of \\(\\beta\\)-diversity extract from these views of habitat heterogeneity some deeper insights about the mechanisms responsible for driving the community formation process, viz. the role of gradients (Process 1: niche theory) and stochastic processes (Process 2: neutral theory).\nProcess 1: If a region comprises the species A, B, C, …, M (i.e. \\(\\gamma\\)-diversity is 13), a subset of the regional flora captured by one quadrat might be species A, D, E. In another quadrat species A, D, F might be present. \\(\\alpha\\)-diversity is three in both instances, and heterogeneity (and hence \\(\\beta\\)-diversity) results from the fact that the first quadrat has species E, but the other has species F. In other words, here, we have the same number of species in both quadrats, but only two of the species are the same. The process responsible for this form of \\(\\beta\\)-diversity is species turnover, \\(\\beta_\\text{sim}\\). Turnover refers to processes that cause communities to differ due to species being lost or gained from section to section, i.e. the species composition changes between sections without corresponding changes in \\(\\alpha\\)-diversity. The function beta() in the R package BAT calls this form of \\(\\beta\\) diversity replacement and use the symbol \\(\\beta_{repl}\\) (Cardoso et al. 2015).\nProcess 2: Consider again species A, B, C, …, M. Now we have a quadrat with species A, B, C, D, G, H (\\(\\alpha\\)-diversity is six) but another quadrat has a subset of these species, e.g. only species A, B, G (\\(\\alpha\\)-diversity three). Here, \\(\\beta\\)-diversity is high even though the quadrats share some species, but the number of species differs among the quadrats (i.e. from place to place) due to one quadrat capturing only a subset of species present in the other. This form of \\(\\beta\\)-diversity is called nestedness-resultant \\(\\beta\\)-diversity, \\(\\beta_\\text{sne}\\), and it refers to processes that cause species to be gained or lost, and the community with the lowest \\(\\alpha\\)-diversity is a subset of the richer community. The function beta() in the R package BAT calls this form of \\(\\beta\\) diversity *richness difference** and uses the symbol \\(\\beta_{rich}\\) (Cardoso et al. 2015).\nThe above two examples show that \\(\\beta\\)-diversity is coupled not only with the identity of the species in the quadrats but also \\(\\alpha\\)-diversity—with species richness in particular.\nWe express \\(\\beta\\)-diversity as nestedness-resultant, \\(\\beta_\\text{sne}\\), and turnover, \\(\\beta_\\text{sim}\\), components to be able to distinguish between these two processes. It allows us to make inferences about the two possible drivers of \\(\\beta\\)-diversity. Turnover refers to processes that cause communities to differ due to species being lost or gained from section to section, i.e. the species composition changes between sections without corresponding changes in \\(\\alpha\\)-diversity. The nestedness-resultant component implies processes that cause species to be gained or lost without replacement, and the community with the lowest \\(\\alpha\\)-diversity is a subset of the richer community.\nAccording to Nekola and White (1999) on p. 868, there are two causes of ecological distance decay. ‘Ecological’ is key to the first cause—it is environmental filtering results in a decrease in similarity as the distance between sites increases. We sometimes call this the niche difference model. Such patterns are typically visible along steep environmental gradients such as elevation slopes (mountains), latitude, or depth in the ocean, to name only three. It is also the dominant mechanism underlying island biogeography.\nThe second cause of distance decay sensu Nekola and White (1999) involves aspects of the spatial configuration, context of the habitats, and some temporal considerations. Here, the evolutionary differences between species—specifically around those traits that affect their ability to disperse—are more at play and are the primary influences of distance decay rates that might vary between species. Let us first consider some properties of a hypothetical homogeneous landscape. The landscape creates some impediment (resistance) to the propagation of some species (hypothetically species A, B, and C) across its surface, but which are less effective in impeding others (D, E, and F). For argument’s sake, all species (A, …, F) share similar environmental tolerances to the prevailing environmental conditions, so one can argue that the niche difference model (environmental filtering) does not explain distributional patterns. Given a particular founding or disturbance event, species D, E, and F will, in a relatively shorter period, be able to become evenly distributed (relatively similar abundances everywhere) across this landscape. However, the less vagile (in terms of dispersal ability), species A, B, and C will develop a steeper gradient of decreasing species abundances away from the founding populations (resulting from, for example, adaptive radiation). They will require more time to become homogeneously dispersed across the landscape. In this regard, historical events set up striking distributional patterns that can be mistaken for gradients, which exist because insufficient time has passed to ensure complete dispersal. Studying the influence of such past events is called ‘historical biogeography.’ In reality, landscapes are seldom homogeneous in their spatial template (e.g. there are hills and valleys), and variable dispersal mechanisms and abilities will interact with this heterogeneous landscape to form interesting patterns of communities. The ecologist will have an exciting time figuring out the relative importance of actual gradients vs those that result from evolved traits that affect their dispersal ability and interact with the environment. I have not said anything about ‘neutral theories’ (but which are seen in the \\(\\beta_\\text{sne}\\) form of \\(\\beta\\)-diversity as in Smit et al. 2017), nor biological interactions that might affect community structure.\n\n\n\\(\\gamma\\)-Diversity (Regional Diversity)\nWhile \\(\\alpha\\)-diversity focuses on the local scale, representing the species richness within a specific area or community, the concept of species richness changes as we broaden our scope of observation. This brings us to the concept of \\(\\gamma\\)-diversity, which refers to the overall diversity of a larger area or region encompassing multiple local-scale units of observation or quantification (Figure 3). The transition from \\(\\alpha\\)- to \\(\\gamma\\)-diversity occurs as we aggregate data from multiple sampling units or sites within a broader landscape or ecosystem. \\(\\gamma\\)-diversity captures the total species diversity across all the local communities in a region. It is not merely the average \\(\\alpha\\)-diversity or total \\(\\alpha\\)-diversity aggregated over individual sites; rather, it reflects the combined diversity, including both the diversity within each local community (\\(\\alpha\\)-diversity) and the diversity between communities (\\(\\beta\\)-diversity).\n\n\n\n\n\n\nFigure 3: Gamma-diversity is the total species list (number of species) across a landscape taking into account all sampling units representative of that landscape.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2b: Metrics of Environmental & Species Diversity"
    ]
  },
  {
    "objectID": "BDC334/L02b-biodiversity.html#sec-diversity-indices",
    "href": "BDC334/L02b-biodiversity.html#sec-diversity-indices",
    "title": "Lecture 2b: Metrics of Environmental & Species Diversity",
    "section": "Diversity Indices",
    "text": "Diversity Indices\nA diversity index is a metric that quantifies species diversity within a community. While species richness simply refers to the number of species present, diversity indices also consider the relative abundances of these species. For instance, consider two communities: community A comprises 10 individuals of each of 10 species (totalling 100 individuals) and community B has 9 species with 1 individual each, and a 10th species with 91 individuals (also totalling 100 individuals). Which community is more diverse? To address this, diversity indices incorporate both richness and evenness information and provides a more comprehensive assessment of diversity than species richness alone.\n\nMargalef’s Index\nMargalef’s Index is a simple measure of species richness that accounts for the number of species in a community and the total number of individuals. The formula for Margalef’s Index is:\n\\[\nD = \\frac{S - 1}{\\ln(N)}\n\\]\nwhere \\(S\\) is the total number of species in the community, and \\(N\\) is the total number of individuals. A higher value of \\(D\\) indicates greater diversity.\n\n\nShannon’s Entropy\nShannon’s Entropy, or Shannon’s H’, comes out of the field of information theory and was developed by Claude Shannon. It measures the uncertainty or diversity within a system. It is a general measure of information content and is applicable to a variety of data types beyond species diversity, such as genetic diversity, linguistic diversity, or even the distribution of different types of land use in a landscape. The formula for Shannon’s H’ is as used by ecologists is:\n\\[\nH' = -\\sum_{i=1}^{S} p_i \\ln(p_i)\n\\]\nwhere \\(S\\) is the total number of species in the community, and \\(p_i\\) is the proportion of individuals belonging to species \\(i\\). A higher H’ value indicates greater diversity, with values typically ranging from 0 to about 4.5, rarely exceeding 5 in extremely diverse communities. We use this index to help us understand the evenness and richness of species within a community, and it is used when we need to emphasise the contribution of rare species.\n\n\nSimpson’s Indices\nSimpson’s Indices are a group of related diversity measures developed by Edward H. Simpson. These indices focus on the dominance or evenness of species in a community, giving more weight to common species and being less sensitive to species richness compared to Shannon’s H’.\n\nSimpson’s Dominance Index\nSimpson’s Dominance Index (\\(\\lambda\\)) measures the probability that two individuals randomly selected from a sample will belong to the same species. The formula for Simpson’s Dominance Index is:\n\\[\n\\lambda = \\sum_{i=1}^{S} p_i^2\n\\]\nwhere \\(S\\) is the total number of species, and \\(p_i\\) is the proportion of individuals belonging to species \\(i\\). Values range from 0 to 1, with higher values indicating lower diversity (higher dominance). A value of 1 represents no diversity (only one species present), while a value approaching 0 indicates very high diversity.\n\n\nSimpson’s Diversity Index\nTo make the index more intuitive we prefer to use Simpson’s Diversity Index, which is calculated as:\n\\[\n1 - \\lambda = 1 - \\sum_{i=1}^{S} p_i^2\n\\]\nThis form ensures that the index increases with increasing diversity. Values range from 0 to 1, with higher values indicating higher diversity.\n\n\nSimpson’s Reciprocal Index\nAnother common form is Simpson’s Reciprocal Index, calculated as:\n\\[\n\\frac{1}{\\lambda} = \\frac{1}{\\sum_{i=1}^{S} p_i^2}\n\\]\nThis index starts with a value of 1 as the lower limit, representing a community containing only one species. The upper limit is the number of species in the sample (S). Higher values indicate greater diversity.\nSimpson’s Indices are less sensitive to species richness and more sensitive to evenness compared to Shannon’s Entropy. They are useful when you want to give more weight to common species in your diversity assessment.\n\n\n\nGini Index\nThe Gini Index, or Gini Coefficient, should be fimiliar to all South Africans—South Africa is infamous for having the highest Gini Coefficient in the world. The Gini Index is a measure of inequality within a distribution, and is typically used in economics to assess income or wealth inequality. Since its purpose is to evaluate disparity, it is also suited to ecological systems because, here too, the distribution in abundance differs among species. The formula for the Gini Index is:\n\\[\nG = \\frac{\\sum_{i=1}^{N} \\sum_{j=1}^{N} |x_i - x_j|}{2N^2 \\bar{x}}\n\\]\nwhere \\(N\\) is the total number of observations, \\(x_i\\) and \\(x_j\\) are the values of the observations, and \\(\\bar{x}\\) is the mean of the values. In ecological studies, a high Gini Index indicates a large disparity in species abundances, with few species dominating the community, whereas a low Gini Index suggests a more even distribution of individuals among species.\n\n\nHerfindahl-Hirschman Index (HHI)\nThe Herfindahl-Hirschman Index (HHI) is a measure of market concentration commonly used in economics to assess the level of competition within an industry. It is calculated as the sum of the squares of the market shares of all firms in the market. Ecologists sometimes use the HHI to assess species dominance or the concentration of individuals within species. The formula for HHI is:\n\\[\nHHI = \\sum_{i=1}^{N} s_i^2\n\\]\nwhere \\(N\\) is the total number of species, and \\(s_i\\) is the proportion of individuals belonging to species \\(i\\). Here, a higher HHI indicates a higher concentration of individuals in a few species, signifying lower diversity. Conversely, a lower HHI reflects a more even distribution of individuals across species, indicating higher diversity.\nHere’s a corrected and improved version of the text:",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2b: Metrics of Environmental & Species Diversity"
    ]
  },
  {
    "objectID": "BDC334/L02b-biodiversity.html#sec-resemblance-metrics",
    "href": "BDC334/L02b-biodiversity.html#sec-resemblance-metrics",
    "title": "Lecture 2b: Metrics of Environmental & Species Diversity",
    "section": "Ecological Resemblance",
    "text": "Ecological Resemblance\nResemblance matrices are mathematical representations used to quantify the similarity or dissimilarity between pairs of samples, communities, or ecological sampling units based on various criteria such as species composition, abundance, functional traits, phylogenetic relatedness, or environmental properties. Well-structured raw data about species composition typically come in the form of a table with rows representing sites or samples, and columns representing species. Similarly, data about environmental variables are structured as a table with rows representing sites or samples, and columns representing environmental variables.\nThe diagram below (Figure 4) summarises the species and environmental data tables, and what we can do with them. These tables are the starting points of many additional analyses, and we will explore some of these deeper insights later in this module.\n\n\n\n\n\n\nFigure 4: Species and environmental tables, resemblance matrices, and deeper analyses possible from the various kinds of ecological data. The ordinations (e.g. PCA, CA, nMDS, etc.) will only be covered in BCB743 in your Honours year.\n\n\n\n\n\n\n\n\n\nTerminology: matrices and tables\n\n\n\nAlthough we often use the terms ‘matrix’ and ‘table’ interchangeably, in this book I use matrix to refer to a mathematical object with rows and columns and with the cell content derived from calculations of distances and dissimilarities. In these situations they tend to be square and symmetrical. I then use the term table to refer to a more general data structure, also with rows and columns, but here representing samples or sites (as rows) and columns representing species or environmental variables. My use of ‘table’ generally refers to the raw data we use as a starting point for our calculations (including of the matrices).\nThis is my notations and authors such as Borcard et al. (2011), David Zelený, and Michael Palmer may not make this distinction and use both terms to refer to a rectangular data structure.\n\n\nWhen the focus is on comparing sites (i.e., the information about objects in the rows of site × species or site × environment tables) based on their species composition or environmental characteristics, we call this type of analysis an R-mode analysis. Such resemblance matrices typically manifest as square matrices, with rows and columns representing the samples or units being compared.\nOther cases of square resemblance matrices include: i) Species-by-species matrices (association matrices), where both rows and columns represent species, and the values in the matrix represent the association between each pair of species. ii) Environmental-by-environmental matrices (correlation matrices), where both rows and columns represent environmental variables, and the values in the matrix represent the correlation between each pair of variables. In these cases, the focus falls onto the information initially contained in the columns (species or descriptors) of the sites × species table or the sites × environmental variables table. This is called a Q-mode analysis.\nEnvironmental resemblance matrices, or environmental distance matrices, are used to quantify the similarity between pairs of sites based on their environmental variables. They can also be used in more advanced analyses, such as various kinds of ordinations and clustering. These matrices have zeros down the diagonal, as the distance between a site and itself is zero. The subdiagonal values are typically the same as the superdiagonal values, as the dissimilarity between samples \\(i\\) and \\(j\\) is the same as the dissimilarity between samples \\(j\\) and \\(i\\), i.e., the matrices are symmetrical. The off-diagonal values represent the distance between pairs of sites, with higher values indicating greater dissimilarity.\nIn species dissimilarity matrices (species resemblance matrices), the values represent the degree of dissimilarity between each pair of samples. Dissimilarity matrices are characterised by a diagonal filled with zeros, because the dissimilarity between a sample and itself is zero. The off-diagonal values represent the dissimilarity between pairs of samples, with higher values indicating greater dissimilarity. They are also symmetrical for the same reasons given for the environmental matrices. Species dissimilarity matrices are used in various multivariate analyses, such as cluster analysis, ordination, and diversity partitioning.\nLegendre and Legendre (2012) provide a full chapter (Chapter 7) on ecological resemblance, including an in-depth look at the various kinds of ‘association coefficients,’ which is what we will cover next. The next two sub-sections will thus introduce a few frequently used association coefficients to study species dissimilarity and environmental distances across the landscape.\n\nEnvironmental Distance\nSometimes we need to quantify the environmental similarities or differences between sampling sites, such as plots, quadrats, or transects. This is typically achieved through the use of distance matrices (one kind of resemblance matrix), which provide an overall view of how all the sites relate to one another. These matrices are derived from data tables containing information on environmental variables (sites in rows and variables in columns).\nThere are several kinds of distance metrics available for use with environmental data. Regardless of which index one chooses, the resulting matrix provides pairwise differences (or distances) or similarities in a metric that relates to the ecological distance between all sites (and which might also link to their community composition, which is the thing we are trying to determine). Such pairwise matrices are foundational for various multivariate analyses and can reveal patterns in ecological data that might not be apparent from raw measurements of individual variables alone.\nEuclidean distance is in my experience the commonly used in spatial analysis. It defined as the straight-line distance between two points in Euclidean space. In its simplest form, it applies to a planar area such as a graph with \\(x\\)- and \\(y\\)-axes, but it can be extended to higher dimensions. In two or three dimensions, it gives the Cartesian distance between points on a plane (\\(x\\), \\(y\\)) or in a volume (\\(x\\), \\(y\\), \\(z\\)), and this concept can be further extended to higher-dimensional spaces. Euclidean distance conforms to our intuitive physical concept of distance, making it useful for applications like measuring short geographic distances between points on a map. However, over large distances on Earth’s surface, Euclidean distance loses accuracy due to the Earth’s spherical shape. In such cases, great circle distances, calculated using formulas like the Haversine formula, provide more accurate measurements.\nMathematically, Euclidean distance is calculated using the Pythagorean theorem. This method squares the differences between coordinates, which means that single large differences become disproportionately important in the final distance calculation. While this property makes Euclidean distance useful for environmental data, where it effectively calculates the ‘straight-line distance’ between two points in multidimensional space (with each dimension representing an environmental variable), it is ill suited to species data.\nThe Euclidean distance between two points \\(A\\) and \\(B\\) in a \\(n\\)-dimensional space is calculated as:\n\\[\nd_{jk} = \\sqrt{\\sum_{i=1}^{n} (j_i - k_i)^2}\n\\]\nwhere \\(j_i\\) and \\(k_i\\) are the values of the \\(i\\)-th variable at points \\(j\\) and \\(k\\), respectively.\nOther distance metrics are the Mahalanobis Distance, Manhattan Distance, Canberra Distance, Gower Distance, and Bray-Curtis Dissimilarity. I’ll not discuss them here and you can refer to Chapter 3 in the book by Borcard et al. (2011) for more information. Additionally, vegan’s vegdist() function does a very good job of providing a wide range of distance metrics and you can find a discussion of many of them in the function’s help file, which you can access as ?vegan::vegdist.\n\n\nSpecies Dissimilarities\nEcological similarity between sites is fundamentally tied to their species composition, which is a function of both species richness and abundance. Sites that share similar species compositions are considered ecologically similar and exhibit a low dissimilarity metric. The factors influencing this similarity are complex and influenced by many properties of the environment and processes operating there.\nAs we have already seen, the degree of similarity between sites can be attributed to measurable environmental differences (i.e. hopefully captured in the environmental distance matrices we saw above) that directly influence species composition. These might include variables like soil type, climate, or topography. However, similarity can also be affected by unmeasured, often overlooked influences that are not immediately apparent or easily quantifiable. Additionally, some degree of variation may simply be attributed to ecological ‘noise’—random fluctuations or stochastic events that affect species distributions.\nIt is our role to disentangle these various influences and determine the primary drivers of similarity or dissimilarity among sites. To aid in this analysis, we use a class of matrices known as dissimilarity matrices (a type of resemblance matrix). These matrices quantify the dissimilarity between sites based on their species composition.\nVarious indices have been developed to compare the composition of different groups or communities. These diversity indices quantify how different or similar groups are based on their attributes, primarily species richness and/or relative abundances. While the simplest application is to compare the species composition of two sites, these indices can be extended to compare multiple groups or communities. They are core to the study of β-diversity, which examines the variation in species composition among sites within a geographic area.\nI’ll present the Bray-Curtis dissimilarity as an example, which is a widely-used metric for comparing species composition between two sites. For abundance data, it is calculated as follows:\n\\[\nd_{jk} = \\frac{\\sum_i |x_{ij} - x_{ik}|}{\\sum_i (x_{ij} + x_{ik})}\n\\]\nwhere \\(x_{ij}\\) and \\(x_{ik}\\) are the abundances of species \\(i\\) (the columns) at sites \\(j\\) and \\(k\\) (the rows) respectively.\nFor presence-absence data, the Bray-Curtis dissimilarity simplifies to:\n\\[\nd_{AB} = \\frac{A+B-2J}{A+B-J}\n\\]\nwhere \\(J\\) is the number of species present in both sites being compared, \\(A\\) is the number unique to site A, and \\(B\\) is the number unique to site B.\nThe Bray-Curtis dissimilarity ranges from 0 (indicating identical species compositions) to 1 (indicating completely different compositions). This metric can be used to construct dissimilarity matrices for multivariate analyses, where each cell in the matrix represents the ecological distance between a pair of sites based on their species composition.\nIn practice, these dissimilarity indices and distances can be calculated using the vegan R package’s vegdist() function. Refer to ?vegan::vegdist for information and a deeper look.\nCommon dissimilarities suited to presence-absence data are the Jaccard Dissimilarity, Sørensen-Dice index, and Ochiai index. For abundance data, we have already seen the Bray-Curtis dissimilarity, but you also have the Morisita-Horn index, which is also commonly used. The Raup-Crick index is used to compare the dissimilarity between two groups to the expected dissimilarity between two random groups, whilst the Chao-Jaccard and Chao-Sørensen indices are probabilistic versions of the Jaccard and Sørensen indices that account for unseen shared species.",
    "crumbs": [
      "Home",
      "BDC334 Biogeography & Global Ecology",
      "Lecture 2b: Metrics of Environmental & Species Diversity"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html",
    "href": "pages/BDC223_FAQ.html",
    "title": "FAQ",
    "section": "",
    "text": "This question was asked by 3rd years, but it is relevant here too.\nI just need some advice from sir. I’m starting to study today and I just wanted to know what do you think is the best way to study for sir’s exam. I’m asking because I studied really hard for the midterm tests but I still got low marks lol. So I just wanted to know if there is maybe a different approach that I can take.\n\nI was trying to memorise things for the midterm tests but I know sir said we must focus on understanding but when I focus on understanding then the work does not stick in my head😂.\n\nSo far I’ve just read through the articles but is there any advice that sir can give me please?\n\n\nThank you for your email. Hmmm, a tricky question to ask of someone who wrote their last exam in 1993!\nI am the opposite to you. I cannot memorise things but I am able to understand things really well. Fortunately, in the process of figuring things out, the relevant bits of information/knowledge relating to the thing I am trying to understand also sticks in my mind, which is (for me) a useful side effect of figuring things out. For me, it is pointless having things to memorise unless I can apply it to something that needs figuring out. So, everything I know, I know because it is useful to me.\nHow does understanding come about? For me, I try and understand stuff because the challenge of a tricky problem is thrilling, so understanding is facilitated because the process aligns with what makes me ‘tick.’ Okay, so this does not answer how understanding comes about; it simply talks to who I am.\nI can tell you is how you can test your understanding. Explain the thing you are trying to understand to a friend or family member. If your explanation of the topic brings about an understanding in the other person, then you yourself understand it. At least this process will tell you where your own understanding starts to fail. As Richard Feynman said, “If you cannot explain something to a 7-year old, you don’t understand it yourself.” Or something like that.\nFor someone who finds it easier to memorise stuff and more challenging to understand… I don’t know what that feels like as I have no personal experience or frame of reference that allows me to place myself into your shoes. But here is the theory:\n\nKnow what it is you already know, and build upon that (see point 2).\nStructure new and existing knowledge around the major concepts and principles of the module (broadly, the new concepts covered each week). This means that work done in your first and second years of your study, in ALL the modules you completed, remains relevant, and has to be used together with the new knowledge obtained in the new module, and structured around the broad concept and principle (there are many concepts and principles a module).\nYou need to develop and understand the language used to communicate the topic. At the very basic level, this requires that you understand in intricate detail the individual words (ALL of them) that form the foundational language of your study discipline (biology and science more broadly). Only once you understand the definitions of individual words will you be able to develop more complex understanding. I think this is the primary reason why students fail to develop a deep understanding of a topic that requires explanation in multiple paragraphs (long answers and essays).\nAnother step involves knowing how all the steps that inform the thinking process are interrelated. This requires that you consider some of the following things: What does the assignment or task require me to do (i.e. unpack the problem)? What are the steps I need to follow to get there? What do I already know about it? What do I not understand and where do I get stuck? Why don’t I know it already? What about the problem causes me to get stuck? Where do I get the knowledge about what I don’t understand, and how can I use this to become unstuck? Okay, so now I am figuring things out… What does the problem remind me about? Have I encountered something similar before, and if so, how can I use that to develop further my current thinking about the problem? This whole process is called metacognition, which is thinking about thinking and learning. This kind of thing has to happen each time you see something new, come across a new piece of information, listen to someone speak, etc. It can be applied in your day to day life to the extent that it become implicit in how you approach life. Eventually, you’ll find yourself saying more often, “I am wondering…” Then you will arrive at critical thinking, which is what makes science special.\nHow well you are able to integrate the metacognitive skills in your life and learning depends unfortunately on your inherent abilities and prior experiences. It is easier for some than it is for others.\nA critical characteristic of good learning is that it informs your sense of self — this means that once you value learning as one of the things most important things (attributes) which informs who you are as a person, the easier it will become to learn, the less effort it will take, and the more learning itself will become the motivator (as opposed to search for motivation externally, like some reward, for having to learn).\nThe activities in your life, your friends, family and interests will also shape how much you learn, and what you learn.\nYou need to mix with people who values learning to the same extent that you do, so this social reinforcement further ‘snowballs’ into life-long learning and understanding.\n\nStep no. 4. is probably to most helpful.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-how-to-study",
    "href": "pages/BDC223_FAQ.html#question-how-to-study",
    "title": "FAQ",
    "section": "",
    "text": "This question was asked by 3rd years, but it is relevant here too.\nI just need some advice from sir. I’m starting to study today and I just wanted to know what do you think is the best way to study for sir’s exam. I’m asking because I studied really hard for the midterm tests but I still got low marks lol. So I just wanted to know if there is maybe a different approach that I can take.\n\nI was trying to memorise things for the midterm tests but I know sir said we must focus on understanding but when I focus on understanding then the work does not stick in my head😂.\n\nSo far I’ve just read through the articles but is there any advice that sir can give me please?\n\n\nThank you for your email. Hmmm, a tricky question to ask of someone who wrote their last exam in 1993!\nI am the opposite to you. I cannot memorise things but I am able to understand things really well. Fortunately, in the process of figuring things out, the relevant bits of information/knowledge relating to the thing I am trying to understand also sticks in my mind, which is (for me) a useful side effect of figuring things out. For me, it is pointless having things to memorise unless I can apply it to something that needs figuring out. So, everything I know, I know because it is useful to me.\nHow does understanding come about? For me, I try and understand stuff because the challenge of a tricky problem is thrilling, so understanding is facilitated because the process aligns with what makes me ‘tick.’ Okay, so this does not answer how understanding comes about; it simply talks to who I am.\nI can tell you is how you can test your understanding. Explain the thing you are trying to understand to a friend or family member. If your explanation of the topic brings about an understanding in the other person, then you yourself understand it. At least this process will tell you where your own understanding starts to fail. As Richard Feynman said, “If you cannot explain something to a 7-year old, you don’t understand it yourself.” Or something like that.\nFor someone who finds it easier to memorise stuff and more challenging to understand… I don’t know what that feels like as I have no personal experience or frame of reference that allows me to place myself into your shoes. But here is the theory:\n\nKnow what it is you already know, and build upon that (see point 2).\nStructure new and existing knowledge around the major concepts and principles of the module (broadly, the new concepts covered each week). This means that work done in your first and second years of your study, in ALL the modules you completed, remains relevant, and has to be used together with the new knowledge obtained in the new module, and structured around the broad concept and principle (there are many concepts and principles a module).\nYou need to develop and understand the language used to communicate the topic. At the very basic level, this requires that you understand in intricate detail the individual words (ALL of them) that form the foundational language of your study discipline (biology and science more broadly). Only once you understand the definitions of individual words will you be able to develop more complex understanding. I think this is the primary reason why students fail to develop a deep understanding of a topic that requires explanation in multiple paragraphs (long answers and essays).\nAnother step involves knowing how all the steps that inform the thinking process are interrelated. This requires that you consider some of the following things: What does the assignment or task require me to do (i.e. unpack the problem)? What are the steps I need to follow to get there? What do I already know about it? What do I not understand and where do I get stuck? Why don’t I know it already? What about the problem causes me to get stuck? Where do I get the knowledge about what I don’t understand, and how can I use this to become unstuck? Okay, so now I am figuring things out… What does the problem remind me about? Have I encountered something similar before, and if so, how can I use that to develop further my current thinking about the problem? This whole process is called metacognition, which is thinking about thinking and learning. This kind of thing has to happen each time you see something new, come across a new piece of information, listen to someone speak, etc. It can be applied in your day to day life to the extent that it become implicit in how you approach life. Eventually, you’ll find yourself saying more often, “I am wondering…” Then you will arrive at critical thinking, which is what makes science special.\nHow well you are able to integrate the metacognitive skills in your life and learning depends unfortunately on your inherent abilities and prior experiences. It is easier for some than it is for others.\nA critical characteristic of good learning is that it informs your sense of self — this means that once you value learning as one of the things most important things (attributes) which informs who you are as a person, the easier it will become to learn, the less effort it will take, and the more learning itself will become the motivator (as opposed to search for motivation externally, like some reward, for having to learn).\nThe activities in your life, your friends, family and interests will also shape how much you learn, and what you learn.\nYou need to mix with people who values learning to the same extent that you do, so this social reinforcement further ‘snowballs’ into life-long learning and understanding.\n\nStep no. 4. is probably to most helpful.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#what-are-climatic-envelopes",
    "href": "pages/BDC223_FAQ.html#what-are-climatic-envelopes",
    "title": "FAQ",
    "section": "What are climatic envelopes?",
    "text": "What are climatic envelopes?\nGood day sir, there isn’t a good definition of climatic envelopes on google. Sir spoke about it in consequences in climate change. Not really sure what it specifically is.\n\nAnswer\nClimatic envelopes are the suite of environmental conditions required for plant (or animal) growth that define the optimal niche area and hence the organism’s distribution.\nOne can model the future climatic envelopes using various statistical approaches, and hence so project the future distribution of the species (or ecosystems) whose distribution are linked to those envelopes. Such models are called bioclimatic models or niche models.\nThe process is called species distribution modelling. We will do this in Hons.\nEnough? The first little para I wrote is the definition and all you would put down if I asked.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-acclimatisation",
    "href": "pages/BDC223_FAQ.html#question-about-acclimatisation",
    "title": "FAQ",
    "section": "Question About Acclimatisation",
    "text": "Question About Acclimatisation\nI also wanted to ask. When plants avoid stress, is it not acclimatization as well?\n\nAnswer\nYes. But there’s only a certain range of env conditions plants can acclimatise to, and exceeding those limits will still cause stress.\nAcclimatisation can happen over minutes to hours to days. Or seasonally. But if env conditions exceed the normal range of variability they’ll become stressed.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-the-organic-foods-essay-topic",
    "href": "pages/BDC223_FAQ.html#question-about-the-organic-foods-essay-topic",
    "title": "FAQ",
    "section": "Question About the Organic Foods Essay Topic",
    "text": "Question About the Organic Foods Essay Topic\nI chose the organic food topic. My question is if I should find research papers for everything I state?\nE.g “Organic food has been a growing interest as people have become more concerned about their diet and what they chose to consume.”\nDo I need to search an article to support that or can I leave it as is since it’s something I’ve recently seen with friends, family and on social media platforms (how organic food is the “right food” to consume).\n\nAnswer\nI think it’s commonly knowledge based on lived experience that organic foods have become more widely consumed. So no need to ref that. But the claims that people make about why organic foods are ‘better’ often do not have factual support. So, if you state that it’s better for whatever reason, that needs factual support. If no support is available, your conclusion would have to be that the claim is dogma, i.e., untested, unsubstantiated, wishful thinking, etc.\nScientific studies need to be done in order to prove some hypothesis. Without it the claim remains unsubstantiated despite how many people buy into the claim. Simply because 10 million people think it is good does not actually provide any evidence that the claim is fact.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-pigments",
    "href": "pages/BDC223_FAQ.html#question-about-pigments",
    "title": "FAQ",
    "section": "Question About Pigments",
    "text": "Question About Pigments\nGood day sir, I have a question about accessory pigments. I know they help pass light onto chlorophyll-a for photosynthesis right? And different chlorophylls, especially chlorophyll-a bind to proteins in different ways. Is that in order to absorb more more that the chrolophyll pigment itself wouldn’t be able to absorb?\n\nAnswer\n“different chlorophylls, especially chlorophyll-a bind to proteins in different ways. Is that in order to absorb more more that the chlorophyll pigment itself wouldn’t be able to absorb” — No. If one would have to design something, then that would be the approach. But these molecules were not designed. They evolved. Evolution does not work by something functioning in a specific way in order for some other thing to do what it does. The specific protein binding between the pigments and proteins happened because, by chance, some configuration arose that happened to fill some need, that is, to fill the green gap. It happened by chance, not design.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-eutrophication",
    "href": "pages/BDC223_FAQ.html#question-about-eutrophication",
    "title": "FAQ",
    "section": "Question About Eutrophication",
    "text": "Question About Eutrophication\nGood day Professor, I was wondering if sir could clarify something. Is an anoxic water where there is no dissolve oxygen? And is that caused by oxygen-using bacteria that decompose dead organisms in eutrophic environments?\n\nAnswer\nNot no oxygen. But very little. Usually anoxia is reached at O2 concentrations below 2mg/L. Before that low level it’s called hypoxia.\nYes. It is caused by bacterial respiration. Hypoxia/anoxia causes even more species to die, and further reduces O2 concentrations.\nEutrophic conditions can cause biomass accumulation of photoautotrophs. During night extremely dense biomass of such accumulations don’t photosynthesise but continue to respire. This is when low O2 first starts, and it causes the initial die-off.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-biofouling",
    "href": "pages/BDC223_FAQ.html#question-about-biofouling",
    "title": "FAQ",
    "section": "Question About Biofouling",
    "text": "Question About Biofouling\nHi Professor is biofouling and epiphytes the same or different things?\n\nAnswer\nBiofouling is a process. It’s the process by which epiphytes colonise the surface of a basiphyte. The epiphytes in question might be macroalgae, but it’s most typically microalgae or bacteria (the latter two collectively called biofilm).",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-calculating-the-rate-of-uptake-v",
    "href": "pages/BDC223_FAQ.html#question-about-calculating-the-rate-of-uptake-v",
    "title": "FAQ",
    "section": "Question About Calculating the Rate of Uptake, V",
    "text": "Question About Calculating the Rate of Uptake, V\nGood day Professor, I am hoping sir could assist with my work. For the V column, does that represent the rate that N is being assimilated into the thallas? If so, then the values should be positive right? 😅.\nI’m asking because some students are getting negative values. Regards\nProfessors response.\n“Yes. Why do you think there’s a negative value? What does a negative rate mean—i.e. does it apply to the culture medium (where the concentration decreases) or to the seaweed (where it increases)?”\nI believe the values of the slope are negative because that shows the rate of N that leaves the solution. If I can put it like that\n\nAnswer\nYes! And thus the rate of appearance of N in the seaweed is of the opposite sign, so simply take the absolute value.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-calculating-s-in-the-nutrient-uptake-experiments",
    "href": "pages/BDC223_FAQ.html#question-about-calculating-s-in-the-nutrient-uptake-experiments",
    "title": "FAQ",
    "section": "Question About Calculating S in the Nutrient Uptake Experiments",
    "text": "Question About Calculating S in the Nutrient Uptake Experiments\nSir, do we consider the only culture volume when calculate our S (substrate conc)? and we use μmol N or μg N units or it doesn’t much matter\n\nAnswer\nIt is a function not so much of culture volume, but of the amount (micro moles or micrograms) of nutrients within a volume of seawater.\nVolume per se is not important: the concentration of a substance is the same in 1 ml or in 1 liter. The amount (moles or grams) of a substance is very different in that 1 ml or 1 liter, however. So, volume does not affect concentration, but it affect total amounts available in a volume.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-perturtbation-experiments",
    "href": "pages/BDC223_FAQ.html#question-about-perturtbation-experiments",
    "title": "FAQ",
    "section": "Question About Perturtbation Experiments",
    "text": "Question About Perturtbation Experiments\n(AJ?) Smit professor, with multiple flask experiment you said you can calculate update rate (so I’m assuming it’s a linear graph) and with perturbation you said it’s a depletion curve.\nWith the Michaelis- menten we measure substrate concentration against uptake rate but use perturbation methods (using the gradient for the uptake rate) Since multiple flask also shows uptake rate can you still use this methodology to generate a Michaelis-menten expression? Also wouldn’t it have been easier because then you don’t have the whole x-axis confusion\n\nAnswer\nWhatsApp Ptt 2022-10-12 at 10.25.49 PM.ogg",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-ks-and-alpha",
    "href": "pages/BDC223_FAQ.html#question-about-ks-and-alpha",
    "title": "FAQ",
    "section": "Question About Ks and \\(\\alpha\\)",
    "text": "Question About Ks and \\(\\alpha\\)\nWith regards to Michaelis Menton expression and specifically the Ks and \\(\\alpha\\) does that specifically relate to diffusion ability?\nDoes a high Ks mean diffusion was rate limiting sooner whereas a low Ks meaning kinetics was rate limiting?\nOr am I completely misunderstanding the work?\n\nAnswer\nYes. Ks and \\(\\alpha\\) relate to the externally controlled phases of nutrient uptake, so they are controlled by diffusion (and thus also water motion and nutrient concentration).",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-the-nitrogen-cycle",
    "href": "pages/BDC223_FAQ.html#question-the-nitrogen-cycle",
    "title": "FAQ",
    "section": "Question – The Nitrogen Cycle",
    "text": "Question – The Nitrogen Cycle\nI just wanted some clarification, is it correct to say that the definition of the nitrogen cycle is a biogeochemical process through which nitrogen is converted into many chemical forms circulating in the marine, terrestrial and atmospheric ecosystems?\n\nAnswer\nN cycle. I’d say something like this:\nThe uptake, transformation, release, and transport of N-containing compounds through components of the Earth system, including the biosphere, geosphere, hydrosphere, cryosphere, and atmosphere. The underlying processes involve a series of biologically, physically, and chemically mediated processes which act on different compounds of inorganic and organic N.\nMore simply we can say the N cycle is N biogeochemistry, but less is explained by this short statement than by the longer one.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-whatsapp-ptt-2022-11-13-at-9.43.54-am.ogg",
    "href": "pages/BDC223_FAQ.html#question-whatsapp-ptt-2022-11-13-at-9.43.54-am.ogg",
    "title": "FAQ",
    "section": "Question – WhatsApp Ptt 2022-11-13 at 9.43.54 AM.ogg",
    "text": "Question – WhatsApp Ptt 2022-11-13 at 9.43.54 AM.ogg\n\nAnswer\nVery nice question! It is a pity I already set the exams.\nSo why does Ulva not show saturation at some point?\nWithin the range of N concentrations typically present in the ocean, say up to 20μM N in upwelling systems, uptake should (can) theoretically remain unsaturated, PROVIDED THAT ALL OTHER ENVIRONMENTAL CONDITIONS REMAIN OPTIMAL. There always has to be sufficient amounts of light; the temperature must be optimal, and so on. As soon as the GROWTH RATE slows down because the alga cannot capture enough light to drive photosynthesis (for cellular replication and biomass growth), there will be an upper limit to the amount of N taken up sequestered. So, the high uptake rates promised by a fully rate-unsaturated uptake mechanism supported by diffusion are only possible if the alga can produce enough biomass quickly so it can assimilate N into biomass (protein). Algae can only assimilate N if enough C comes in (through photosynthesis) for sufficient amounts of the C compounds containing N in an organic form.\nTherefore, all suboptimal environmental conditions influencing C uptake will affect N uptake.\nOnly some environmental conditions are optimal for long enough for algae to sustain high N uptake through rapid growth rates. Only because of fast growth rates will N be maintained at low enough concentrations in the vacuoles to prevent feedback inhibition. When feedback inhibition happens, the rate of N uptake is limited. Under most natural conditions, there is likely an upper limit to N uptake. However, we can create optimised conditions in the lab to maximise the algal growth rate; thus, N uptake could remain unsaturated.\nEven passive uptake (N uptake through diffusion) can be rate limited if the amount of N building up inside the cells is so high that it reduces the concentration gradient across the cell from outside (water) to inside (vacuole). In this situation, there would also be a Vmax, determined by the rate at which the alga can bind N into an inorganic form, typically as protein (including some phycobilins).",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-question-about-a-question",
    "href": "pages/BDC223_FAQ.html#question-question-about-a-question",
    "title": "FAQ",
    "section": "Question – Question About a Question",
    "text": "Question – Question About a Question\nSir with this, are we actually supposed to draw the graphs and do the calculations or simply state what needs to be done?\n\n\n\nThe question about which the question is asked.\n\n\n\nAnswer\nIt’s as the question says:\nDesign an experiment that will provide insight into both the optimum ratio of N and P and the optimum concentration of potassium nitrate and orthophosphoric acid to feed the U. lactuca mass culture (i.e. with the aim to maximise biomass production).\nIn your answer, please pay specific attention to the experimental conditions during the acclimation phase (i.e. a period lasting two weeks prior to the experiment), as well as during the experimental phase. Provide a rationale and justification for all your decisions that ultimately inform your experiment.\nCalculations can only done after the experiment is completed, and the question simply asks that you design the experiment.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-the-anthropocene",
    "href": "pages/BDC223_FAQ.html#question-the-anthropocene",
    "title": "FAQ",
    "section": "Question – The Anthropocene",
    "text": "Question – The Anthropocene\nJust a quick question to anyone who might know the answer: Based on Rockstrom’s paper, especially the intro, in which period are we currently? He first mentioned the Holocene, but then states that we have entered the Anthropocene. However, a few sentences later he talks about maintaining the the status and staying in the Holocene.\n\nAnswer\nThe American Geophysical Union does not recognise the Anthropocene as an actual geological epoch yet, so according to them we are still in the Holocene. But many people think that we have already deviated so far away from what was typical for Holocene into something very different, and that we should redefine the current era as the Anthropocene.\nWhat’s your personal view Prof?\nAnthropocene means ‘the age of humans’. So, humans have become so abundant that the signal of our activities have made an imprint on global biogeochemical systems such that in millennia from now when people no longer exist, ‘we’ (whatever replaces us or visits Earth) will be able to pick up signs of people’s existence in various geological strata on Earth.\nI think it makes sense to call where we are presently the Anthropocene, and I think Johan Rockström makes the same argument.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question---conclusions-drawn-from-the-keeling-curve",
    "href": "pages/BDC223_FAQ.html#question---conclusions-drawn-from-the-keeling-curve",
    "title": "FAQ",
    "section": "Question - Conclusions Drawn from the Keeling Curve",
    "text": "Question - Conclusions Drawn from the Keeling Curve\nCan we also use Keelings conclusion to justify that we are in anthropocene because I think it goes hand in with what John [Johan Rockström] is saying?\n\nAnswer\nRalph Keeling’s work is part of the justification. Much more has happened since, especially in the last decade. I don’t think a justification to use Anthropocene yet existed in the 1960s, but there’s plenty going on now to cause one to make that argument.\nSee The Keeling Curve for nice views into what constitutes the Keeling curve over various timescales.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-about-the-history-of-climate-change",
    "href": "pages/BDC223_FAQ.html#question-about-the-history-of-climate-change",
    "title": "FAQ",
    "section": "Question – About the History of Climate Change",
    "text": "Question – About the History of Climate Change\nGood day Prof for the key historical events with regards of climate change do we have to know the years or would the persons name and what they discovered be enough for an answer?\n\nAnswer\nI guess I’m not so much interested in exact dates, but do knowing which part of which century things happened is important. And the correct order of events. The fact is, we know about climate change far longer than people give credit to.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/BDC223_FAQ.html#question-question-about-a-previous-exam-question",
    "href": "pages/BDC223_FAQ.html#question-question-about-a-previous-exam-question",
    "title": "FAQ",
    "section": "Question – Question About a Previous Exam Question",
    "text": "Question – Question About a Previous Exam Question\nSir, I’ve been struggling to contextualize the Guideline you gave us on Material and Methods.\nI saw a question on a previous question and I struggled to answer it for 25 marks.\n\n\n\nThe offending question.\n\n\n\nAnswer\nI gave you the answer on Friday [the one about N uptake, as seen above]. Something like that. Just adapt it for photosynthesis. You want to measure O2 production/consumption or CO2 production/consumption in stead of nutrients.\nJust pick your favourite plant or algal species. The experiment must be appropriate for plants or algae, of course. The difference is that plants live in air and algae in an aqueous medium, so the experiment must be set up appropriately.\nIn air we use an IRGA (infrared gas analyser) and in water we can use an O2 meter. Or we can use a C14-labelled source of CO2 and use scintillation counting to measure the appearance of a radioactive C for in the pool where CO2 accumulates.\nOtherwise, not too different from the N uptake answer, except we probably won’t use the perturbation method.\nAnd you probably want to measure net photosynthesis, so make sure you measure respiration too.",
    "crumbs": [
      "Home",
      "BDC223 Ecophysiology",
      "FAQ"
    ]
  },
  {
    "objectID": "pages/technology_infusion.html",
    "href": "pages/technology_infusion.html",
    "title": "Technology infusion and reproducible research",
    "section": "",
    "text": "Coding skills supported by the intertwined technologies of R, RStudio IDE, and Quarto play a key role in my views on shaping modern-day learning and scientific processes. They equip students with the skills to become better collaborative learners and scientists. These technologies offer an extensive range of tools and libraries best known for data analysis, statistics, and visualisation. Coding skills and data analytical skills equip students to develop a deep understanding of complex data sets and derive meaningful insights from them, expanding their analytical thinking and problem-solving skills.\nRecently, Quarto has become tightly integrated into the R ‘ecosystem.’ The website states that Quarto is “an open-source scientific and technical publishing system.” At its heart, it is a dynamic document format based on R and Markdown. It enables students to create interactive, reproducible, well-documented reports, presentations, and websites that combine code, results, and narrative in a single document. The Tangled Bank was entirely developed within Quarto! This approach not only enhances students’ communication skills by encouraging clear and concise explanations of their findings but also promotes transparency and reproducibility in research. By integrating code and results seamlessly, Quarto reduces errors, simplifies the updating process, and ensures that results remain consistent with the underlying data and methods. Quarto is the de facto mode of reporting and communication that students must adopt in BCB744 and BCB743. I am exploring the feasibility of introducing it into BDC334, as feedback indicates that students are keen to develop their coding skills earlier in their undergraduate degrees.\nThe collaborative potential of R and Quarto further empowers students to work effectively in interdisciplinary teams. Students can easily share their code, data, and findings using version control systems, such as Git (as implemented in GitHub), alongside R and Quarto. This fosters a collaborative learning environment where students can collectively learn from each other’s expertise, troubleshoot problems, and develop innovative solutions. Moreover, creating and sharing well-documented Quarto reports improves communication among team members, ensuring everyone is on the same page and facilitating smoother project execution.\nIntegrating these collaborative, open, transparent coding technologies into the teaching, learning, and scientific processes cultivates essential skills in students, such as critical thinking, problem-solving, communication, and collaboration. By leveraging these technologies, students become better equipped to tackle the challenges of today’s data-driven research landscape, ultimately contributing to advancing science and developing innovative solutions to pressing global issues. These skills are also highly sought after in the workplace outside of science and academia and will significantly improve the employability of our graduates regardless of their future career paths.\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{j._smit2023,\n  author = {J. Smit, Albertus},\n  title = {Technology Infusion and Reproducible Research},\n  date = {2023-04-24},\n  url = {http://tangledbank.netlify.app/pages/technology_infusion.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A (2023) Technology infusion and reproducible research. http://tangledbank.netlify.app/pages/technology_infusion.html."
  },
  {
    "objectID": "pages/graduate_attributes.html",
    "href": "pages/graduate_attributes.html",
    "title": "Graduate attributes",
    "section": "",
    "text": "Key graduate attributes I emphasise in my BDC334, BCB744, and BCB743 syllabi are:\nBCB334, BCB744, and BCB743:\n\nAdvanced subject knowledge Deep understanding of the subject matter, its principles, and current research trends.\nCritical thinking Ability to evaluate scientific literature, identify gaps in knowledge, and propose novel research questions.\nCommunication skills Effective presentation of scientific concepts and research findings, both in written and oral formats, to diverse audiences.\nEthical awareness Understanding and adhering to ethical guidelines and principles in research, including responsible conduct of research, data management, and intellectual property rights.\n\nBCB744 and BCB743 additionally develop:\n\nProblem-solving Capacity to develop innovative solutions for complex scientific challenges.\nResearch skills Proficiency in experimental design, data collection, analysis, interpretation, and reporting of scientific findings.\nCollaboration Teamwork and interdisciplinary cooperation in research projects, fostering a productive scientific environment.\nAdaptability Flexibility and openness to new ideas, methods, and technologies, enabling continuous growth and development in the ever-evolving scientific landscape.\nProject management Planning, organising, and executing scientific projects while managing resources and time effectively.\nProfessional development Commitment to lifelong learning, networking, and career advancement through participation in conferences, workshops, and professional organisations.\n\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{j._smit2023,\n  author = {J. Smit, Albertus},\n  title = {Graduate Attributes},\n  date = {2023-04-24},\n  url = {http://tangledbank.netlify.app/pages/graduate_attributes.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A (2023) Graduate attributes. http://tangledbank.netlify.app/pages/graduate_attributes.html."
  },
  {
    "objectID": "pages/ABNJ.html",
    "href": "pages/ABNJ.html",
    "title": "Areas Beyond National Jurisdiction",
    "section": "",
    "text": "Areas Beyond National Jurisdiction (ABNJ) refer to the parts of the world’s oceans that fall outside of any country’s Exclusive Economic Zone (EEZ). These areas make up about 64% of the surface of the ocean, and include both the High Seas (the water column beyond the EEZ) and the Area (the seabed and subsoil beyond the limits of national jurisdiction).\nUnlike waters within national jurisdictions, where a country has the exclusive right to exploit resources and is responsible for managing and protecting the marine environment, ABNJ are governed by a complex framework of international laws and agreements.\nThe primary legal framework is the United Nations Convention on the Law of the Sea (UNCLOS), which came into force in 1994. UNCLOS sets out the legal framework for the conservation and sustainable use of oceans and their resources. It establishes the rights and obligations of states in relation to the use of the oceans, and provides mechanisms for dispute resolution.\nIn terms of ABNJ, UNCLOS recognises the concept of “the common heritage of mankind,” which asserts that the resources of the deep seabed beyond national jurisdiction are the common heritage of all humanity and should be managed for the benefit of all. However, the UNCLOS does not provide a comprehensive regime for the conservation and sustainable use of marine biodiversity in ABNJ, which is a gap that current negotiations at the UN are trying to fill.\nIn addition to UNCLOS, there are a number of other international agreements that pertain to ABNJ. These include the Convention on Biological Diversity (CBD), which has developed a set of criteria for identifying ecologically or biologically significant marine areas (EBSAs) in need of protection, including in ABNJ. There’s also the International Maritime Organization (IMO), which has the authority to designate Particularly Sensitive Sea Areas (PSSAs) in need of special protection, including in ABNJ.\nThe governance of ABNJ is a complex and evolving issue, with ongoing discussions at the international level about how to improve the management and conservation of these vast and largely unregulated areas of the ocean. This includes debates over issues such as the establishment of marine protected areas in ABNJ, the regulation of emerging industries like deep-sea mining, and how to share the benefits of marine genetic resources.\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{j._smit2023,\n  author = {J. Smit, Albertus},\n  title = {Areas {Beyond} {National} {Jurisdiction}},\n  date = {2023-05-16},\n  url = {http://tangledbank.netlify.app/pages/ABNJ.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A (2023) Areas Beyond National Jurisdiction. http://tangledbank.netlify.app/pages/ABNJ.html."
  },
  {
    "objectID": "pages/reproducible_research.html",
    "href": "pages/reproducible_research.html",
    "title": "Reproducible research and the information economy",
    "section": "",
    "text": "The information economy refers to the modern-day and continually evolving economic system where information, knowledge, and data are the primary drivers of productivity, growth, and innovation. In this economy, the creation, distribution, and consumption of information are more valuable than in traditional industries. The information economy relies on technological advancements, particularly in information and communication technologies (ICTs), to enable efficient processing, storage, and data sharing. Tech companies, digital service providers, and knowledge-intensive industries are typically seen as key players in the information economy. As biologists, however, we often overlook how our information pipelines and knowledge-sharing approaches might benefit from the principles that are now deeply ingrained in just about every aspect of our daily lives."
  },
  {
    "objectID": "pages/reproducible_research.html#eresearch-and-the-information-economy",
    "href": "pages/reproducible_research.html#eresearch-and-the-information-economy",
    "title": "Reproducible research and the information economy",
    "section": "",
    "text": "The information economy refers to the modern-day and continually evolving economic system where information, knowledge, and data are the primary drivers of productivity, growth, and innovation. In this economy, the creation, distribution, and consumption of information are more valuable than in traditional industries. The information economy relies on technological advancements, particularly in information and communication technologies (ICTs), to enable efficient processing, storage, and data sharing. Tech companies, digital service providers, and knowledge-intensive industries are typically seen as key players in the information economy. As biologists, however, we often overlook how our information pipelines and knowledge-sharing approaches might benefit from the principles that are now deeply ingrained in just about every aspect of our daily lives."
  },
  {
    "objectID": "pages/reproducible_research.html#embracing-technological-advancements-a-pathway-to-enhanced-research-and-collaboration",
    "href": "pages/reproducible_research.html#embracing-technological-advancements-a-pathway-to-enhanced-research-and-collaboration",
    "title": "Reproducible research and the information economy",
    "section": "Embracing Technological Advancements: A Pathway to Enhanced Research and Collaboration",
    "text": "Embracing Technological Advancements: A Pathway to Enhanced Research and Collaboration\nOver the years, I have enthusiastically adopted various technological advancements, recognising their potential to elevate my research impact both locally and globally and to keep pace with the evolving global landscape. However, I have observed that not all scientists share my enthusiasm for technology, leading to a sense of alienation among some colleagues who prefer traditional research methods where buckets and spades still rule.\nIt appears that, for some individuals, particularly in fields such as biology or ecology, there is a belief that focusing solely on their discipline-specific subject matter is sufficient and that insights from Computer Science Departments hold little relevance. This narrow perspective, in my view, is limiting and stifles creativity.\nBy embracing technology, we can not only broaden our horizons but also enhance our research capabilities and expand collaboration. We must remain open-minded, explore the potential of interdisciplinary learning, and leverage technology to maximise the possibilities in our respective fields."
  },
  {
    "objectID": "pages/reproducible_research.html#the-interconnected-nature-of-science-and-technology-an-ongoing-journey",
    "href": "pages/reproducible_research.html#the-interconnected-nature-of-science-and-technology-an-ongoing-journey",
    "title": "Reproducible research and the information economy",
    "section": "The Interconnected Nature of Science and Technology: An Ongoing Journey",
    "text": "The Interconnected Nature of Science and Technology: An Ongoing Journey\nAs the practice of science has undergone dramatic changes in recent years, driven in part by Moore’s Law, we are now tackling global issues across vast timescales. This transformation is largely attributed to the availability of vast amounts of data, which has necessitated the development of efficient algorithms to establish connections, access subsets, and distil complex information using supervised and unsupervised data-analytical techniques.\nConcurrently, this data explosion has spurred the advancement of hardware capable of handling the computational, memory, and data transfer demands of big data. While it is debatable whether hardware development has facilitated the collection of increasing amounts of data or vice versa, the ultimate takeaway remains the same: technological progress is relentless, and the practice of science must adapt swiftly to keep up. By acknowledging this interconnected nature of science and technology, we can work with agility, ensuring we remain at the forefront of scientific discovery and innovation."
  },
  {
    "objectID": "pages/reproducible_research.html#navigating-modern-science-interdisciplinary-collaboration-transparency-and-data-sharing",
    "href": "pages/reproducible_research.html#navigating-modern-science-interdisciplinary-collaboration-transparency-and-data-sharing",
    "title": "Reproducible research and the information economy",
    "section": "Navigating Modern Science: Interdisciplinary Collaboration, Transparency, and Data Sharing",
    "text": "Navigating Modern Science: Interdisciplinary Collaboration, Transparency, and Data Sharing\nContemporary science is characterised by the convergence of diverse skill sets to address complex problems through interdisciplinary and transdisciplinary research. This approach, however, presents challenges in team dynamics, data sharing, and code management. Additionally, there is an increasing demand for transparency in research methodologies, as exemplified by the International Panel for Climate Change, and the emergence of reproducible research.\nCompliance with data and information-sharing policies, such as the FAIR principles, global standards, national legislative acts, and discipline-specific norms, has become essential. Recognising the value of metadata alongside primary datasets is now the norm. While software offers solutions to these challenges, only a fraction of us, primarily the tech-savvy, possess the willingness to keep pace and fully embrace the opportunities.\nTo advance modern science, it is imperative that we adapt and cultivate the skills necessary to navigate interdisciplinary collaboration, ensure transparency, and adhere to evolving data-sharing standards."
  },
  {
    "objectID": "pages/reproducible_research.html#embracing-modern-technologies-across-disciplines-for-a-future-ready-workforce",
    "href": "pages/reproducible_research.html#embracing-modern-technologies-across-disciplines-for-a-future-ready-workforce",
    "title": "Reproducible research and the information economy",
    "section": "Embracing Modern Technologies Across Disciplines for a Future-Ready Workforce",
    "text": "Embracing Modern Technologies Across Disciplines for a Future-Ready Workforce\nModern technologies are indispensable for those of us working with extensive datasets, whether in climate change, computational linguistics, or small-scale studies. My disregard for traditional disciplinary boundaries has enabled me to stay informed about relevant advancements, driving my determination to develop this website, The Tangled Bank. My motivation is further fuelled by the concern that many colleagues are failing to maintain the necessary interest for continuous advancement.\nA reluctance to embrace change not only affects ourselves but also has a domino effect on postgraduate and undergraduate students. By not nurturing the required skills in students, academics hinder their ability to become well-rounded graduates equipped for the modern workplace and to develop transferable skills that transcend disciplinary boundaries. It is crucial to remember that many graduates, particularly those with Bachelor and Honours degrees, will pursue careers unrelated to their original fields of study. Yet, they want to have a degree that provides skills anywhere their future selves might find themselves.\nTo foster a future-ready workforce, it is necessary that we embrace technological advancements and cultivate adaptable, interdisciplinary skill sets in the next generation of graduates."
  },
  {
    "objectID": "pages/reproducible_research.html#exemplifying-the-importance-of-reproducible-research-and-eresearch-frameworks",
    "href": "pages/reproducible_research.html#exemplifying-the-importance-of-reproducible-research-and-eresearch-frameworks",
    "title": "Reproducible research and the information economy",
    "section": "Exemplifying the Importance of Reproducible Research and eResearch Frameworks",
    "text": "Exemplifying the Importance of Reproducible Research and eResearch Frameworks\nConsider the challenge of conducting reproducible research, which, when addressed, can resolve many eResearch framework issues. A typical PhD student spends a few months writing their thesis, which often serves as the sole evidence of degree completion. However, the majority of the learning and methodological expertise developed during the rest of the degree remains undocumented and eventually forgotten. This wealth of knowledge is rarely shared, leading to repeated dead-ends in knowledge transfer as new candidates embark on similar journeys.\nMost research neglects the full data lifecycle, focusing mainly on the initial steps. The failure to share behind-the-scenes solutions results in non-reproducible research, making the scientific process opaque and fostering public mistrust. This opacity hinders collaboration among supervisors and co-investigators, increases error-proneness, and scales poorly as datasets and complexities grow. Additionally, the research process becomes less efficient due to inadequate documentation of data selection, filtering justifications, metadata tracking, data versions, and processing changes.\nAddressing these challenges is essential to promote reproducible research, enhance collaboration, and build public trust in science, ultimately contributing to a more efficient and transparent research process. This makes the research process extremely wasteful in as far as preserving the full complexity of what a typical student learns."
  },
  {
    "objectID": "pages/reproducible_research.html#promoting-reproducible-research-through-lab-notebooks-and-proper-workflow-management",
    "href": "pages/reproducible_research.html#promoting-reproducible-research-through-lab-notebooks-and-proper-workflow-management",
    "title": "Reproducible research and the information economy",
    "section": "Promoting Reproducible Research through Lab Notebooks and Proper Workflow Management",
    "text": "Promoting Reproducible Research through Lab Notebooks and Proper Workflow Management\nMany solutions exist to address research reproducibility, but I find lab notebooks using RStudio’s markdown (for R users) or Jupyter Lab/Notebooks (for Python users) particularly effective. Version tracking can be achieved using git, such as in GitHub. These notebooks integrate code with text, allowing automatic updates of tables and figures with new data. My students are proficient in this approach, ensuring their work is reproducible.\nI advocate for the widespread adoption of lab notebooks at universities, making them a prerequisite for thesis submission in applicable disciplines. The thesis can be a reproducible document written in markdown, and typeset to various formats such as PDF, HTML, MS Word, or eBook. This method also incorporates proper bibliography management.\nThis reproducible workflow complies with funding instruments requiring data and code sharing, reproducibility, and open publication per FAIR principles. It is already prevalent in disciplines like ecology. While this example focuses on paper or thesis writing, technology impacts research practice across disciplines, commerce, arts, and law. A comprehensive overview is beyond our scope, but the examples provided illustrate the broader possibilities."
  },
  {
    "objectID": "pages/How_to_learn.html",
    "href": "pages/How_to_learn.html",
    "title": "How to learn",
    "section": "",
    "text": "This question was asked by 3rd years, but it is relevant here too.\nI just need some advice from sir. I’m starting to study today and I just wanted to know what do you think is the best way to study for sir’s exam. I’m asking because I studied really hard for the midterm tests but I still got low marks lol. So I just wanted to know if there is maybe a different approach that I can take.\n\nI was trying to memorise things for the midterm tests but I know sir said we must focus on understanding but when I focus on understanding then the work does not stick in my head😂.\n\nSo far I’ve just read through the articles but is there any advice that sir can give me please?\n\n\nThank you for your email. Hmmm, a tricky question to ask of someone who wrote their last exam in 1993!\nI am the opposite to you. I cannot memorise things but I am able to understand things really well. Fortunately, in the process of figuring things out, the relevant bits of information/knowledge relating to the thing I am trying to understand also sticks in my mind, which is (for me) a useful side effect of figuring things out. For me, it is pointless having things to memorise unless I can apply it to something that needs figuring out. So, everything I know, I know because it is useful to me.\nHow does understanding come about? For me, I try and understand stuff because the challenge of a tricky problem is thrilling, so understanding is facilitated because the process aligns with what makes me ‘tick.’ Okay, so this does not answer how understanding comes about; it simply talks to who I am.\nI can tell you is how you can test your understanding. Explain the thing you are trying to understand to a friend or family member. If your explanation of the topic brings about an understanding in the other person, then you yourself understand it. At least this process will tell you where your own understanding starts to fail. As Richard Feynman said, “If you cannot explain something to a 7-year old, you don’t understand it yourself.” Or something like that.\nFor someone who finds it easier to memorise stuff and more challenging to understand… I don’t know what that feels like as I have no personal experience or frame of reference that allows me to place myself into your shoes. But here is the theory:\n\nKnow what it is you already know, and build upon that (see point 2). At some point later on you will also know what you don’t know…\n\n“Reports that say that something hasn’t happened are always interesting to me, because as we know, there are known knowns; there are things we know we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns—the ones we don’t know we don’t know. And if one looks throughout the history of our country and other free countries, it is the latter category that tends to be the difficult ones.”\n-- Donald Rumsfeld, February 12, 2002\n\nYou already know things. Structure new and existing knowledge around the major concepts and principles of the module (broadly, the new concepts covered each week). This means that work done in your first and second years of your study, in ALL the modules you completed, remains relevant, and has to be used together with the new knowledge obtained in the new module, and structured around the broad concept and principle (there are many concepts and principles in a module).\nYou need to develop and understand the language used to communicate the topic. At the very basic level, this requires that you understand in intricate detail the individual words (ALL of them) that form the foundational language of your study discipline (biology and science more broadly). Only once you understand the definitions of individual words will you be able to develop more complex understanding. I think this is the primary reason why students fail to develop a deep understanding of a topic that requires explanation in multiple paragraphs (long answers and essays).\nAnother step involves knowing how all the steps that inform the thinking process are interrelated. This requires that you consider some of the following things: What does the assignment or task require me to do (i.e. unpack the problem)? What are the steps I need to follow to get there? What do I already know about it? What do I not understand and where do I get stuck? Why don’t I know it already? What about the problem causes me to get stuck? Where do I get the knowledge about what I don’t understand, and how can I use this to become unstuck? Okay, so now I am figuring things out… What does the problem remind me about? Have I encountered something similar before, and if so, how can I use that to develop further my current thinking about the problem? This whole process is called metacognition, which is thinking about thinking and learning. This kind of thing has to happen each time you see something new, come across a new piece of information, listen to someone speak, etc. It can be applied in your day to day life to the extent that it become implicit in how you approach life. Eventually, you’ll find yourself saying more often, “I am wondering…” Then you will arrive at critical thinking, which is what makes science special.\nHow well you are able to integrate the metacognitive skills in your life and learning depends unfortunately on your inherent abilities and prior experiences. It is easier for some than it is for others.\nA critical characteristic of good learning is that it informs your sense of self — this means that once you value learning as one of the most important attributes which inform who you are as a person, the easier it will become to learn, the less effort it will take, and the more learning itself will become the motivator (as opposed to search for motivation externally, like some reward, for having to learn).\nThe activities in your life, your friends, family and interests will also shape how much you learn, and what you learn.\nYou need to mix with people who values learning to the same extent that you do, so this social reinforcement further ‘snowballs’ into life-long learning and understanding.\n\nStep no. 4. is probably to most helpful."
  },
  {
    "objectID": "pages/How_to_learn.html#how-does-one-study-to-understand",
    "href": "pages/How_to_learn.html#how-does-one-study-to-understand",
    "title": "How to learn",
    "section": "",
    "text": "This question was asked by 3rd years, but it is relevant here too.\nI just need some advice from sir. I’m starting to study today and I just wanted to know what do you think is the best way to study for sir’s exam. I’m asking because I studied really hard for the midterm tests but I still got low marks lol. So I just wanted to know if there is maybe a different approach that I can take.\n\nI was trying to memorise things for the midterm tests but I know sir said we must focus on understanding but when I focus on understanding then the work does not stick in my head😂.\n\nSo far I’ve just read through the articles but is there any advice that sir can give me please?\n\n\nThank you for your email. Hmmm, a tricky question to ask of someone who wrote their last exam in 1993!\nI am the opposite to you. I cannot memorise things but I am able to understand things really well. Fortunately, in the process of figuring things out, the relevant bits of information/knowledge relating to the thing I am trying to understand also sticks in my mind, which is (for me) a useful side effect of figuring things out. For me, it is pointless having things to memorise unless I can apply it to something that needs figuring out. So, everything I know, I know because it is useful to me.\nHow does understanding come about? For me, I try and understand stuff because the challenge of a tricky problem is thrilling, so understanding is facilitated because the process aligns with what makes me ‘tick.’ Okay, so this does not answer how understanding comes about; it simply talks to who I am.\nI can tell you is how you can test your understanding. Explain the thing you are trying to understand to a friend or family member. If your explanation of the topic brings about an understanding in the other person, then you yourself understand it. At least this process will tell you where your own understanding starts to fail. As Richard Feynman said, “If you cannot explain something to a 7-year old, you don’t understand it yourself.” Or something like that.\nFor someone who finds it easier to memorise stuff and more challenging to understand… I don’t know what that feels like as I have no personal experience or frame of reference that allows me to place myself into your shoes. But here is the theory:\n\nKnow what it is you already know, and build upon that (see point 2). At some point later on you will also know what you don’t know…\n\n“Reports that say that something hasn’t happened are always interesting to me, because as we know, there are known knowns; there are things we know we know. We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns—the ones we don’t know we don’t know. And if one looks throughout the history of our country and other free countries, it is the latter category that tends to be the difficult ones.”\n-- Donald Rumsfeld, February 12, 2002\n\nYou already know things. Structure new and existing knowledge around the major concepts and principles of the module (broadly, the new concepts covered each week). This means that work done in your first and second years of your study, in ALL the modules you completed, remains relevant, and has to be used together with the new knowledge obtained in the new module, and structured around the broad concept and principle (there are many concepts and principles in a module).\nYou need to develop and understand the language used to communicate the topic. At the very basic level, this requires that you understand in intricate detail the individual words (ALL of them) that form the foundational language of your study discipline (biology and science more broadly). Only once you understand the definitions of individual words will you be able to develop more complex understanding. I think this is the primary reason why students fail to develop a deep understanding of a topic that requires explanation in multiple paragraphs (long answers and essays).\nAnother step involves knowing how all the steps that inform the thinking process are interrelated. This requires that you consider some of the following things: What does the assignment or task require me to do (i.e. unpack the problem)? What are the steps I need to follow to get there? What do I already know about it? What do I not understand and where do I get stuck? Why don’t I know it already? What about the problem causes me to get stuck? Where do I get the knowledge about what I don’t understand, and how can I use this to become unstuck? Okay, so now I am figuring things out… What does the problem remind me about? Have I encountered something similar before, and if so, how can I use that to develop further my current thinking about the problem? This whole process is called metacognition, which is thinking about thinking and learning. This kind of thing has to happen each time you see something new, come across a new piece of information, listen to someone speak, etc. It can be applied in your day to day life to the extent that it become implicit in how you approach life. Eventually, you’ll find yourself saying more often, “I am wondering…” Then you will arrive at critical thinking, which is what makes science special.\nHow well you are able to integrate the metacognitive skills in your life and learning depends unfortunately on your inherent abilities and prior experiences. It is easier for some than it is for others.\nA critical characteristic of good learning is that it informs your sense of self — this means that once you value learning as one of the most important attributes which inform who you are as a person, the easier it will become to learn, the less effort it will take, and the more learning itself will become the motivator (as opposed to search for motivation externally, like some reward, for having to learn).\nThe activities in your life, your friends, family and interests will also shape how much you learn, and what you learn.\nYou need to mix with people who values learning to the same extent that you do, so this social reinforcement further ‘snowballs’ into life-long learning and understanding.\n\nStep no. 4. is probably to most helpful."
  },
  {
    "objectID": "pages/assessment_theory.html",
    "href": "pages/assessment_theory.html",
    "title": "Assessment theory",
    "section": "",
    "text": "BCB744 and BCB743 thoroughly implement formative and summative assessments.\nFormative assessment is ‘academic speak’ for continuous assessment. It provides you with ongoing feedback that you can use to track your performance and to self-evaluate your understanding. Formative assessment also lets me see your development as we progress from simple to more complex topics. Since this is done daily with feedback the next day, I can identify and address any hurdles before they become problematic and impede progression. Formative assessments may include quizzes, discussions, observations, group activities, or small focussed tasks. They are designed to gauge your progress and identify areas of strength or weakness. Continual monitoring and feedback allow me to modify and adapt my instructional strategies in real-time to meet your needs as students better. I intend for this dynamic approach to assessment to create a more engaging, interactive, collaborative, and supportive learning environment, ultimately promoting deeper understanding and long-term retention of knowledge.\nSummative assessment is the second and final mode of assessment. It is designed to evaluate your understanding and mastery of subjects in their full complexity at the end of the learning period. These assessments are in the form of standardised tests or exams and may also comprise comprehensive integrative projects. This mode of assessment provides us (you, me, the BCB Department, and the UWC) with a view of attaining the desired teaching outcomes as stated in the modules’ preambles. It is also a yardstick we use to rate and rank the effectiveness of my instructional methods and the extent to which you have acquired knowledge.\nFormative and summative assessments must inform decisions regarding student advancement and future instructional needs. They contribute to the continuous improvement of the integrated educational program, the curriculum, and teaching practices.\nHere’s a summary of the two modes of assessment:\n\nPurpose Formative assessment mainly monitors your progress and provides feedback during the learning process. In contrast, summative assessment evaluates your performance and understanding at the end of a learning period.\nTiming Formative assessments frequently occur throughout a course or unit, allowing continuous feedback and adjustment. Summative assessments typically occur at the end of a course, unit, or semester.\nFeedback Formative assessment offers real-time, actionable feedback that enables you and me to adjust learning and teaching strategies. Summative assessment provides a more comprehensive evaluation of your knowledge and skills, which can inform future instruction or determine advancement.\nImpact on grades Formative assessments are often weighted less regarding how much tasks contribute to the final mark; it focuses instead on learning and improvement. Summative assessments typically count more towards the final grade and allow us to establish whether you have attained specific learning objectives.\n\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{j._smit2023,\n  author = {J. Smit, Albertus},\n  title = {Assessment Theory},\n  date = {2023-04-24},\n  url = {http://tangledbank.netlify.app/pages/assessment_theory.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nJ. Smit A (2023) Assessment theory. http://tangledbank.netlify.app/pages/assessment_theory.html."
  }
]