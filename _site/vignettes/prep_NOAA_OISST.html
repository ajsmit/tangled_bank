<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="Robert W Schlegel and AJ Smit">
<meta name="dcterms.date" content="2023-02-15">
<meta name="description" content="This vignette demonstrates how to download NOAA OISST data and prepare them for the detection of marine heatwaves.">
<title>Downloading and Preparing NOAA OISST Data: ERDDAP – The Tangled Bank</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../images/favicon.ico" rel="icon">
<script src="../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-1757f00c6ae8c581f53f5d4246fc66b3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-SCYH68M489"></script><script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-SCYH68M489', { 'anonymize_ip': true});
</script><script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"headline",
  "consent_type":"express",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script><style>html{ scroll-behavior: smooth; }</style>
<script async="" src="https://hypothes.is/embed.js"></script><script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script><link rel="stylesheet" href="../LesCodex2.css">
<meta property="og:title" content="Downloading and Preparing NOAA OISST Data: ERDDAP – The Tangled Bank">
<meta property="og:description" content="This vignette demonstrates how to download NOAA OISST data and prepare them for the detection of marine heatwaves.">
<meta property="og:site_name" content="The Tangled Bank">
</head>
<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">The Tangled Bank</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
<li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-vignettes" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Vignettes</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-vignettes">
<li>
    <a class="dropdown-item" href="../vignettes/netCDF_dates.html">
 <span class="dropdown-text">Dates From netCDF Files: Two Approaches</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/prep_NOAA_OISST.html">
 <span class="dropdown-text">Downloading and Prep: ERDDAP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/chl_ERDDAP.html">
 <span class="dropdown-text">Retrieving Chlorophyll-a Data from ERDDAP Servers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/alt_method.html">
 <span class="dropdown-text">Downloading and Prep: Python + CDO</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/gridded_data.html">
 <span class="dropdown-text">Detecting Events in Gridded Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/regridding.html">
 <span class="dropdown-text">Regridding gridded data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/MHW_MCS_horizonplots.html">
 <span class="dropdown-text">Displaying MHWs and MCSs as Horizon Plots</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/heatwaveR_issues.html">
 <span class="dropdown-text">heatwaveR Issues</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/chl_sightings.html">
 <span class="dropdown-text">Plotting the Whale Sightings and Chlorophyll-<em>a</em> Concentrations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/chl_localisation.html">
 <span class="dropdown-text">Spatial Localisation, Subsetting, and Aggregation of the Chlorophyll-<em>a</em> Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/elem_ts_methods.html">
 <span class="dropdown-text">Wavelet Analysis of Diatom Time Series</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/buffer_data_extract.html">
 <span class="dropdown-text">Extracting gridded data within a buffer</span></a>
  </li>  
    </ul>
</li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-high-performace-computing" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">High-Performace Computing</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-high-performace-computing">
<li>
    <a class="dropdown-item" href="../vignettes/README_Lengau.html">
 <span class="dropdown-text">Using Lengau</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/PBSPro_users.html">
 <span class="dropdown-text">PBSPro user and job management</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../vignettes/README_tmux.html">
 <span class="dropdown-text">Using tmux</span></a>
  </li>  
    </ul>
</li>
  <li class="nav-item">
    <a class="nav-link" href="../blog.html"> 
<span class="menu-text">Tangled Bank Blog</span></a>
  </li>  
</ul>
<ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-blogroll" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Blogroll</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-blogroll">
<li>
    <a class="dropdown-item" href="https://www.r-bloggers.com">
 <span class="dropdown-text">R-bloggers</span></a>
  </li>  
    </ul>
</li>
  <li class="nav-item compact">
    <a class="nav-link" href="../blog.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">
<li>
    <a class="dropdown-item" href="https://github.com/ajsmit/tangled_bank">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://bugs.com">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
</li>
</ul>
</div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
      </div> <!-- /container-fluid -->
    </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li>
<a href="#downloading-subsetted-data" id="toc-downloading-subsetted-data" class="nav-link" data-scroll-target="#downloading-subsetted-data">Downloading subsetted data</a>
  <ul class="collapse">
<li><a href="#file-information" id="toc-file-information" class="nav-link" data-scroll-target="#file-information">File information</a></li>
  <li><a href="#download-function" id="toc-download-function" class="nav-link" data-scroll-target="#download-function">Download function</a></li>
  <li><a href="#date-range" id="toc-date-range" class="nav-link" data-scroll-target="#date-range">Date range</a></li>
  <li><a href="#downloadprep-data" id="toc-downloadprep-data" class="nav-link" data-scroll-target="#downloadprep-data">Download/prep data</a></li>
  <li><a href="#visualise-data" id="toc-visualise-data" class="nav-link" data-scroll-target="#visualise-data">Visualise data</a></li>
  <li><a href="#save-data" id="toc-save-data" class="nav-link" data-scroll-target="#save-data">Save data</a></li>
  </ul>
</li>
  <li>
<a href="#downloading-global-data" id="toc-downloading-global-data" class="nav-link" data-scroll-target="#downloading-global-data">Downloading global data</a>
  <ul class="collapse">
<li><a href="#file-information-1" id="toc-file-information-1" class="nav-link" data-scroll-target="#file-information-1">File information</a></li>
  <li><a href="#download-data" id="toc-download-data" class="nav-link" data-scroll-target="#download-data">Download data</a></li>
  <li><a href="#load-data" id="toc-load-data" class="nav-link" data-scroll-target="#load-data">Load data</a></li>
  <li><a href="#visualise-data-1" id="toc-visualise-data-1" class="nav-link" data-scroll-target="#visualise-data-1">Visualise data</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/ajsmit/tangled_bank/edit/main/vignettes/prep_NOAA_OISST.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/ajsmit/tangled_bank/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content column-page-left" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Downloading and Preparing NOAA OISST Data: ERDDAP</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">Marine heatwaves and cold spells as per Hobday et al (2016) and Schlegel et al (2017)</p>
</div>

<div>
  <div class="description">
    This vignette demonstrates how to download NOAA OISST data and prepare them for the detection of marine heatwaves.
  </div>
</div>


<div class="quarto-title-meta column-page-left">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Robert W Schlegel and AJ Smit </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 15, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header><p>This material also appears as a <a href="https://robwschlegel.github.io/heatwaveR/articles/OISST_preparation.html">heatwaveR vignette</a>.</p>
<section id="overview" class="level2"><h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>In this vignette we will see how to retrieve and prepare Reynolds optimally interpolated sea surface temperature (OISST) data for calculating marine heatwaves (MHWs). The OISST product is a global 1/4 degree gridded dataset of Advanced Very High Resolution Radiometer (AVHRR) derived SSTs at a daily resolution, starting on 1 September 1981. The source of the data is currently the <a href="https://www.ncei.noaa.gov/products/optimum-interpolation-sst">NOAA NCDC</a>.</p>
<p>Each daily global file, when not compressed, is around 8.3 MB, so they add up to a large amount of data when a time series of the recommended 30 year minimum duration for the detection of MHWs is downloaded. If one were to download all of the data currently available it would exceed 100 GB of total disk space. It is therefore best practice to download only a subset of the data that matches one’s study area. Thanks to the <a href="https://docs.ropensci.org/rerddap/"><strong><code>rerddap</code></strong> package</a> this is incredibly easy to do in <code>R</code>.</p>
<p>Should one want to download the full global dataset, each daily global file is available in netCDF format and is roughly 1.6 MB. This means that one full year of global data will be roughly 600 MB, and the full dataset roughly 25 GB. This is however when the data are very compressed. If we were to attempt to load the entire uncompressed dataset into our memory at once it would take more than 200 GB of RAM. That is well beyond the scope of any current laptop so in the second half of this vignette we will see how to download the full OISST dataset before then seeing how we can load only a subset of the data into the R environment for use with further analyses.</p>
<p>This vignette may appear very long and complex but it has been written in an attempt to keep the process of downloading and working with satellite data as straight-forward and easy to follow as possible. Before we begin with all of the code etc. please note that for almost all applications it is only necessary to use the first method outlined below. For most users the second download method in this vignette can simply be skipped.</p>
</section><section id="setup" class="level2"><h2 class="anchored" data-anchor-id="setup">Setup</h2>
<p>For this vignette we will be accessing the NOAA OISST dataset on this <a href="https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW.html">ERDDAP server</a> for the subsetted data, while the global data are indexed <a href="https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr/">here</a>. One may download the data on both servers manually by using the ERDDAP UI or clicking on each indexed file individually. But programming languages like R are designed to prevent us from needing to experience that sort of anguish. Below we will load the libraries we need in order to have R download all of the data that we may need. If any of the lines of code in the following chunk do not run it means that we will need to first install that package. Uncomment the line of code that would install the problem package and run it before trying to load the library again.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="co"># The packages we will need</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co"># install.packages("dplyr")</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co"># install.packages("lubridate")</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co"># install.packages("ggplot2")</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co"># install.packages("tidync")</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co"># install.packages("doParallel")</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co"># install.packages("rerddap")</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co"># install.packages("plyr") # Note that this library should never be loaded, only installed</span></span>
<span id="cb1-9"><a href="#cb1-9"></a></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="co"># The packages we will use</span></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="fu">library</span>(dplyr) <span class="co"># A staple for modern data management in R</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="fu">library</span>(lubridate) <span class="co"># Useful functions for dealing with dates</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="fu">library</span>(ggplot2) <span class="co"># The preferred library for data visualisation</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="fu">library</span>(tidync) <span class="co"># For easily dealing with NetCDF data</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="fu">library</span>(rerddap) <span class="co"># For easily downloading subsets of data</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="fu">library</span>(doParallel) <span class="co"># For parallel processing</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With our packages loaded we may now begin downloading and preparing our data for further use. Please use the table of contents on the right side of the screen to jump between the different download methods as desired. We will break each different method down into smaller steps in order to keep this process as clear as possible. Before we begin I need to stress that this is a very direct and unrestricted method for accessing these data and I urge responsibility in only downloading as much data as are necessary. Please do not download the entire dataset unless you have a specific need for it.</p>
</section><section id="downloading-subsetted-data" class="level2"><h2 class="anchored" data-anchor-id="downloading-subsetted-data">Downloading subsetted data</h2>
<section id="file-information" class="level3"><h3 class="anchored" data-anchor-id="file-information">File information</h3>
<p>Before we begin downloading the subsetted data for our study area we need to make sure that they are currently available on an ERDDAP server. The location of the NOAA OISST data has changed in the past so it should not be assumed that the current location will exist in perpetuity. Finding the server on which these data are located can be a cup game at times.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># The information for the NOAA OISST data</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>rerddap<span class="sc">::</span><span class="fu">info</span>(<span class="at">datasetid =</span> <span class="st">"ncdcOisst21Agg_LonPM180"</span>, <span class="at">url =</span> <span class="st">"https://coastwatch.pfeg.noaa.gov/erddap/"</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co"># Note that there is also a version with lon values from 0 yo 360</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>rerddap<span class="sc">::</span><span class="fu">info</span>(<span class="at">datasetid =</span> <span class="st">"ncdcOisst21Agg"</span>, <span class="at">url =</span> <span class="st">"https://coastwatch.pfeg.noaa.gov/erddap/"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With our target dataset identified we may now begin the download with the <code>griddap()</code> function. While putting this vignette together however I noticed one little hiccup in the work flow. It seems that the ERDDAP server does not like it when one tries to access more than nine consecutive years of data in one request, regardless of the spatial extent being requested. So before we download our data we are going to make a wrapper function that helps us control the range of times we want to download. This will reduce the amount of redundant coding we would otherwise need to do.</p>
</section><section id="download-function" class="level3"><h3 class="anchored" data-anchor-id="download-function">Download function</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># This function downloads and prepares data based on user provided start and end dates</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>OISST_sub_dl <span class="ot">&lt;-</span> <span class="cf">function</span>(time_df){</span>
<span id="cb3-3"><a href="#cb3-3"></a>  OISST_dat <span class="ot">&lt;-</span> <span class="fu">griddap</span>(<span class="at">x =</span> <span class="st">"ncdcOisst21Agg_LonPM180"</span>, </span>
<span id="cb3-4"><a href="#cb3-4"></a>                       <span class="at">url =</span> <span class="st">"https://coastwatch.pfeg.noaa.gov/erddap/"</span>, </span>
<span id="cb3-5"><a href="#cb3-5"></a>                       <span class="at">time =</span> <span class="fu">c</span>(time_df<span class="sc">$</span>start, time_df<span class="sc">$</span>end), </span>
<span id="cb3-6"><a href="#cb3-6"></a>                       <span class="at">zlev =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb3-7"><a href="#cb3-7"></a>                       <span class="at">latitude =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">40</span>, <span class="sc">-</span><span class="dv">35</span>),</span>
<span id="cb3-8"><a href="#cb3-8"></a>                       <span class="at">longitude =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">21</span>),</span>
<span id="cb3-9"><a href="#cb3-9"></a>                       <span class="at">fields =</span> <span class="st">"sst"</span>)<span class="sc">$</span>data <span class="sc">%&gt;%</span> </span>
<span id="cb3-10"><a href="#cb3-10"></a>    <span class="fu">mutate</span>(<span class="at">time =</span> <span class="fu">as.Date</span>(stringr<span class="sc">::</span><span class="fu">str_remove</span>(time, <span class="st">"T00:00:00Z"</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb3-11"><a href="#cb3-11"></a>    dplyr<span class="sc">::</span><span class="fu">rename</span>(<span class="at">t =</span> time, <span class="at">temp =</span> sst) <span class="sc">%&gt;%</span> </span>
<span id="cb3-12"><a href="#cb3-12"></a>    <span class="fu">select</span>(lon, lat, t, temp) <span class="sc">%&gt;%</span> </span>
<span id="cb3-13"><a href="#cb3-13"></a>    <span class="fu">na.omit</span>()</span>
<span id="cb3-14"><a href="#cb3-14"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the wrapper function above we see that we have chosen to download only the ‘sst’ data out of the several variables (‘fields’) available to us. We also see that we have chosen the spatial extent of latitude -40 to -35 and longitude 15 to 21. This a small window over some of the Agulhas Retroflection to the south west of South Africa. A larger area is not being chosen here simply due to the speed constraints of downloading the data and detecting the events therein. One may simply change the longitude and latitude values above as necessary to match the desired study area. The function will also be re-labelling the ‘time’ column as ‘t’, and the ‘sst’ column as ‘temp’. We do this so that they match the default column names that are expected for calculating MHWs and we won’t have to do any extra work later on.</p>
<p>One must note here that depending on the RAM available on one’s machine, it may not be possible to handle all of the data downloaded at once if they are very large (e.g.&nbsp;&gt; 5 GB). The discussion on the limitations of the R language due to its dependence on virtual memory is beyond the scope of this vignette, but if one limits one’s downloads to no more than several square pixels at a time that should be fine. Were one to try to download the whole Indian Ocean, for example, that may cause issues if being run on a laptop or computer of a similar power.</p>
</section><section id="date-range" class="level3"><h3 class="anchored" data-anchor-id="date-range">Date range</h3>
<p>With our wrapper function written we would now need to run it several times in order to grab all of the OISST data from <code>1982-01-01</code> to <code>2019-12-31</code>. Even though each year of data for the extent used in this vignette is only ~360 KB, the server does not like it when more than 9 years of consecutive data are requested. The server will also end a users connection after ~17 individual files have been requested. Because we can’t download all of the data in one request, and we can’t download the data one year at a time, we will need to make requests for multiple batches of data. To accomplish this we will create a dataframe of start and end dates that will allow us to automate the entire download while meeting the aforementioned criteria.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Date download range by start and end dates per year</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>dl_years <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">date_index =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,</span>
<span id="cb4-3"><a href="#cb4-3"></a>                       <span class="at">start =</span> <span class="fu">as.Date</span>(<span class="fu">c</span>(<span class="st">"1982-01-01"</span>, <span class="st">"1990-01-01"</span>, </span>
<span id="cb4-4"><a href="#cb4-4"></a>                                         <span class="st">"1998-01-01"</span>, <span class="st">"2006-01-01"</span>, <span class="st">"2014-01-01"</span>)),</span>
<span id="cb4-5"><a href="#cb4-5"></a>                       <span class="at">end =</span> <span class="fu">as.Date</span>(<span class="fu">c</span>(<span class="st">"1989-12-31"</span>, <span class="st">"1997-12-31"</span>, </span>
<span id="cb4-6"><a href="#cb4-6"></a>                                       <span class="st">"2005-12-31"</span>, <span class="st">"2013-12-31"</span>, <span class="st">"2019-12-31"</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="downloadprep-data" class="level3"><h3 class="anchored" data-anchor-id="downloadprep-data">Download/prep data</h3>
<p>One could also use the <strong><code>plyr</code></strong> suite of functions to automate the process of downloading and processing multiple files, but I’ve chosen here to stick with the <strong><code>tidyverse</code></strong> native approach. If the below chunk of code fails or times out, simply re-run it until all of the data have been downloaded.</p>
<p>It is worth pointing out here that these data are downloaded as cached files on the users computer by using the <strong><code>hoardr</code></strong> package. This means that if one runs the same command again, it will not re-download the data because it first looks in the folder where it has automatically cached the data for you and sees that it may simply draw the data from there. No need to change anything or write a second script for loading data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># Download all of the data with one nested request</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co"># The time this takes will vary greatly based on connection speed</span></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="fu">system.time</span>(</span>
<span id="cb5-4"><a href="#cb5-4"></a>  OISST_data <span class="ot">&lt;-</span> dl_years <span class="sc">%&gt;%</span> </span>
<span id="cb5-5"><a href="#cb5-5"></a>    <span class="fu">group_by</span>(date_index) <span class="sc">%&gt;%</span> </span>
<span id="cb5-6"><a href="#cb5-6"></a>    <span class="fu">group_modify</span>(<span class="sc">~</span><span class="fu">OISST_sub_dl</span>(.x)) <span class="sc">%&gt;%</span> </span>
<span id="cb5-7"><a href="#cb5-7"></a>    <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb5-8"><a href="#cb5-8"></a>    <span class="fu">select</span>(lon, lat, t, temp)</span>
<span id="cb5-9"><a href="#cb5-9"></a>) <span class="co"># 38 seconds, ~8 seconds per batch</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If the above code chunk is giving errors it is likely due to one’s Internet connection timing out. There are also rare instances where the NOAA server is not responding due to an issue on their end. Any connection based issues may be resolved by simply waiting for a few minutes, or by ensuring a stable connection.</p>
</section><section id="visualise-data" class="level3"><h3 class="anchored" data-anchor-id="visualise-data">Visualise data</h3>
<p>Before we save our data for later use it is good practice to visualise them.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>OISST_data <span class="sc">%&gt;%</span> </span>
<span id="cb6-2"><a href="#cb6-2"></a>  <span class="fu">filter</span>(t <span class="sc">==</span> <span class="st">"2019-12-01"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb6-3"><a href="#cb6-3"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> lon, <span class="at">y =</span> lat)) <span class="sc">+</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>  <span class="fu">geom_tile</span>(<span class="fu">aes</span>(<span class="at">fill =</span> temp)) <span class="sc">+</span></span>
<span id="cb6-5"><a href="#cb6-5"></a>  <span class="co"># borders() + # Activate this line to see the global map</span></span>
<span id="cb6-6"><a href="#cb6-6"></a>  <span class="fu">scale_fill_viridis_c</span>() <span class="sc">+</span></span>
<span id="cb6-7"><a href="#cb6-7"></a>  <span class="fu">coord_quickmap</span>(<span class="at">expand =</span> F) <span class="sc">+</span></span>
<span id="cb6-8"><a href="#cb6-8"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="cn">NULL</span>, <span class="at">fill =</span> <span class="st">"SST (°C)"</span>) <span class="sc">+</span></span>
<span id="cb6-9"><a href="#cb6-9"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="save-data" class="level3"><h3 class="anchored" data-anchor-id="save-data">Save data</h3>
<p>With the data downloaded and prepared for further use (and a test visual run), all that’s left to do is save them.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Save the data as an .Rds file because it has a much better compression rate than .RData</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="fu">saveRDS</span>(OISST_data, <span class="at">file =</span> <span class="st">"~/Desktop/OISST_vignette.Rds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note above that I have chosen to save the file to my desktop. This is not normally where one (hopefully!) would save such a file. Rather one would be saving these data into the project folder out of which one is working. In the next vignette we will see how to <a href="https://robwschlegel.github.io/heatwaveR/articles/gridded_event_detection.html">detect MHWs in gridded data</a> using the data downloaded here.</p>
</section></section><section id="downloading-global-data" class="level2"><h2 class="anchored" data-anchor-id="downloading-global-data">Downloading global data</h2>
<p>The method for downloading and preparing NOAA OISST data outlined in the first half of this vignette should be considered best practice for all applications except those that specifically need to look at the entire globe. If one needs to download the global dataset then it is preferable to go straight to the source. Note that one may still download the full global dataset using the methods above by setting the lon/lat extent to be the full width and height of the globe. The method outlined below will download over 13,000 individual files. This makes dealing with individual files very easy, but agglomerating them into one file can be very time consuming.</p>
<section id="file-information-1" class="level3"><h3 class="anchored" data-anchor-id="file-information-1">File information</h3>
<p>The first step in downloading the full global dataset is to tell you computer where they are. There is an automated way to do this but it requires a couple of additional packages and we aim to keep this vignette as simple and direct as possible. For our purposes today we will manually create the URLs of the files we want to download.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># First we tell R where the data are on the interwebs</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>OISST_base_url <span class="ot">&lt;-</span> <span class="st">"https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr/"</span></span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="co"># Note that one may go to this URL in any web browser to manually inspect the files</span></span>
<span id="cb8-4"><a href="#cb8-4"></a></span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="co"># Now we create a data.frame that contains all of the dates we want to download</span></span>
<span id="cb8-6"><a href="#cb8-6"></a>  <span class="co"># NB: In order to change the dates download changes the dates in the following line</span></span>
<span id="cb8-7"><a href="#cb8-7"></a>OISST_dates <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">t =</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">"2019-12-01"</span>), <span class="fu">as.Date</span>(<span class="st">"2019-12-31"</span>), <span class="at">by =</span> <span class="st">"day"</span>))</span>
<span id="cb8-8"><a href="#cb8-8"></a></span>
<span id="cb8-9"><a href="#cb8-9"></a><span class="co"># To finish up this step we add some text to those dates so they match the OISST file names</span></span>
<span id="cb8-10"><a href="#cb8-10"></a>OISST_files <span class="ot">&lt;-</span> OISST_dates <span class="sc">%&gt;%</span> </span>
<span id="cb8-11"><a href="#cb8-11"></a>  <span class="fu">mutate</span>(<span class="at">t_day =</span> <span class="fu">gsub</span>(<span class="st">"-"</span>, <span class="st">""</span>, t),</span>
<span id="cb8-12"><a href="#cb8-12"></a>         <span class="at">t_month =</span> <span class="fu">substr</span>(t_day, <span class="dv">1</span>, <span class="dv">6</span>),</span>
<span id="cb8-13"><a href="#cb8-13"></a>         <span class="at">t_year =</span> <span class="fu">year</span>(t),</span>
<span id="cb8-14"><a href="#cb8-14"></a>         <span class="at">file_name =</span> <span class="fu">paste0</span>(OISST_base_url, t_month, <span class="st">"/"</span>, <span class="st">"oisst-avhrr-v02r01."</span>, t_day ,<span class="st">".nc"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="download-data" class="level3"><h3 class="anchored" data-anchor-id="download-data">Download data</h3>
<p>Now that we have a dataframe that contains all of the URLs for the files we want to download we’ll create a function that will crawl through those URLs and download the files for us.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># This function will go about downloading each day of data as a NetCDF file</span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="co"># Note that this will download files into a 'data/OISST' folder in the root directory</span></span>
<span id="cb9-3"><a href="#cb9-3"></a>  <span class="co"># If this folder does not exist it will create it</span></span>
<span id="cb9-4"><a href="#cb9-4"></a>  <span class="co"># If it does not automatically create the folder it will need to be done manually</span></span>
<span id="cb9-5"><a href="#cb9-5"></a>  <span class="co"># The folder that is created must be a new folder with no other files in it</span></span>
<span id="cb9-6"><a href="#cb9-6"></a>  <span class="co"># A possible bug with netCDF files in R is they won't load correctly from </span></span>
<span id="cb9-7"><a href="#cb9-7"></a>  <span class="co"># existing folders with other file types in them</span></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="co"># This function will also check if the file has been previously downloaded</span></span>
<span id="cb9-9"><a href="#cb9-9"></a>  <span class="co"># If it has it will not download it again</span></span>
<span id="cb9-10"><a href="#cb9-10"></a>OISST_url_daily_dl <span class="ot">&lt;-</span> <span class="cf">function</span>(target_URL){</span>
<span id="cb9-11"><a href="#cb9-11"></a>  <span class="fu">dir.create</span>(<span class="st">"~/data/OISST"</span>, <span class="at">showWarnings =</span> F)</span>
<span id="cb9-12"><a href="#cb9-12"></a>  file_name <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"~/data/OISST/"</span>,<span class="fu">sapply</span>(<span class="fu">strsplit</span>(target_URL, <span class="at">split =</span> <span class="st">"/"</span>), <span class="st">"[["</span>, <span class="dv">10</span>))</span>
<span id="cb9-13"><a href="#cb9-13"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">file.exists</span>(file_name)) <span class="fu">download.file</span>(<span class="at">url =</span> target_URL, <span class="at">method =</span> <span class="st">"libcurl"</span>, <span class="at">destfile =</span> file_name)</span>
<span id="cb9-14"><a href="#cb9-14"></a>}</span>
<span id="cb9-15"><a href="#cb9-15"></a></span>
<span id="cb9-16"><a href="#cb9-16"></a><span class="co"># The more cores used, the faster the data may be downloaded</span></span>
<span id="cb9-17"><a href="#cb9-17"></a>  <span class="co"># It is best practice to not use all of the cores on one's machine</span></span>
<span id="cb9-18"><a href="#cb9-18"></a>  <span class="co"># The laptop on which I am running this code has 8 cores, so I use 7 here</span></span>
<span id="cb9-19"><a href="#cb9-19"></a>doParallel<span class="sc">::</span><span class="fu">registerDoParallel</span>(<span class="at">cores =</span> <span class="dv">7</span>)</span>
<span id="cb9-20"><a href="#cb9-20"></a></span>
<span id="cb9-21"><a href="#cb9-21"></a><span class="co"># And with that we are clear for take off</span></span>
<span id="cb9-22"><a href="#cb9-22"></a><span class="fu">system.time</span>(plyr<span class="sc">::</span><span class="fu">l_ply</span>(OISST_files<span class="sc">$</span>file_name, <span class="at">.fun =</span> OISST_url_daily_dl, <span class="at">.parallel =</span> T)) <span class="co"># ~15 seconds</span></span>
<span id="cb9-23"><a href="#cb9-23"></a></span>
<span id="cb9-24"><a href="#cb9-24"></a><span class="co"># In roughly 15 seconds a user may have a full month of global data downloaded</span></span>
<span id="cb9-25"><a href="#cb9-25"></a><span class="co"># This scales well into years and decades, and is much faster with more cores</span></span>
<span id="cb9-26"><a href="#cb9-26"></a><span class="co"># Download speeds will also depend on the speed of the users internet connection</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section><section id="load-data" class="level3"><h3 class="anchored" data-anchor-id="load-data">Load data</h3>
<p>The following code chunk contains the function we may use to load and prepare our OISST data for further use in R.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># This function will load and subset daily data into one data.frame</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="co"># Note that the subsetting by lon/lat is done before the data are loaded</span></span>
<span id="cb10-3"><a href="#cb10-3"></a>  <span class="co"># This means it will use much less RAM and is viable for use on most laptops</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>  <span class="co"># Assuming one's study area is not too large</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>OISST_load <span class="ot">&lt;-</span> <span class="cf">function</span>(file_name, lon1, lon2, lat1, lat2){</span>
<span id="cb10-6"><a href="#cb10-6"></a>      OISST_dat <span class="ot">&lt;-</span> <span class="fu">tidync</span>(file_name) <span class="sc">%&gt;%</span></span>
<span id="cb10-7"><a href="#cb10-7"></a>        <span class="fu">hyper_filter</span>(<span class="at">lon =</span> <span class="fu">between</span>(lon, lon1, lon2),</span>
<span id="cb10-8"><a href="#cb10-8"></a>                     <span class="at">lat =</span> <span class="fu">between</span>(lat, lat1, lat2)) <span class="sc">%&gt;%</span> </span>
<span id="cb10-9"><a href="#cb10-9"></a>        <span class="fu">hyper_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb10-10"><a href="#cb10-10"></a>        <span class="fu">select</span>(lon, lat, time, sst) <span class="sc">%&gt;%</span> </span>
<span id="cb10-11"><a href="#cb10-11"></a>        dplyr<span class="sc">::</span><span class="fu">rename</span>(<span class="at">t =</span> time, <span class="at">temp =</span> sst) <span class="sc">%&gt;%</span> </span>
<span id="cb10-12"><a href="#cb10-12"></a>        <span class="fu">mutate</span>(<span class="at">t =</span> <span class="fu">as.Date</span>(t, <span class="at">origin =</span> <span class="st">"1978-01-01"</span>))</span>
<span id="cb10-13"><a href="#cb10-13"></a>      <span class="fu">return</span>(OISST_dat)</span>
<span id="cb10-14"><a href="#cb10-14"></a>}</span>
<span id="cb10-15"><a href="#cb10-15"></a></span>
<span id="cb10-16"><a href="#cb10-16"></a><span class="co"># Locate the files that will be loaded</span></span>
<span id="cb10-17"><a href="#cb10-17"></a>OISST_files <span class="ot">&lt;-</span> <span class="fu">dir</span>(<span class="st">"~/data/OISST"</span>, <span class="at">full.names =</span> T)</span>
<span id="cb10-18"><a href="#cb10-18"></a></span>
<span id="cb10-19"><a href="#cb10-19"></a><span class="co"># Load the data in parallel</span></span>
<span id="cb10-20"><a href="#cb10-20"></a>OISST_dat <span class="ot">&lt;-</span> plyr<span class="sc">::</span><span class="fu">ldply</span>(<span class="at">.data =</span> OISST_files, <span class="at">.fun =</span> OISST_load, <span class="at">.parallel =</span> T,</span>
<span id="cb10-21"><a href="#cb10-21"></a>                         <span class="at">lon1 =</span> <span class="dv">270</span>, <span class="at">lon2 =</span> <span class="dv">320</span>, <span class="at">lat1 =</span> <span class="dv">30</span>, <span class="at">lat2 =</span> <span class="dv">50</span>)</span>
<span id="cb10-22"><a href="#cb10-22"></a></span>
<span id="cb10-23"><a href="#cb10-23"></a><span class="co"># It should only take a few seconds to load one month of data depending on the size of the lon/lat extent chosen</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the code chunk above I have chosen the spatial extent of longitude 270 to 320 and latitude 30 to 50. This a window over the Atlantic Coast of North America. One may simply change the lon/lat values above as necessary to match the desired study area. The function also re-labels the ‘time’ column as ‘t’, and the ‘sst’ column as ‘temp’. We do this now so that they match the default column names that are expected for calculating MHWs so we won’t have to do any extra work later on.</p>
<p>Again, please note that trying to load too much data at once may be too much for the RAM on one’s machine. If running the above code causes one’s machine to hang, try loading a smaller subset of data. Or make friends with someone with a server sized machine.</p>
</section><section id="visualise-data-1" class="level3"><h3 class="anchored" data-anchor-id="visualise-data-1">Visualise data</h3>
<p>It is always good to visualise data early and often in any workflow. The code pipeline below shows how we can visualise a day of data from those we’ve loaded.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>OISST_dat <span class="sc">%&gt;%</span> </span>
<span id="cb11-2"><a href="#cb11-2"></a>  <span class="fu">filter</span>(t <span class="sc">==</span> <span class="st">"2019-12-01"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb11-3"><a href="#cb11-3"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> lon, <span class="at">y =</span> lat)) <span class="sc">+</span></span>
<span id="cb11-4"><a href="#cb11-4"></a>  <span class="fu">geom_tile</span>(<span class="fu">aes</span>(<span class="at">fill =</span> temp)) <span class="sc">+</span></span>
<span id="cb11-5"><a href="#cb11-5"></a>  <span class="fu">scale_fill_viridis_c</span>() <span class="sc">+</span></span>
<span id="cb11-6"><a href="#cb11-6"></a>  <span class="fu">coord_quickmap</span>(<span class="at">expand =</span> F) <span class="sc">+</span></span>
<span id="cb11-7"><a href="#cb11-7"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="cn">NULL</span>, <span class="at">fill =</span> <span class="st">"SST (°C)"</span>) <span class="sc">+</span></span>
<span id="cb11-8"><a href="#cb11-8"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the next vignette we will see how to <a href="https://robwschlegel.github.io/heatwaveR/articles/gridded_event_detection.html">detect MHWs in gridded data</a>.</p>


<!-- -->

</section></section><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></div></div></section><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{smit,_a._j.,
  author = {Smit, A. J., and W Schlegel and AJ Smit, Robert},
  title = {Downloading and {Preparing} {NOAA} {OISST} {Data:} {ERDDAP}},
  date = {},
  url = {http://tangledbank.netlify.app/vignettes/prep_NOAA_OISST.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-smit,_a._j." class="csl-entry quarto-appendix-citeas" role="listitem">
Smit, A. J., W Schlegel and AJ Smit R Downloading and Preparing NOAA
OISST Data: ERDDAP. <a href="http://tangledbank.netlify.app/vignettes/prep_NOAA_OISST.html">http://tangledbank.netlify.app/vignettes/prep_NOAA_OISST.html.
</a>
</div></div></section></div></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("http:\/\/tangledbank\.netlify\.app");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb12" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb12-1"><a href="#cb12-1"></a><span class="co">---</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="an">author:</span><span class="co"> "Robert W Schlegel and AJ Smit"</span></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="an">date:</span><span class="co"> "`r Sys.Date()`"</span></span>
<span id="cb12-4"><a href="#cb12-4"></a><span class="an">title:</span><span class="co"> "Downloading and Preparing NOAA OISST Data: ERDDAP"</span></span>
<span id="cb12-5"><a href="#cb12-5"></a><span class="an">subtitle:</span><span class="co"> "Marine heatwaves and cold spells as per Hobday et al (2016) and Schlegel et al (2017)"</span></span>
<span id="cb12-6"><a href="#cb12-6"></a><span class="an">description:</span><span class="co"> "This vignette demonstrates how to download NOAA OISST data and prepare them for the detection of marine heatwaves."</span></span>
<span id="cb12-7"><a href="#cb12-7"></a><span class="an">bibliography:</span><span class="co"> ../references.bib</span></span>
<span id="cb12-8"><a href="#cb12-8"></a><span class="an">csl:</span><span class="co"> ../marine-biology.csl</span></span>
<span id="cb12-9"><a href="#cb12-9"></a><span class="an">format:</span></span>
<span id="cb12-10"><a href="#cb12-10"></a><span class="co">  html:</span></span>
<span id="cb12-11"><a href="#cb12-11"></a><span class="co">    code-fold: false</span></span>
<span id="cb12-12"><a href="#cb12-12"></a><span class="co">    toc-title: "On this page"</span></span>
<span id="cb12-13"><a href="#cb12-13"></a><span class="co">    standalone: true</span></span>
<span id="cb12-14"><a href="#cb12-14"></a><span class="co">    toc-location: right</span></span>
<span id="cb12-15"><a href="#cb12-15"></a><span class="co">    page-layout: full</span></span>
<span id="cb12-16"><a href="#cb12-16"></a><span class="co">---</span></span>
<span id="cb12-17"><a href="#cb12-17"></a></span>
<span id="cb12-18"><a href="#cb12-18"></a>This material also appears as a <span class="co">[</span><span class="ot">heatwaveR vignette</span><span class="co">](https://robwschlegel.github.io/heatwaveR/articles/OISST_preparation.html)</span>.</span>
<span id="cb12-19"><a href="#cb12-19"></a></span>
<span id="cb12-20"><a href="#cb12-20"></a><span class="fu">## Overview</span></span>
<span id="cb12-21"><a href="#cb12-21"></a></span>
<span id="cb12-22"><a href="#cb12-22"></a>In this vignette we will see how to retrieve and prepare Reynolds optimally interpolated sea surface temperature (OISST) data for calculating marine heatwaves (MHWs). The OISST product is a global 1/4 degree gridded dataset of Advanced Very High Resolution Radiometer (AVHRR) derived SSTs at a daily resolution, starting on 1 September 1981. The source of the data is currently the <span class="co">[</span><span class="ot">NOAA NCDC</span><span class="co">](https://www.ncei.noaa.gov/products/optimum-interpolation-sst)</span>. </span>
<span id="cb12-23"><a href="#cb12-23"></a></span>
<span id="cb12-24"><a href="#cb12-24"></a>Each daily global file, when not compressed, is around 8.3 MB, so they add up to a large amount of data when a time series of the recommended 30 year minimum duration for the detection of MHWs is downloaded. If one were to download all of the data currently available it would exceed 100 GB of total disk space. It is therefore best practice to download only a subset of the data that matches one's study area. Thanks to the <span class="co">[</span><span class="ot">__`rerddap`__ package</span><span class="co">](https://docs.ropensci.org/rerddap/)</span> this is incredibly easy to do in <span class="in">`R`</span>.</span>
<span id="cb12-25"><a href="#cb12-25"></a></span>
<span id="cb12-26"><a href="#cb12-26"></a>Should one want to download the full global dataset, each daily global file is available in netCDF format and is roughly 1.6 MB. This means that one full year of global data will be roughly 600 MB, and the full dataset roughly 25 GB. This is however when the data are very compressed. If we were to attempt to load the entire uncompressed dataset into our memory at once it would take more than 200 GB of RAM. That is well beyond the scope of any current laptop so in the second half of this vignette we will see how to download the full OISST dataset before then seeing how we can load only a subset of the data into the R environment for use with further analyses.</span>
<span id="cb12-27"><a href="#cb12-27"></a></span>
<span id="cb12-28"><a href="#cb12-28"></a>This vignette may appear very long and complex but it has been written in an attempt to keep the process of downloading and working with satellite data as straight-forward and easy to follow as possible. Before we begin with all of the code etc. please note that for almost all applications it is only necessary to use the first method outlined below. For most users the second download method in this vignette can simply be skipped.</span>
<span id="cb12-29"><a href="#cb12-29"></a></span>
<span id="cb12-30"><a href="#cb12-30"></a><span class="fu">## Setup</span></span>
<span id="cb12-31"><a href="#cb12-31"></a></span>
<span id="cb12-32"><a href="#cb12-32"></a>For this vignette we will be accessing the NOAA OISST dataset on this <span class="co">[</span><span class="ot">ERDDAP server</span><span class="co">](https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW.html)</span> for the subsetted data, while the global data are indexed <span class="co">[</span><span class="ot">here</span><span class="co">](https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr/)</span>. One may download the data on both servers manually by using the ERDDAP UI or clicking on each indexed file individually. But programming languages like R are designed to prevent us from needing to experience that sort of anguish. Below we will load the libraries we need in order to have R download all of the data that we may need. If any of the lines of code in the following chunk do not run it means that we will need to first install that package. Uncomment the line of code that would install the problem package and run it before trying to load the library again. </span>
<span id="cb12-33"><a href="#cb12-33"></a></span>
<span id="cb12-34"><a href="#cb12-34"></a><span class="in">```{r setup, eval=FALSE}</span></span>
<span id="cb12-35"><a href="#cb12-35"></a><span class="co"># The packages we will need</span></span>
<span id="cb12-36"><a href="#cb12-36"></a><span class="co"># install.packages("dplyr")</span></span>
<span id="cb12-37"><a href="#cb12-37"></a><span class="co"># install.packages("lubridate")</span></span>
<span id="cb12-38"><a href="#cb12-38"></a><span class="co"># install.packages("ggplot2")</span></span>
<span id="cb12-39"><a href="#cb12-39"></a><span class="co"># install.packages("tidync")</span></span>
<span id="cb12-40"><a href="#cb12-40"></a><span class="co"># install.packages("doParallel")</span></span>
<span id="cb12-41"><a href="#cb12-41"></a><span class="co"># install.packages("rerddap")</span></span>
<span id="cb12-42"><a href="#cb12-42"></a><span class="co"># install.packages("plyr") # Note that this library should never be loaded, only installed</span></span>
<span id="cb12-43"><a href="#cb12-43"></a></span>
<span id="cb12-44"><a href="#cb12-44"></a><span class="co"># The packages we will use</span></span>
<span id="cb12-45"><a href="#cb12-45"></a><span class="fu">library</span>(dplyr) <span class="co"># A staple for modern data management in R</span></span>
<span id="cb12-46"><a href="#cb12-46"></a><span class="fu">library</span>(lubridate) <span class="co"># Useful functions for dealing with dates</span></span>
<span id="cb12-47"><a href="#cb12-47"></a><span class="fu">library</span>(ggplot2) <span class="co"># The preferred library for data visualisation</span></span>
<span id="cb12-48"><a href="#cb12-48"></a><span class="fu">library</span>(tidync) <span class="co"># For easily dealing with NetCDF data</span></span>
<span id="cb12-49"><a href="#cb12-49"></a><span class="fu">library</span>(rerddap) <span class="co"># For easily downloading subsets of data</span></span>
<span id="cb12-50"><a href="#cb12-50"></a><span class="fu">library</span>(doParallel) <span class="co"># For parallel processing</span></span>
<span id="cb12-51"><a href="#cb12-51"></a><span class="in">```</span></span>
<span id="cb12-52"><a href="#cb12-52"></a></span>
<span id="cb12-53"><a href="#cb12-53"></a>With our packages loaded we may now begin downloading and preparing our data for further use. Please use the table of contents on the right side of the screen to jump between the different download methods as desired. We will break each different method down into smaller steps in order to keep this process as clear as possible. Before we begin I need to stress that this is a very direct and unrestricted method for accessing these data and I urge responsibility in only downloading as much data as are necessary. Please do not download the entire dataset unless you have a specific need for it.</span>
<span id="cb12-54"><a href="#cb12-54"></a></span>
<span id="cb12-55"><a href="#cb12-55"></a><span class="fu">## Downloading subsetted data</span></span>
<span id="cb12-56"><a href="#cb12-56"></a></span>
<span id="cb12-57"><a href="#cb12-57"></a><span class="fu">### File information</span></span>
<span id="cb12-58"><a href="#cb12-58"></a></span>
<span id="cb12-59"><a href="#cb12-59"></a>Before we begin downloading the subsetted data for our study area we need to make sure that they are currently available on an ERDDAP server. The location of the NOAA OISST data has changed in the past so it should not be assumed that the current location will exist in perpetuity. Finding the server on which these data are located can be a cup game at times.</span>
<span id="cb12-60"><a href="#cb12-60"></a></span>
<span id="cb12-61"><a href="#cb12-61"></a><span class="in">```{r erddap-info, eval=FALSE}</span></span>
<span id="cb12-62"><a href="#cb12-62"></a><span class="co"># The information for the NOAA OISST data</span></span>
<span id="cb12-63"><a href="#cb12-63"></a>rerddap<span class="sc">::</span><span class="fu">info</span>(<span class="at">datasetid =</span> <span class="st">"ncdcOisst21Agg_LonPM180"</span>, <span class="at">url =</span> <span class="st">"https://coastwatch.pfeg.noaa.gov/erddap/"</span>)</span>
<span id="cb12-64"><a href="#cb12-64"></a></span>
<span id="cb12-65"><a href="#cb12-65"></a><span class="co"># Note that there is also a version with lon values from 0 yo 360</span></span>
<span id="cb12-66"><a href="#cb12-66"></a>rerddap<span class="sc">::</span><span class="fu">info</span>(<span class="at">datasetid =</span> <span class="st">"ncdcOisst21Agg"</span>, <span class="at">url =</span> <span class="st">"https://coastwatch.pfeg.noaa.gov/erddap/"</span>)</span>
<span id="cb12-67"><a href="#cb12-67"></a><span class="in">```</span></span>
<span id="cb12-68"><a href="#cb12-68"></a></span>
<span id="cb12-69"><a href="#cb12-69"></a>With our target dataset identified we may now begin the download with the <span class="in">`griddap()`</span> function. While putting this vignette together however I noticed one little hiccup in the work flow. It seems that the ERDDAP server does not like it when one tries to access more than nine consecutive years of data in one request, regardless of the spatial extent being requested. So before we download our data we are going to make a wrapper function that helps us control the range of times we want to download. This will reduce the amount of redundant coding we would otherwise need to do.</span>
<span id="cb12-70"><a href="#cb12-70"></a></span>
<span id="cb12-71"><a href="#cb12-71"></a><span class="fu">### Download function</span></span>
<span id="cb12-72"><a href="#cb12-72"></a></span>
<span id="cb12-73"><a href="#cb12-73"></a><span class="in">```{r download-func, eval=FALSE}</span></span>
<span id="cb12-74"><a href="#cb12-74"></a><span class="co"># This function downloads and prepares data based on user provided start and end dates</span></span>
<span id="cb12-75"><a href="#cb12-75"></a>OISST_sub_dl <span class="ot">&lt;-</span> <span class="cf">function</span>(time_df){</span>
<span id="cb12-76"><a href="#cb12-76"></a>  OISST_dat <span class="ot">&lt;-</span> <span class="fu">griddap</span>(<span class="at">x =</span> <span class="st">"ncdcOisst21Agg_LonPM180"</span>, </span>
<span id="cb12-77"><a href="#cb12-77"></a>                       <span class="at">url =</span> <span class="st">"https://coastwatch.pfeg.noaa.gov/erddap/"</span>, </span>
<span id="cb12-78"><a href="#cb12-78"></a>                       <span class="at">time =</span> <span class="fu">c</span>(time_df<span class="sc">$</span>start, time_df<span class="sc">$</span>end), </span>
<span id="cb12-79"><a href="#cb12-79"></a>                       <span class="at">zlev =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb12-80"><a href="#cb12-80"></a>                       <span class="at">latitude =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">40</span>, <span class="sc">-</span><span class="dv">35</span>),</span>
<span id="cb12-81"><a href="#cb12-81"></a>                       <span class="at">longitude =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">21</span>),</span>
<span id="cb12-82"><a href="#cb12-82"></a>                       <span class="at">fields =</span> <span class="st">"sst"</span>)<span class="sc">$</span>data <span class="sc">%&gt;%</span> </span>
<span id="cb12-83"><a href="#cb12-83"></a>    <span class="fu">mutate</span>(<span class="at">time =</span> <span class="fu">as.Date</span>(stringr<span class="sc">::</span><span class="fu">str_remove</span>(time, <span class="st">"T00:00:00Z"</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb12-84"><a href="#cb12-84"></a>    dplyr<span class="sc">::</span><span class="fu">rename</span>(<span class="at">t =</span> time, <span class="at">temp =</span> sst) <span class="sc">%&gt;%</span> </span>
<span id="cb12-85"><a href="#cb12-85"></a>    <span class="fu">select</span>(lon, lat, t, temp) <span class="sc">%&gt;%</span> </span>
<span id="cb12-86"><a href="#cb12-86"></a>    <span class="fu">na.omit</span>()</span>
<span id="cb12-87"><a href="#cb12-87"></a>}</span>
<span id="cb12-88"><a href="#cb12-88"></a><span class="in">```</span></span>
<span id="cb12-89"><a href="#cb12-89"></a></span>
<span id="cb12-90"><a href="#cb12-90"></a>In the wrapper function above we see that we have chosen to download only the 'sst' data out of the several variables ('fields') available to us. We also see that we have chosen the spatial extent of latitude -40 to -35 and longitude 15 to 21. This a small window over some of the Agulhas Retroflection to the south west of South Africa. A larger area is not being chosen here simply due to the speed constraints of downloading the data and detecting the events therein. One may simply change the longitude and latitude values above as necessary to match the desired study area. The function will also be re-labelling the 'time' column as 't', and the 'sst' column as 'temp'. We do this so that they match the default column names that are expected for calculating MHWs and we won't have to do any extra work later on.</span>
<span id="cb12-91"><a href="#cb12-91"></a></span>
<span id="cb12-92"><a href="#cb12-92"></a>One must note here that depending on the RAM available on one's machine, it may not be possible to handle all of the data downloaded at once if they are very large (e.g. &gt; 5 GB). The discussion on the limitations of the R language due to its dependence on virtual memory is beyond the scope of this vignette, but if one limits one's downloads to no more than several square pixels at a time that should be fine. Were one to try to download the whole Indian Ocean, for example, that may cause issues if being run on a laptop or computer of a similar power.</span>
<span id="cb12-93"><a href="#cb12-93"></a></span>
<span id="cb12-94"><a href="#cb12-94"></a><span class="fu">### Date range</span></span>
<span id="cb12-95"><a href="#cb12-95"></a></span>
<span id="cb12-96"><a href="#cb12-96"></a>With our wrapper function written we would now need to run it several times in order to grab all of the OISST data from <span class="in">`1982-01-01`</span> to <span class="in">`2019-12-31`</span>. Even though each year of data for the extent used in this vignette is only ~360 KB, the server does not like it when more than 9 years of consecutive data are requested. The server will also end a users connection after ~17 individual files have been requested. Because we can't download all of the data in one request, and we can't download the data one year at a time, we will need to make requests for multiple batches of data. To accomplish this we will create a dataframe of start and end dates that will allow us to automate the entire download while meeting the aforementioned criteria.</span>
<span id="cb12-97"><a href="#cb12-97"></a></span>
<span id="cb12-98"><a href="#cb12-98"></a><span class="in">```{r year-index, eval=FALSE}</span></span>
<span id="cb12-99"><a href="#cb12-99"></a><span class="co"># Date download range by start and end dates per year</span></span>
<span id="cb12-100"><a href="#cb12-100"></a>dl_years <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">date_index =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,</span>
<span id="cb12-101"><a href="#cb12-101"></a>                       <span class="at">start =</span> <span class="fu">as.Date</span>(<span class="fu">c</span>(<span class="st">"1982-01-01"</span>, <span class="st">"1990-01-01"</span>, </span>
<span id="cb12-102"><a href="#cb12-102"></a>                                         <span class="st">"1998-01-01"</span>, <span class="st">"2006-01-01"</span>, <span class="st">"2014-01-01"</span>)),</span>
<span id="cb12-103"><a href="#cb12-103"></a>                       <span class="at">end =</span> <span class="fu">as.Date</span>(<span class="fu">c</span>(<span class="st">"1989-12-31"</span>, <span class="st">"1997-12-31"</span>, </span>
<span id="cb12-104"><a href="#cb12-104"></a>                                       <span class="st">"2005-12-31"</span>, <span class="st">"2013-12-31"</span>, <span class="st">"2019-12-31"</span>)))</span>
<span id="cb12-105"><a href="#cb12-105"></a><span class="in">```</span></span>
<span id="cb12-106"><a href="#cb12-106"></a></span>
<span id="cb12-107"><a href="#cb12-107"></a><span class="fu">### Download/prep data</span></span>
<span id="cb12-108"><a href="#cb12-108"></a></span>
<span id="cb12-109"><a href="#cb12-109"></a>One could also use the __`plyr`__ suite of functions to automate the process of downloading and processing multiple files, but I've chosen here to stick with the __`tidyverse`__ native approach. If the below chunk of code fails or times out, simply re-run it until all of the data have been downloaded.</span>
<span id="cb12-110"><a href="#cb12-110"></a></span>
<span id="cb12-111"><a href="#cb12-111"></a>It is worth pointing out here that these data are downloaded as cached files on the users computer by using the __`hoardr`__ package. This means that if one runs the same command again, it will not re-download the data because it first looks in the folder where it has automatically cached the data for you and sees that it may simply draw the data from there. No need to change anything or write a second script for loading data.</span>
<span id="cb12-112"><a href="#cb12-112"></a></span>
<span id="cb12-113"><a href="#cb12-113"></a><span class="in">```{r download-data, eval=FALSE}</span></span>
<span id="cb12-114"><a href="#cb12-114"></a><span class="co"># Download all of the data with one nested request</span></span>
<span id="cb12-115"><a href="#cb12-115"></a><span class="co"># The time this takes will vary greatly based on connection speed</span></span>
<span id="cb12-116"><a href="#cb12-116"></a><span class="fu">system.time</span>(</span>
<span id="cb12-117"><a href="#cb12-117"></a>  OISST_data <span class="ot">&lt;-</span> dl_years <span class="sc">%&gt;%</span> </span>
<span id="cb12-118"><a href="#cb12-118"></a>    <span class="fu">group_by</span>(date_index) <span class="sc">%&gt;%</span> </span>
<span id="cb12-119"><a href="#cb12-119"></a>    <span class="fu">group_modify</span>(<span class="sc">~</span><span class="fu">OISST_sub_dl</span>(.x)) <span class="sc">%&gt;%</span> </span>
<span id="cb12-120"><a href="#cb12-120"></a>    <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb12-121"><a href="#cb12-121"></a>    <span class="fu">select</span>(lon, lat, t, temp)</span>
<span id="cb12-122"><a href="#cb12-122"></a>) <span class="co"># 38 seconds, ~8 seconds per batch</span></span>
<span id="cb12-123"><a href="#cb12-123"></a><span class="in">```</span></span>
<span id="cb12-124"><a href="#cb12-124"></a></span>
<span id="cb12-125"><a href="#cb12-125"></a>If the above code chunk is giving errors it is likely due to one's Internet connection timing out. There are also rare instances where the NOAA server is not responding due to an issue on their end. Any connection based issues may be resolved by simply waiting for a few minutes, or by ensuring a stable connection.</span>
<span id="cb12-126"><a href="#cb12-126"></a></span>
<span id="cb12-127"><a href="#cb12-127"></a><span class="fu">### Visualise data</span></span>
<span id="cb12-128"><a href="#cb12-128"></a></span>
<span id="cb12-129"><a href="#cb12-129"></a>Before we save our data for later use it is good practice to visualise them.</span>
<span id="cb12-130"><a href="#cb12-130"></a></span>
<span id="cb12-131"><a href="#cb12-131"></a><span class="in">```{r SA-visual, eval=FALSE}</span></span>
<span id="cb12-132"><a href="#cb12-132"></a>OISST_data <span class="sc">%&gt;%</span> </span>
<span id="cb12-133"><a href="#cb12-133"></a>  <span class="fu">filter</span>(t <span class="sc">==</span> <span class="st">"2019-12-01"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-134"><a href="#cb12-134"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> lon, <span class="at">y =</span> lat)) <span class="sc">+</span></span>
<span id="cb12-135"><a href="#cb12-135"></a>  <span class="fu">geom_tile</span>(<span class="fu">aes</span>(<span class="at">fill =</span> temp)) <span class="sc">+</span></span>
<span id="cb12-136"><a href="#cb12-136"></a>  <span class="co"># borders() + # Activate this line to see the global map</span></span>
<span id="cb12-137"><a href="#cb12-137"></a>  <span class="fu">scale_fill_viridis_c</span>() <span class="sc">+</span></span>
<span id="cb12-138"><a href="#cb12-138"></a>  <span class="fu">coord_quickmap</span>(<span class="at">expand =</span> F) <span class="sc">+</span></span>
<span id="cb12-139"><a href="#cb12-139"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="cn">NULL</span>, <span class="at">fill =</span> <span class="st">"SST (°C)"</span>) <span class="sc">+</span></span>
<span id="cb12-140"><a href="#cb12-140"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb12-141"><a href="#cb12-141"></a><span class="in">```</span></span>
<span id="cb12-142"><a href="#cb12-142"></a></span>
<span id="cb12-143"><a href="#cb12-143"></a><span class="fu">### Save data</span></span>
<span id="cb12-144"><a href="#cb12-144"></a></span>
<span id="cb12-145"><a href="#cb12-145"></a>With the data downloaded and prepared for further use (and a test visual run), all that's left to do is save them.</span>
<span id="cb12-146"><a href="#cb12-146"></a></span>
<span id="cb12-147"><a href="#cb12-147"></a><span class="in">```{r prep-data, eval=FALSE}</span></span>
<span id="cb12-148"><a href="#cb12-148"></a><span class="co"># Save the data as an .Rds file because it has a much better compression rate than .RData</span></span>
<span id="cb12-149"><a href="#cb12-149"></a><span class="fu">saveRDS</span>(OISST_data, <span class="at">file =</span> <span class="st">"~/Desktop/OISST_vignette.Rds"</span>)</span>
<span id="cb12-150"><a href="#cb12-150"></a><span class="in">```</span></span>
<span id="cb12-151"><a href="#cb12-151"></a></span>
<span id="cb12-152"><a href="#cb12-152"></a>Note above that I have chosen to save the file to my desktop. This is not normally where one (hopefully!) would save such a file. Rather one would be saving these data into the project folder out of which one is working. In the next vignette we will see how to <span class="co">[</span><span class="ot">detect MHWs in gridded data</span><span class="co">](https://robwschlegel.github.io/heatwaveR/articles/gridded_event_detection.html)</span> using the data downloaded here.</span>
<span id="cb12-153"><a href="#cb12-153"></a></span>
<span id="cb12-154"><a href="#cb12-154"></a><span class="fu">## Downloading global data</span></span>
<span id="cb12-155"><a href="#cb12-155"></a></span>
<span id="cb12-156"><a href="#cb12-156"></a>The method for downloading and preparing NOAA OISST data outlined in the first half of this vignette should be considered best practice for all applications except those that specifically need to look at the entire globe. If one needs to download the global dataset then it is preferable to go straight to the source. Note that one may still download the full global dataset using the methods above by setting the lon/lat extent to be the full width and height of the globe. The method outlined below will download over 13,000 individual files. This makes dealing with individual files very easy, but agglomerating them into one file can be very time consuming.</span>
<span id="cb12-157"><a href="#cb12-157"></a></span>
<span id="cb12-158"><a href="#cb12-158"></a><span class="fu">### File information</span></span>
<span id="cb12-159"><a href="#cb12-159"></a></span>
<span id="cb12-160"><a href="#cb12-160"></a>The first step in downloading the full global dataset is to tell you computer where they are. There is an automated way to do this but it requires a couple of additional packages and we aim to keep this vignette as simple and direct as possible. For our purposes today we will manually create the URLs of the files we want to download.</span>
<span id="cb12-161"><a href="#cb12-161"></a></span>
<span id="cb12-162"><a href="#cb12-162"></a><span class="in">```{r NOAA-info, eval=FALSE}</span></span>
<span id="cb12-163"><a href="#cb12-163"></a><span class="co"># First we tell R where the data are on the interwebs</span></span>
<span id="cb12-164"><a href="#cb12-164"></a>OISST_base_url <span class="ot">&lt;-</span> <span class="st">"https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr/"</span></span>
<span id="cb12-165"><a href="#cb12-165"></a><span class="co"># Note that one may go to this URL in any web browser to manually inspect the files</span></span>
<span id="cb12-166"><a href="#cb12-166"></a></span>
<span id="cb12-167"><a href="#cb12-167"></a><span class="co"># Now we create a data.frame that contains all of the dates we want to download</span></span>
<span id="cb12-168"><a href="#cb12-168"></a>  <span class="co"># NB: In order to change the dates download changes the dates in the following line</span></span>
<span id="cb12-169"><a href="#cb12-169"></a>OISST_dates <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">t =</span> <span class="fu">seq</span>(<span class="fu">as.Date</span>(<span class="st">"2019-12-01"</span>), <span class="fu">as.Date</span>(<span class="st">"2019-12-31"</span>), <span class="at">by =</span> <span class="st">"day"</span>))</span>
<span id="cb12-170"><a href="#cb12-170"></a></span>
<span id="cb12-171"><a href="#cb12-171"></a><span class="co"># To finish up this step we add some text to those dates so they match the OISST file names</span></span>
<span id="cb12-172"><a href="#cb12-172"></a>OISST_files <span class="ot">&lt;-</span> OISST_dates <span class="sc">%&gt;%</span> </span>
<span id="cb12-173"><a href="#cb12-173"></a>  <span class="fu">mutate</span>(<span class="at">t_day =</span> <span class="fu">gsub</span>(<span class="st">"-"</span>, <span class="st">""</span>, t),</span>
<span id="cb12-174"><a href="#cb12-174"></a>         <span class="at">t_month =</span> <span class="fu">substr</span>(t_day, <span class="dv">1</span>, <span class="dv">6</span>),</span>
<span id="cb12-175"><a href="#cb12-175"></a>         <span class="at">t_year =</span> <span class="fu">year</span>(t),</span>
<span id="cb12-176"><a href="#cb12-176"></a>         <span class="at">file_name =</span> <span class="fu">paste0</span>(OISST_base_url, t_month, <span class="st">"/"</span>, <span class="st">"oisst-avhrr-v02r01."</span>, t_day ,<span class="st">".nc"</span>))</span>
<span id="cb12-177"><a href="#cb12-177"></a><span class="in">```</span></span>
<span id="cb12-178"><a href="#cb12-178"></a></span>
<span id="cb12-179"><a href="#cb12-179"></a><span class="fu">### Download data</span></span>
<span id="cb12-180"><a href="#cb12-180"></a></span>
<span id="cb12-181"><a href="#cb12-181"></a>Now that we have a dataframe that contains all of the URLs for the files we want to download we'll create a function that will crawl through those URLs and download the files for us.</span>
<span id="cb12-182"><a href="#cb12-182"></a></span>
<span id="cb12-183"><a href="#cb12-183"></a><span class="in">```{r NOAA-dl, eval=FALSE}</span></span>
<span id="cb12-184"><a href="#cb12-184"></a><span class="co"># This function will go about downloading each day of data as a NetCDF file</span></span>
<span id="cb12-185"><a href="#cb12-185"></a><span class="co"># Note that this will download files into a 'data/OISST' folder in the root directory</span></span>
<span id="cb12-186"><a href="#cb12-186"></a>  <span class="co"># If this folder does not exist it will create it</span></span>
<span id="cb12-187"><a href="#cb12-187"></a>  <span class="co"># If it does not automatically create the folder it will need to be done manually</span></span>
<span id="cb12-188"><a href="#cb12-188"></a>  <span class="co"># The folder that is created must be a new folder with no other files in it</span></span>
<span id="cb12-189"><a href="#cb12-189"></a>  <span class="co"># A possible bug with netCDF files in R is they won't load correctly from </span></span>
<span id="cb12-190"><a href="#cb12-190"></a>  <span class="co"># existing folders with other file types in them</span></span>
<span id="cb12-191"><a href="#cb12-191"></a><span class="co"># This function will also check if the file has been previously downloaded</span></span>
<span id="cb12-192"><a href="#cb12-192"></a>  <span class="co"># If it has it will not download it again</span></span>
<span id="cb12-193"><a href="#cb12-193"></a>OISST_url_daily_dl <span class="ot">&lt;-</span> <span class="cf">function</span>(target_URL){</span>
<span id="cb12-194"><a href="#cb12-194"></a>  <span class="fu">dir.create</span>(<span class="st">"~/data/OISST"</span>, <span class="at">showWarnings =</span> F)</span>
<span id="cb12-195"><a href="#cb12-195"></a>  file_name <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"~/data/OISST/"</span>,<span class="fu">sapply</span>(<span class="fu">strsplit</span>(target_URL, <span class="at">split =</span> <span class="st">"/"</span>), <span class="st">"[["</span>, <span class="dv">10</span>))</span>
<span id="cb12-196"><a href="#cb12-196"></a>  <span class="cf">if</span>(<span class="sc">!</span><span class="fu">file.exists</span>(file_name)) <span class="fu">download.file</span>(<span class="at">url =</span> target_URL, <span class="at">method =</span> <span class="st">"libcurl"</span>, <span class="at">destfile =</span> file_name)</span>
<span id="cb12-197"><a href="#cb12-197"></a>}</span>
<span id="cb12-198"><a href="#cb12-198"></a></span>
<span id="cb12-199"><a href="#cb12-199"></a><span class="co"># The more cores used, the faster the data may be downloaded</span></span>
<span id="cb12-200"><a href="#cb12-200"></a>  <span class="co"># It is best practice to not use all of the cores on one's machine</span></span>
<span id="cb12-201"><a href="#cb12-201"></a>  <span class="co"># The laptop on which I am running this code has 8 cores, so I use 7 here</span></span>
<span id="cb12-202"><a href="#cb12-202"></a>doParallel<span class="sc">::</span><span class="fu">registerDoParallel</span>(<span class="at">cores =</span> <span class="dv">7</span>)</span>
<span id="cb12-203"><a href="#cb12-203"></a></span>
<span id="cb12-204"><a href="#cb12-204"></a><span class="co"># And with that we are clear for take off</span></span>
<span id="cb12-205"><a href="#cb12-205"></a><span class="fu">system.time</span>(plyr<span class="sc">::</span><span class="fu">l_ply</span>(OISST_files<span class="sc">$</span>file_name, <span class="at">.fun =</span> OISST_url_daily_dl, <span class="at">.parallel =</span> T)) <span class="co"># ~15 seconds</span></span>
<span id="cb12-206"><a href="#cb12-206"></a></span>
<span id="cb12-207"><a href="#cb12-207"></a><span class="co"># In roughly 15 seconds a user may have a full month of global data downloaded</span></span>
<span id="cb12-208"><a href="#cb12-208"></a><span class="co"># This scales well into years and decades, and is much faster with more cores</span></span>
<span id="cb12-209"><a href="#cb12-209"></a><span class="co"># Download speeds will also depend on the speed of the users internet connection</span></span>
<span id="cb12-210"><a href="#cb12-210"></a><span class="in">```</span></span>
<span id="cb12-211"><a href="#cb12-211"></a></span>
<span id="cb12-212"><a href="#cb12-212"></a><span class="fu">### Load data</span></span>
<span id="cb12-213"><a href="#cb12-213"></a></span>
<span id="cb12-214"><a href="#cb12-214"></a>The following code chunk contains the function we may use to load and prepare our OISST data for further use in R.</span>
<span id="cb12-215"><a href="#cb12-215"></a></span>
<span id="cb12-216"><a href="#cb12-216"></a><span class="in">```{r NOAA-load, eval=FALSE}</span></span>
<span id="cb12-217"><a href="#cb12-217"></a><span class="co"># This function will load and subset daily data into one data.frame</span></span>
<span id="cb12-218"><a href="#cb12-218"></a><span class="co"># Note that the subsetting by lon/lat is done before the data are loaded</span></span>
<span id="cb12-219"><a href="#cb12-219"></a>  <span class="co"># This means it will use much less RAM and is viable for use on most laptops</span></span>
<span id="cb12-220"><a href="#cb12-220"></a>  <span class="co"># Assuming one's study area is not too large</span></span>
<span id="cb12-221"><a href="#cb12-221"></a>OISST_load <span class="ot">&lt;-</span> <span class="cf">function</span>(file_name, lon1, lon2, lat1, lat2){</span>
<span id="cb12-222"><a href="#cb12-222"></a>      OISST_dat <span class="ot">&lt;-</span> <span class="fu">tidync</span>(file_name) <span class="sc">%&gt;%</span></span>
<span id="cb12-223"><a href="#cb12-223"></a>        <span class="fu">hyper_filter</span>(<span class="at">lon =</span> <span class="fu">between</span>(lon, lon1, lon2),</span>
<span id="cb12-224"><a href="#cb12-224"></a>                     <span class="at">lat =</span> <span class="fu">between</span>(lat, lat1, lat2)) <span class="sc">%&gt;%</span> </span>
<span id="cb12-225"><a href="#cb12-225"></a>        <span class="fu">hyper_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb12-226"><a href="#cb12-226"></a>        <span class="fu">select</span>(lon, lat, time, sst) <span class="sc">%&gt;%</span> </span>
<span id="cb12-227"><a href="#cb12-227"></a>        dplyr<span class="sc">::</span><span class="fu">rename</span>(<span class="at">t =</span> time, <span class="at">temp =</span> sst) <span class="sc">%&gt;%</span> </span>
<span id="cb12-228"><a href="#cb12-228"></a>        <span class="fu">mutate</span>(<span class="at">t =</span> <span class="fu">as.Date</span>(t, <span class="at">origin =</span> <span class="st">"1978-01-01"</span>))</span>
<span id="cb12-229"><a href="#cb12-229"></a>      <span class="fu">return</span>(OISST_dat)</span>
<span id="cb12-230"><a href="#cb12-230"></a>}</span>
<span id="cb12-231"><a href="#cb12-231"></a></span>
<span id="cb12-232"><a href="#cb12-232"></a><span class="co"># Locate the files that will be loaded</span></span>
<span id="cb12-233"><a href="#cb12-233"></a>OISST_files <span class="ot">&lt;-</span> <span class="fu">dir</span>(<span class="st">"~/data/OISST"</span>, <span class="at">full.names =</span> T)</span>
<span id="cb12-234"><a href="#cb12-234"></a></span>
<span id="cb12-235"><a href="#cb12-235"></a><span class="co"># Load the data in parallel</span></span>
<span id="cb12-236"><a href="#cb12-236"></a>OISST_dat <span class="ot">&lt;-</span> plyr<span class="sc">::</span><span class="fu">ldply</span>(<span class="at">.data =</span> OISST_files, <span class="at">.fun =</span> OISST_load, <span class="at">.parallel =</span> T,</span>
<span id="cb12-237"><a href="#cb12-237"></a>                         <span class="at">lon1 =</span> <span class="dv">270</span>, <span class="at">lon2 =</span> <span class="dv">320</span>, <span class="at">lat1 =</span> <span class="dv">30</span>, <span class="at">lat2 =</span> <span class="dv">50</span>)</span>
<span id="cb12-238"><a href="#cb12-238"></a></span>
<span id="cb12-239"><a href="#cb12-239"></a><span class="co"># It should only take a few seconds to load one month of data depending on the size of the lon/lat extent chosen</span></span>
<span id="cb12-240"><a href="#cb12-240"></a><span class="in">```</span></span>
<span id="cb12-241"><a href="#cb12-241"></a></span>
<span id="cb12-242"><a href="#cb12-242"></a>In the code chunk above I have chosen the spatial extent of longitude 270 to 320 and latitude 30 to 50. This a window over the Atlantic Coast of North America. One may simply change the lon/lat values above as necessary to match the desired study area. The function also re-labels the 'time' column as 't', and the 'sst' column as 'temp'. We do this now so that they match the default column names that are expected for calculating MHWs so we won't have to do any extra work later on.</span>
<span id="cb12-243"><a href="#cb12-243"></a></span>
<span id="cb12-244"><a href="#cb12-244"></a>Again, please note that trying to load too much data at once may be too much for the RAM on one's machine. If running the above code causes one's machine to hang, try loading a smaller subset of data. Or make friends with someone with a server sized machine.</span>
<span id="cb12-245"><a href="#cb12-245"></a></span>
<span id="cb12-246"><a href="#cb12-246"></a><span class="fu">### Visualise data</span></span>
<span id="cb12-247"><a href="#cb12-247"></a></span>
<span id="cb12-248"><a href="#cb12-248"></a>It is always good to visualise data early and often in any workflow. The code pipeline below shows how we can visualise a day of data from those we've loaded.</span>
<span id="cb12-249"><a href="#cb12-249"></a></span>
<span id="cb12-250"><a href="#cb12-250"></a><span class="in">```{r NOAA-visual, eval=FALSE}</span></span>
<span id="cb12-251"><a href="#cb12-251"></a>OISST_dat <span class="sc">%&gt;%</span> </span>
<span id="cb12-252"><a href="#cb12-252"></a>  <span class="fu">filter</span>(t <span class="sc">==</span> <span class="st">"2019-12-01"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-253"><a href="#cb12-253"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> lon, <span class="at">y =</span> lat)) <span class="sc">+</span></span>
<span id="cb12-254"><a href="#cb12-254"></a>  <span class="fu">geom_tile</span>(<span class="fu">aes</span>(<span class="at">fill =</span> temp)) <span class="sc">+</span></span>
<span id="cb12-255"><a href="#cb12-255"></a>  <span class="fu">scale_fill_viridis_c</span>() <span class="sc">+</span></span>
<span id="cb12-256"><a href="#cb12-256"></a>  <span class="fu">coord_quickmap</span>(<span class="at">expand =</span> F) <span class="sc">+</span></span>
<span id="cb12-257"><a href="#cb12-257"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">y =</span> <span class="cn">NULL</span>, <span class="at">fill =</span> <span class="st">"SST (°C)"</span>) <span class="sc">+</span></span>
<span id="cb12-258"><a href="#cb12-258"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb12-259"><a href="#cb12-259"></a><span class="in">```</span></span>
<span id="cb12-260"><a href="#cb12-260"></a></span>
<span id="cb12-261"><a href="#cb12-261"></a>In the next vignette we will see how to <span class="co">[</span><span class="ot">detect MHWs in gridded data</span><span class="co">](https://robwschlegel.github.io/heatwaveR/articles/gridded_event_detection.html)</span>.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>© 2025, AJ Smit</p>
</div>   
    <div class="nav-footer-center">

<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/ajsmit/tangled_bank/edit/main/vignettes/prep_NOAA_OISST.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/ajsmit/tangled_bank/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>


<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>