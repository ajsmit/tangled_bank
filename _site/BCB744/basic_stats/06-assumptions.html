<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<meta name="author" content="AJ Smit">
<meta name="dcterms.date" content="2021-01-01">
<title>The Tangled Bank - 6. Assumptions for parametric statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../BCB744/basic_stats/07-t_tests.html" rel="next">
<link href="../../BCB744/basic_stats/05a-decision_guide.html" rel="prev">
<link href="../../images/favicon.ico" rel="icon">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-SCYH68M489"></script><script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-SCYH68M489', { 'anonymize_ip': true});
</script><script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script><style>html{ scroll-behavior: smooth; }</style>
<script async="" src="https://hypothes.is/embed.js"></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><link rel="stylesheet" href="../../styles.css">
</head>
<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg navbar-dark "><div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">The Tangled Bank</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
<li class="nav-item">
    <a class="nav-link active" href="../../index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-vignettes" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Vignettes</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-vignettes">
<li>
    <a class="dropdown-item" href="../../vignettes/Lab_streaks.html" rel="" target="">
 <span class="dropdown-text">Detect lab event streaks based on specified thresholds</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/netCDF_dates.html" rel="" target="">
 <span class="dropdown-text">Dates From netCDF Files: Two Approaches</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/prep_NOAA_OISST.html" rel="" target="">
 <span class="dropdown-text">Downloading and Prep: ERDDAP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/chl_ERDDAP.html" rel="" target="">
 <span class="dropdown-text">Retrieving Chlorophyll-a Data from ERDDAP Servers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/MHW_basic_detection.html" rel="" target="">
 <span class="dropdown-text">Basic Detection and Visualisation of Events</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/alt_method.html" rel="" target="">
 <span class="dropdown-text">Downloading and Prep: Python + CDO</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/gridded_data.html" rel="" target="">
 <span class="dropdown-text">Detecting Events in Gridded Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/regridding.html" rel="" target="">
 <span class="dropdown-text">Regridding gridded data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/MHW_MCS_horizonplots.html" rel="" target="">
 <span class="dropdown-text">Displaying MHWs and MCSs as Horizon Plots</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/heatwaveR_issues.html" rel="" target="">
 <span class="dropdown-text">heatwaveR Issues</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/chl_sightings.html" rel="" target="">
 <span class="dropdown-text">Plotting the Whale Sightings and Chlorophyll-<em>a</em> Concentrations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/chl_localisation.html" rel="" target="">
 <span class="dropdown-text">Spatial Localisation, Subsetting, and Aggregation of the Chlorophyll-<em>a</em> Data</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/elem_ts_methods.html" rel="" target="">
 <span class="dropdown-text">Wavelet Analysis of Diatom Time Series</span></a>
  </li>  
    </ul>
</li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-high-performace-computing" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">High-Performace Computing</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-high-performace-computing">
<li>
    <a class="dropdown-item" href="../../vignettes/README_Lengau.html" rel="" target="">
 <span class="dropdown-text">Using Lengau</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/PBSPro_users.html" rel="" target="">
 <span class="dropdown-text">PBSPro user and job management</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../vignettes/README_tmux.html" rel="" target="">
 <span class="dropdown-text">Using tmux</span></a>
  </li>  
    </ul>
</li>
</ul>
<ul class="navbar-nav navbar-nav-scroll ms-auto">
<li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ajsmit" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-github">
<li>
    <a class="dropdown-item" href="https://github.com/ajsmit/tangled_bank" rel="" target="">
 <span class="dropdown-text">Source Code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://bugs.com" rel="" target="">
 <span class="dropdown-text">Report a Bug</span></a>
  </li>  
    </ul>
</li>
</ul>
<div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../BCB744/basic_stats/01-data-in-R.html">BCB744 (Biostatistics)</a></li><li class="breadcrumb-item"><a href="../../BCB744/basic_stats/06-assumptions.html">6. Assumptions for parametric statistics</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/hex_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
 <span class="menu-text">☘︎</span>
  </li>
        <li class="sidebar-item">
 <span class="menu-text">UNDERGRADUATE</span>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">BDC223</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/BDC223_FAQ.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FAQ</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">BDC334</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BDC334/BDC334_index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BDC334: Macroecology and Global Biogeography</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BDC334/01-introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 1: Ecological Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BDC334/02a-r_rstudio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 2a: R and RStudio</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BDC334/02b-env_dist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 2b: Environmental Distance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BDC334/03-biodiversity1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 3: Quantifying Biodiversity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BDC334/04-biodiversity2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lab 4: Describing Biodiversity Patterns</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../pages/Transboundary_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Transboundary systems</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
 <span class="menu-text">☘</span>
  </li>
        <li class="sidebar-item">
 <span class="menu-text">HONOURS CORE</span>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">BCB744 (Intro R)</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/BCB744_index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BCB744: Introduction to R, and Biostatistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/01-RStudio.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. R and RStudio</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/02-working-with-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Working with data and code</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/03-workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. R workflows</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/04-graphics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Graphics with ggplot2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/05-faceting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Faceting figures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/06-brewing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Brewing colours</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/07-mapping.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Mapping with ggplot2</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/08-mapping_style.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. Mapping with style</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/09-mapping_rnaturalearth.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Mapping with Natural Earth and the <strong>sf</strong> package</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/10-mapping_quakes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. The Fiji Earthquake Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/11-tidy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Tidy data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/12-tidier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Tidier data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/13-tidiest.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13. Tidiest data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/14-recap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">14. Recap</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/15-functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15. Functions by chapter</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/16-base_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">16. Base R primer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/intro_r/17-dates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17. Dates</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">BCB744 (Biostatistics)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/01-data-in-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1. Data classes and structures in R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/02-summarise-and-describe.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2. Exploring with summaries and descriptions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/03-visualise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3. Exploring with figures</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/04-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4. Data distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/05-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Statistical inference and hypothesis testing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/05a-decision_guide.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5a. A quick guide to selecting the right test</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/06-assumptions.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">6. Assumptions for parametric statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/07-t_tests.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. <em>t</em>-tests</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/08-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8. Analysis of Variance (ANOVA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/09-regressions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Simple linear regressions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/10-correlations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Correlations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/11-glance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11. Non-parametric statistical tests at a glance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB744/basic_stats/12-confidence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Confidence intervals</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
 <span class="menu-text">☘</span>
  </li>
        <li class="sidebar-item">
 <span class="menu-text">HONOURS ELECTIVES</span>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">BCB743</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/BCB743_index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BCB743: Quantitative Ecology</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/00-review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1-4. Review Biogeography and Global Ecology</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/05-correlations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5. Correlations and Associations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/06-deep_dive.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6. Deep Dive into Gradients</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/07-ordination.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7. Ordination</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/08-PCA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8a. Principal Component Analysis (PCA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/08-PCA_examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8b. PCA Additional Examples</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/08-PCA_SDG.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8c. PCA of WHO SDGs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/09-CA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9. Correspondence Analysis (CA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/10-PCoA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10. Principal Coordinate Analysis (PCoA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/11-nMDS.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11a. non-Metric Multidimensional Scaling (nMDS)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/11-nMDS_diatoms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11b. nMDS of Mayombo’s Diatom Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/12-constrained_ordination.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12. Constrained Ordination</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../BCB743/13-cluster_analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13. Cluster Analysis</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
 <span class="menu-text">☘︎</span>
  </li>
        <li class="sidebar-item">
 <span class="menu-text">SUPPORT</span>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
 <span class="menu-text">Web Resources</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/general_resources_web.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">R Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/ecology_resources_web.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantitative Ecology Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../resources/spatial_resources_web.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Spatial R Resources</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
 <span class="menu-text">☘︎</span>
  </li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul>
<li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a></li>
  <li>
<a href="#sec-assum" id="toc-sec-assum" class="nav-link" data-scroll-target="#sec-assum"><span class="header-section-number">2</span> Testing the assumptions</a>
  <ul class="collapse">
<li><a href="#tests-for-normality" id="toc-tests-for-normality" class="nav-link" data-scroll-target="#tests-for-normality"><span class="header-section-number">2.1</span> Tests for normality</a></li>
  <li><a href="#sec-homogeneity" id="toc-sec-homogeneity" class="nav-link" data-scroll-target="#sec-homogeneity"><span class="header-section-number">2.2</span> Tests for homogeneity of variances</a></li>
  </ul>
</li>
  <li><a href="#sec-nonparam" id="toc-sec-nonparam" class="nav-link" data-scroll-target="#sec-nonparam"><span class="header-section-number">3</span> Epic fail… now what? Non-parametric statistics!</a></li>
  <li>
<a href="#data-transformations" id="toc-data-transformations" class="nav-link" data-scroll-target="#data-transformations"><span class="header-section-number">4</span> Data transformations</a>
  <ul class="collapse">
<li><a href="#log-transformation" id="toc-log-transformation" class="nav-link" data-scroll-target="#log-transformation"><span class="header-section-number">4.1</span> Log transformation</a></li>
  <li><a href="#arcsine-transformation" id="toc-arcsine-transformation" class="nav-link" data-scroll-target="#arcsine-transformation"><span class="header-section-number">4.2</span> Arcsine transformation</a></li>
  <li><a href="#square-root-transformation" id="toc-square-root-transformation" class="nav-link" data-scroll-target="#square-root-transformation"><span class="header-section-number">4.3</span> Square root transformation</a></li>
  <li><a href="#square-transformation" id="toc-square-transformation" class="nav-link" data-scroll-target="#square-transformation"><span class="header-section-number">4.4</span> Square transformation</a></li>
  <li><a href="#cube-transformation" id="toc-cube-transformation" class="nav-link" data-scroll-target="#cube-transformation"><span class="header-section-number">4.5</span> Cube transformation</a></li>
  <li><a href="#reciprocal-transformation" id="toc-reciprocal-transformation" class="nav-link" data-scroll-target="#reciprocal-transformation"><span class="header-section-number">4.6</span> Reciprocal transformation</a></li>
  <li><a href="#anscombe-transformation" id="toc-anscombe-transformation" class="nav-link" data-scroll-target="#anscombe-transformation"><span class="header-section-number">4.7</span> Anscombe transformation</a></li>
  </ul>
</li>
  <li><a href="#transformation-and-regressions" id="toc-transformation-and-regressions" class="nav-link" data-scroll-target="#transformation-and-regressions"><span class="header-section-number">5</span> Transformation and regressions</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">6</span> Conclusion</a></li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/ajsmit/tangled_bank/edit/main/BCB744/basic_stats/06-assumptions.qmd" class="toc-action">Edit this page</a></p><p><a href="https://github.com/ajsmit/tangled_bank/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full column-body" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">6. Assumptions for parametric statistics</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">When assumptions fail alchemy starts</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><a href="https://ajsmit.netlify.app">AJ Smit</a> <a href="https://orcid.org/0000-0002-3799-6126" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://uwc.ac.za">
            University of the Western Cape
            </a>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2021</p>
    </div>
  </div>
  
    
  </div>
  

</header><div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
In this Chapter
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Revisiting assumptions</li>
<li>Normality and homogeneity of variance tests</li>
<li>Revisiting the non-parametric tests</li>
<li>Log transformation</li>
<li>Square-root transformation</li>
<li>Arcsine transformation</li>
<li>Power transformation</li>
<li>Lesser-used transformation</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tasks to complete in this Chapter
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>None</li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="../../images/paranormal_distributions.jpeg" class="img-fluid figure-img" width="600"></p>
</figure>
</div>
<section id="introduction" class="level1" data-number="1"><h1 data-number="1">
<span class="header-section-number">1</span> Introduction</h1>
<p>Parametric statistical tests such as <em>t</em>-tests, ANOVAs, regressions, and correlations are built on some assumptions about the nature of our data. In life, however, sometimes things get messy and the assumptions go unmet. In this Section we will look in more detail into testing the assumptions and what do do when the assumptions are violated.</p>
<!-- The first challenge involves *assessing whether our data satisfy the necessary assumptions* preceding the main inferential statistical procedure---we will explore the various formal assumption tests later on in this section. -->

<!-- The second challenge can be more tricky, depending on the chosen solution. Suppose the data fail to meet one or more of the necessary assumptions: we now have to decide on the next course of action. First prize is to select a suitable non-parametric alternative to the inferential statistical method required to test our hypotheses. Non-parametric tests do not require assumptions about the underlying population distribution, making them a robust alternative. However, if a suitable non-parametric alternative is not available the only feasible way forward is to apply some form of data transformation to the original dataset to 'force' the data to meet the necessary assumptions and thus permitting us to use a parametric statistical test. This process can be complicated as the physical nature of the data may not allow for easy transformation, and different transformations can lead to different conclusions. -->
<!-- In the sections below we will look at tests for the various assumptions, then we will consider the non-parametric substitutes for the parametric tests, and lastly, we will discuss the alchemy of data transformations. -->
</section><section id="sec-assum" class="level1 page-columns page-full" data-number="2"><h1 data-number="2">
<span class="header-section-number">2</span> Testing the assumptions</h1>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="../../images/wahlberg_assumptions.jpeg" class="img-fluid figure-img" width="600"></p>
</figure>
</div>
</div></div><p>The parametric statistical tests that we are frequently required to perform demand that our data fulfil a few crucial assumptions that are not guaranteed to hold. These assumptions are frequently violated as real-world data, particularly biological data, are typically complex and often contain measurement errors or other sources of variability. Therefore, we need to ensure that:</p>
<ul>
<li>the data are <strong>normally distributed</strong>, meaning that the data follow a Gaussian distribution;</li>
<li>that the data are <strong>homoscedastic</strong>, i.e.&nbsp;the variance should be the same across all levels of the independent variable, and in particular, that there are no outliers;</li>
<li>the dependent variable must be <strong>continuous</strong>,</li>
<li>the observations in the groups being compared are <strong>independent</strong> of each other,</li>
</ul>
<p>I view the last two points as expectations, not an assumptions, because these two aspects of our data are entirely under our control. No amount of transformation or manipulation can make data independent or continuous if they were not produced to be so right from the outset.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<em>i.i.d.</em>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Sometimes we will see the term <em>i.i.d.</em> which stands for “independent and identically distributed”. i.i.d. is a general way of stating the assumptions, particularly bullet points 2-4 above.</p>
<p><strong>Independent</strong> means that the occurrence of one event does not affect the occurrence of any other event in the sample. In other words, the observations are unrelated to each other.</p>
<p><strong>Identically distributed</strong> means that each observation is drawn from the same underlying probability distribution. In other words, the statistical properties of each observation are the same.</p>
</div>
</div>
<p>How do we know that the assumptions of normality and homoscedasticity are not violated? Here are your options. Although I mention the stats tests to use, I will not explain each in detail with examples. You should easily be able to figure it out at this stage of your R journey.</p>
<section id="tests-for-normality" class="level2 page-columns page-full" data-number="2.1"><h2 data-number="2.1" class="anchored" data-anchor-id="tests-for-normality">
<span class="header-section-number">2.1</span> Tests for normality</h2>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-histo1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="06-assumptions_files/figure-html/fig-histo1-1.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Histograms showing two randomly generated normal distributions.</figcaption></figure>
</div>
</div></div></div>
<p>Remember from <a href="../../BCB744/basic_stats/04-distributions.html">Chapter 4</a> what a normal distribution is/looks like? Let’s have a peek below to remind ourselves (<a href="#fig-histo1">Figure&nbsp;1</a>).</p>
<p>Whereas histograms may be a pretty way to check the normality of our data, there are actual statistical tests for this, which is preferable to a visual inspection alone. But remember that you should <em>always</em> visualise your data before performing any statistics on them.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hypothesis for normailty
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(H_{0}\)</span>: The distribution of our data is not different from normal (or, the variable is normally distributed).</p>
</div>
</div>
<p>The <strong>Shapiro-Wilk</strong> test is frequently used to assess the normality of a dataset. It is known to have good power and accuracy for detecting departures from normality, even for small sample sizes, and it is also robust to outliers, making it useful for analysing data that may contain extreme values.</p>
<p>It tests the <em>H</em><sub>0</sub> that <em>the population from which the sample, <span class="math inline">\(x_{1},..., x_{n}\)</span>, was drawn is not significantly different from normal</em>. The test does so by sorting the data from lowest to highest, and a test statistic, <span class="math inline">\(W\)</span>, is calculated based on the deviations of the observed values from the expected values under a normal distribution (<a href="#eq-shapiro">Equation&nbsp;1</a>). <span class="math inline">\(W\)</span> is compared to a critical value, based on the sample size and significance level, to determine whether to reject or fail to reject the <em>H</em><sub>0</sub>.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>The Shapiro-Wilk test</strong>: <span id="eq-shapiro"><span class="math display">\[W = \frac{(\sum_{i=1}^n a_i x_{(i)})^2}{\sum_{i=1}^n (x_i - \overline{x})^2} \tag{1}\]</span></span></p>
<p>Here, <span class="math inline">\(W\)</span> represents the Shapiro-Wilk test statistic, <span class="math inline">\(a_{i}\)</span> are coefficients that depend on the sample size and distribution of the data, <span class="math inline">\(x_{(i)}\)</span> represents the <span class="math inline">\(i\)</span>-th order statistic, or the <span class="math inline">\(i\)</span>-th smallest value in the sample, and <span class="math inline">\(\overline{x}\)</span> represents the sample mean.</p>
</div></div><p>The Shapiro-Wilk test is available within base R as the function <code><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test()</a></code>. If the <em>p</em>-value is <strong>above</strong> 0.05 we may assume the data to be normally distributed. In order to demonstrate what the output of <code><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test()</a></code> looks like we will run it on all of the random data we generated.</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test</a></span><span class="op">(</span><span class="va">r_dat</span><span class="op">$</span><span class="va">dat</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Shapiro-Wilk normality test

data:  r_dat$dat
W = 0.9942, p-value = 4.649e-07</code></pre>
</div>
</div>
<p>Note that this shows that the data are <em>not</em> normally distributed. This is because we have incorrectly run this function simultaneously on two different samples of data. To perform this test correctly, and in the tidy way, we need to recognise the grouping structure (Groups A and B) and select only the second piece of information from the <code><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test()</a></code> output and ensure that it is presented as a numeric value:</p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># we use the square bracket notation to select only the *-value;</span></span>
<span><span class="co"># had we used `[1]` we'd have gotten W</span></span>
<span><span class="va">r_dat</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">sample</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">summarise</span><span class="op">(</span>norm_dat <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
  sample norm_dat
  &lt;chr&gt;     &lt;dbl&gt;
1 A         0.375
2 B         0.461</code></pre>
</div>
</div>
<p>Now we see that our two sample sets are indeed normally distributed.</p>
<p>Several other tests are available to test whether our data are consistent with a normal distribution:</p>
<ul>
<li><p><strong>Kolmogorov-Smirnov test</strong> This test is a non-parametric test that compares the empirical distribution of a sample with a hypothesised normal distribution. It is based on the maximum absolute difference between the cumulative distribution function of the sample and the theoretical normal distribution function. This test can also be used to see if one’s own data are consistent with other kinds of data distributions. In R the Kolmogorov-Smirnov test is available as <code><a href="https://rdrr.io/r/stats/ks.test.html">ks.test()</a></code>.</p></li>
<li><p><strong>Anderson-Darling test</strong> Similar to the Shapiro-Wilk test, the Anderson-Darling test is used to test the hypothesis that a sample comes from a normal (or any other) distribution. It is based on the squared differences between the empirical distribution function of the sample and the theoretical normal distribution function. This function is not natively available in base R but the function <code>ad.test()</code> is made available in two packages (that I know of), namely, <strong>nortest</strong> and <strong>kSamples</strong>. Read the help files—even though the name of the function is the same in the two packages, they are implemented differently.</p></li>
<li><p><strong>Lilliefors test</strong> This test is a modification of the Kolmogorov-Smirnov test that is specifically designed for small sample sizes. It is based on the maximum difference between the empirical distribution function of the sample and the normal distribution function. Some R packages such as <strong>nortest</strong> and <strong>descTools</strong> seem to use Lilliefors synonymously with Kolmogorov-Smirnov. These functions are called <code>lillie.test()</code> and <code>LillieTest()</code>, respectively.</p></li>
<li><p><strong>Jarque-Bera test</strong> This test is based on the skewness and kurtosis of a sample and tests whether the sample has the skewness and kurtosis expected from a normal distribution. Find it in R as <code>jarque.bera.test()</code> in the <strong>DescTools</strong> and <strong>tseries</strong> packages. Again, read the help files as a function with the same name appears in two independent packages and I cannot give assurance that it implemented consistently.</p></li>
<li><p><strong>Cramer-Von Mises test</strong> The Cramer-Von Mises test is used to assess the goodness of fit of a distribution to a sample of data. The test is based on the cumulative distribution function (CDF) of the sample and the theoretical distribution being tested. See the <code>cvm.test()</code> function in the <strong>goftest</strong> package.</p></li>
</ul>
<p>Take your pick. The Shapiro-Wilk and Kolmogorov-Smirnov tests are the most frequently used normality tests in my experience but be adventurous and use the Cramer-Von Mises test and surprise your supervisor in an interesting way—more than likely, they will not have heard of it before. When you decide, however, do your homework and read about these pros and cons of the tests as they are not all equally robust to all the surprises data can throw at them.</p>
</section><section id="sec-homogeneity" class="level2 page-columns page-full" data-number="2.2"><h2 data-number="2.2" class="anchored" data-anchor-id="sec-homogeneity">
<span class="header-section-number">2.2</span> Tests for homogeneity of variances</h2>
<p>Besides requiring that our data are normally distributed, we must also ensure that they are <strong>homoscedastic</strong>. This word means that the scedasticity (variance) of our samples is homogeneous (similar). In practical terms this means that the variance of the samples we are comparing should not be more than two to four times greater than one another. In R, we use the function <code><a href="https://rdrr.io/r/stats/cor.html">var()</a></code> to check the variance in a sample:</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">r_dat</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">group_by</span><span class="op">(</span><span class="va">sample</span><span class="op">)</span> <span class="op">%&gt;%</span> </span>
<span>  <span class="fu">summarise</span><span class="op">(</span>sample_var <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 2
  sample sample_var
  &lt;chr&gt;       &lt;dbl&gt;
1 A            8.72
2 B            3.97</code></pre>
</div>
</div>
<p>Above we see that the variance of our two samples is homoscedastic because the variance of one is not more than two to four times greater than the other. However, there are formal tests to establish the equality of variances, as we can see in the following hypothesis tests:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hypotheses for equality of variances
</div>
</div>
<div class="callout-body-container callout-body">
<p>The two-sided and one-sided formulations are:</p>
<p><span class="math inline">\(H_{0}: \sigma^{2}_{A} = \sigma^{2}_{B}\)</span> and <span class="math inline">\(H_{a}: \sigma^{2}_{A} \ne \sigma^{2}_{B}\)</span></p>
<p><span class="math inline">\(H_{0}: \sigma^{2}_{A} \le \sigma^{2}_{B}\)</span> and <span class="math inline">\(H_{a}: \sigma^{2}_{A} \gt \sigma^{2}_{B}\)</span></p>
<p><span class="math inline">\(H_{0}: \sigma^{2}_{A} \ge \sigma^{2}_{B}\)</span> and <span class="math inline">\(H_{a}: \sigma^{2}_{A} \lt \sigma^{2}_{B}\)</span></p>
<p>where <span class="math inline">\(\sigma^{2}_{A}\)</span> and <span class="math inline">\(\sigma^{2}_{B}\)</span> are the variances for samples <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, respectively.</p>
</div>
</div>
<p>The most commonly used test for equality of variances is <strong>Levene’s test</strong>, <code>leveneTest()</code>. Levene’s test assess the equality of variances between two or more groups in a dataset. The <em>H</em><sub>0</sub> is that the variances of the groups are equal. It is a non-parametric test that does not assume anything about the data’s normality and as such it is more robust than the <em>F</em>-test.</p>
<p>The test is commonly used in <em>t</em>-tests and ANOVA to check that the variances of the dependent variable are the same across all levels of the independent variable. Violating this assumption can lead to incorrect conclusions made from the test outcome, such as those resulting from Type I and Type II errors.</p>
<p>In Levene’s test, the absolute deviations of the observations from their group medians are calculated, and the test statistic is computed as the ratio of the sum of the deviations to the degrees of freedom (<a href="#eq-levene">Equation&nbsp;2</a>). The test statistic follows an <em>F</em> distribution under the <em>H</em><sub>0</sub>, and a significant result indicates that the variances of the groups are significantly different.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Levene’s test</strong>:</p>
<p><span id="eq-levene"><span class="math display">\[W = \frac{(N-k)}{(k-1)} \cdot \frac{\sum_{i=1}^k n_i (\bar{z}_i - \bar{z})^2}{\sum_{i=1}^k \sum_{j=1}^{n_i} (z_{ij} - \bar{z}_i)^2} \tag{2}\]</span></span></p>
<p>where <span class="math inline">\(W\)</span> represents the Levene’s test statistic, <span class="math inline">\(N\)</span> is the total sample size, <span class="math inline">\(k\)</span> is the number of groups being compared, <span class="math inline">\(n_i\)</span> is the sample size of the <span class="math inline">\(i\)</span>-th group, <span class="math inline">\(z_{ij}\)</span> is the <span class="math inline">\(j\)</span>-th observation in the <span class="math inline">\(i\)</span>-th group, <span class="math inline">\(z_{i}\)</span> is the mean of the ith group, and <span class="math inline">\(\bar{z}\)</span> is the overall mean of all groups combined.</p>
<p>The test statistic is calculated by comparing the deviations of the observations within each group from their group mean (<span class="math inline">\(\bar{z}_i\)</span>) to the deviations of the group means from the overall mean (<span class="math inline">\(\bar{z}\)</span>).</p>
</div></div><p>Levene’s test is considered robust to non-normality and outliers, making it a useful tool for analysing data that do not meet the assumptions of normality, but it can be sensitive to unequal sample sizes and may not be appropriate for very small sample sizes.</p>
<p>Several other statistical tests are available to assess the homogeneity of variances in a dataset:</p>
<ul>
<li><p><strong><em>F</em>-test</strong> This test is also known as the variance ratio test. Use the <code><a href="https://rdrr.io/r/stats/var.test.html">var.test()</a></code> function in R. It assumes that the underlying data follows a normal distribution and is designed to test the <em>H</em><sub>0</sub> that the variances of two populations are equal. The test statistic is the ratio of the variances of the two populations. You will often see this test used in the context of an ANOVA to test for homogeneity of variance across groups.</p></li>
<li><p><strong>Bartlett’s test</strong> This test is similar to Levene’s test and is used to assess the equality of variances across multiple groups. The test is based on the <span class="math inline">\(\chi\)</span>-squared distribution and assumes that the data are normally distributed. Base R has the <code><a href="https://rdrr.io/r/stats/bartlett.test.html">bartlett.test()</a></code> function.</p></li>
<li><p><strong>Brown-Forsythe test</strong> This test is a modification of the Levene’s test that uses the absolute deviations of the observations from their respective group medians instead of means. This makes the test more robust to outliers and non-normality. It is available in <strong>onewaytests</strong> as the function <code>bf.test()</code>.</p></li>
<li><p><strong>Fligner-Killeen test</strong> This is another non-parametric test that uses the medians of the groups instead of the means. It is based on the <span class="math inline">\(\chi\)</span>-squared distribution and is also robust to non-normality and outliers. The Fligner test is available in Base R as <code><a href="https://rdrr.io/r/stats/fligner.test.html">fligner.test()</a></code>.</p></li>
</ul>
<p>As always, supplement your analysis with these checks: i) perform any of the diagnostic plots we covered in the earlier Chapters, or ii) compare the variances and see if they differ by more than a factor of four.</p>
<p>See <a href="https://stats.stackexchange.com/questions/91872/alternatives-to-one-way-anova-for-heteroskedastic-data">this discussion</a> if you would like to know about some more advanced options when faced with heteroscedastic data.</p>
</section></section><section id="sec-nonparam" class="level1" data-number="3"><h1 data-number="3">
<span class="header-section-number">3</span> Epic fail… now what? Non-parametric statistics!</h1>
<p>Tests for these two assumptions fail often with real data. Once we have evaluated our data against the two critical assumptions and discovered that one or both of the assumptions are not met, we are presented with two options. Firstly, we can select an appropriate non-parametric test. If that is not possible, then we may need to consider transforming our data. However, it is preferable to avoid the latter option whenever feasible.</p>
<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Parametric and non-parametric tests
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Parametric tests</strong> assume that the data follow a specific distribution, such as the normal distribution, and that the population parameters are known or can be estimated from the sample data. Examples of parametric tests include <em>t</em>-tests, ANOVA, and regression analysis.</p>
<p><strong>Non-parametric tests</strong> make fewer assumptions about the underlying distribution of the data and are used when the data do not meet the assumptions of parametric tests. Non-parametric tests do not rely on population parameters but instead use ranks or other non-numerical measures of the data. Examples of non-parametric tests include the <strong>Wilcoxon rank-sum test</strong> (non-parametric substitute for <em>t</em>-tests) or the <strong>Kruskal-Wallis test</strong> (substitute for ANOVA).</p>
<p>In general, parametric tests are more powerful than non-parametric tests when the assumptions are met, but non-parametric tests are more robust and can be used in a wider range of situations. The choice between parametric and non-parametric tests depends on the nature of the data and the research question being addressed.</p>
</div>
</div>
<p>Non-parametric tests do not assume a specific probability distribution for the data. These tests are often used when the assumptions of normality and homoscedasticity underlying parametric tests are violated. The non-parametric substitutes for the parametric tests that we will often have to use are discussed in <a href="../../BCB744/basic_stats/11-glance.html">Chapter 11</a>. Below, however, we will talk about data transformations.</p>
</section><section id="data-transformations" class="level1" data-number="4"><h1 data-number="4">
<span class="header-section-number">4</span> Data transformations</h1>
<p>Data transformation is used to change the scale of the data in a way that makes it conform to the assumptions of normality and homoscedasticity so that we can proceed with parametric tests in the usual way. Transformations can be used to <em>change the shape of the distribution</em> of the data, <em>reduce the effects of outliers</em>, or <em>stabilise the variance</em> across levels of the independent variable. However, we must often first identify the way in which our data are distributed (refer to <a href="../../BCB744/basic_stats/04-distributions.html">Chapter 4</a>) so we may better decide how to transformation them in an attempt to coerce them into a format that will pass the assumptions of normality and homoscedasticity.</p>
<p>Common data transformations include <strong>logarithmic</strong>, <strong>square root</strong>, and <strong>reciprocal</strong> transformations, among others. These transformations can be applied to the dependent variable, independent variable, or both, depending on the nature of the data and the research question of interest.</p>
<p>When selecting a data transformation method, it is important to consider the goals of the analysis, as well as the properties of the data. Different transformations can have different effects on the distribution of the data, and may lead to different conclusions or interpretations of the results.</p>
<p>When transforming data, one does a mathematical operation on the observations and then use these transformed numbers in the statistical tests. After one as conducted the statistical analysis and calculated the mean ± SD (or ± 95% CI), these values are back transformed (i.e.&nbsp;by applying the reverse of the transformation function) to the original scale before being reported. Note that in back-transformed data the SD (or CI) are not necessarily symmetrical, so one cannot simply compute one (e.g.&nbsp;the upper) and then assumed the lower one would be the same distance away from the mean.</p>
<blockquote class="blockquote">
<p>“<em>Torture numbers and they will confess to anything</em>” — Gregg Easterbrook</p>
</blockquote>
<p>When transforming data, it is a good idea to know a bit about how data within your field of study are usually transformed—try and use the same approach in your own work. Don’t try all the various transformations until you find one that works, else it might seem as if you are trying to massage the data into an acceptable outcome. The effects of transformations are often difficult to see on the shape of data distributions, especially when you have few samples, so trust that what you are doing is correct. Unfortunately, as I said before, transforming data requires a bit of experience and knowledge with the subject matter, so read widely before you commit to one.</p>
<p>Some of the texts below come from <a href="http://fmwww.bc.edu/repec/bocode/t/transint.html">this discussion</a> and from <a href="http://www.biostathandbook.com/transformation.html">John H. McDonald</a>. Below (i.e.&nbsp;the text on log transformation, square-root transformation, and arcsine transformation) I have extracted, often verbatim, the excellent text produced by John H MacDonald from his ‘Handbook of Biological Statistics’. Please attribute this text directly to him. I have made minor editorial changes to point towards some R code, but aside from that the text is more-or-less used as is. I strongly suggest reading the preceding text under his ‘Data transformations’ section, as well as consulting the textbook for in-depth reading about biostatistics. Highly recommended!</p>
<section id="log-transformation" class="level2" data-number="4.1"><h2 data-number="4.1" class="anchored" data-anchor-id="log-transformation">
<span class="header-section-number">4.1</span> Log transformation</h2>
<p>Log transformation is often applied to positively skewed data. It consists of taking the log of each observation. You can use either base-10 logs (<code>log10(x)</code>) or base-<span class="math inline">\(e\)</span> logs, also known as natural logs (<code>log(x)</code>). It makes no difference for a statistical test whether you use base-10 logs or natural logs, because they differ by a constant factor; the base- 10 log of a number is just 2.303…× the natural log of the number. You should specify which log you’re using when you write up the results, as it will affect things like the slope and intercept in a regression. I prefer base-10 logs, because it’s possible to look at them and see the magnitude of the original number: <span class="math inline">\(log(1) = 0\)</span>, <span class="math inline">\(log(10) = 1\)</span>, <span class="math inline">\(log(100) = 2\)</span>, etc.</p>
<p>The back transformation is to raise 10 or <span class="math inline">\(e\)</span> to the power of the number; if the mean of your base-10 log-transformed data is 1.43, the back transformed mean is <span class="math inline">\(10^{1.43} = 26.9\)</span> (in R, <code>10^1.43</code>). If the mean of your base-<span class="math inline">\(e\)</span> log-transformed data is 3.65, the back transformed mean is <span class="math inline">\(e^{3.65} = 38.5\)</span> (in R, <code>exp(3.65)</code>). If you have zeros or negative numbers, you can’t take the log; you should add a constant to each number to make them positive and non-zero (i.e.&nbsp;<code>log10(x + 1))</code>. If you have count data, and some of the counts are zero, the convention is to add 0.5 to each number.</p>
<p>Many variables in biology have log-normal distributions, meaning that after log-transformation, the values are normally distributed. This is because if you take a bunch of independent factors and multiply them together, the resulting product is log-normal. For example, let’s say you’ve planted a bunch of weed seeds, then 10 years later you see how tall the trees are. The height of an individual tree would be affected by the nitrogen in the soil, the amount of water, amount of sunlight, amount of insect damage, etc. Having more nitrogen might make a tree 10% larger than one with less nitrogen; the right amount of water might make it 30% larger than one with too much or too little water; more sunlight might make it 20% larger; less insect damage might make it 15% larger, etc. Thus the final size of a tree would be a function of nitrogen × water × sunlight × insects, and mathematically, this kind of function turns out to be log-normal.</p>
</section><section id="arcsine-transformation" class="level2" data-number="4.2"><h2 data-number="4.2" class="anchored" data-anchor-id="arcsine-transformation">
<span class="header-section-number">4.2</span> Arcsine transformation</h2>
<p>Arcsine transformation is commonly used for proportions, which range from 0 to 1, or percentages that go from 0 to 100. Specifically, this transformation is quite useful when the data follow a binomial distribution and have extreme proportions close to 0 or 1.</p>
<p>A biological example of the type of data suitable for arcsine transformation is the proportion of offspring that survives or the proportion of plants that succumbs to a disease; such data often follow a binomial distribution.</p>
<p>This transformation involves of taking the arcsine of the square root of a number (in R, <code>arcsin(sqrt(x))</code>). (The result is given in radians, not degrees, and can range from −π/2 to π/2). The numbers to be arcsine transformed must be in the range 0 to 1. […] the back-transformation is to square the sine of the number (in R, <code>sin(x)^2</code>).</p>
</section><section id="square-root-transformation" class="level2" data-number="4.3"><h2 data-number="4.3" class="anchored" data-anchor-id="square-root-transformation">
<span class="header-section-number">4.3</span> Square root transformation</h2>
<p>The square root transformation (in R, <code>sqrt(x)</code>) is often used to stabilise the variance of data that have a non-linear relationship between the mean and variance (heteroscedasticity). It is effective for reducing right-skewness (positively skewed). Taking the square root of each observation has the effect of compressing the data towards zero and reducing the impact of extreme values. It is a monotonic transformation, which means that it preserves the order of the data and does not change the relative rankings of the observations.</p>
<p>The square root transformation does not work with negative values, but one could add a constant to each number to make them positive.</p>
<p>A square root transformation is most frequently applied where the data are counts or frequencies, such as the number of individuals in a population or the number of events in a certain time period. Count data are prone to the variance increasing with the mean due to the discrete nature of the data. In these cases, the data tend to follow a Poisson distribution, which is characterised by a variance that is equal to the mean. The same applies to some environmental data, such as rainfall or wind; these may also exhibit heteroscedasticity due to extreme weather phenomena.</p>
</section><section id="square-transformation" class="level2" data-number="4.4"><h2 data-number="4.4" class="anchored" data-anchor-id="square-transformation">
<span class="header-section-number">4.4</span> Square transformation</h2>
<p>Another transformation available for dealing with heteroscedasticity is the square transformation. As the name suggests, it involves taking the square of each observation in a dataset (<code>x^2</code>). The effect sought is to reduce left skewness.</p>
<p>This transformation has the effect of magnifying the differences between values and so increasing the influence of extreme values. However, this can make outliers more prominent and can make it more challenging to interpret the results of statistical analysis.</p>
<p>The square transformation is often used in situations where the data are related to areas or volumes, such as the size of cells or the volume of an organ, where the data may follow a nonlinear relationship between the mean and variance.</p>
</section><section id="cube-transformation" class="level2" data-number="4.5"><h2 data-number="4.5" class="anchored" data-anchor-id="cube-transformation">
<span class="header-section-number">4.5</span> Cube transformation</h2>
<p>This transformation also applies to heteroscedastic data. It is sometimes used with moderately left skewed data. This transformation is more drastic than a square transformation, and the drawback are more severe.</p>
<p>The cube transformation is less commonly used than other data transformations such as square-root or log transformation. Use with caution.</p>
</section><section id="reciprocal-transformation" class="level2" data-number="4.6"><h2 data-number="4.6" class="anchored" data-anchor-id="reciprocal-transformation">
<span class="header-section-number">4.6</span> Reciprocal transformation</h2>
<p>It involves taking the reciprocal or inverse of each observation in a dataset (<code>1/x</code>). It is another variance stabilising transformation and is used with severely positively skewed data.</p>
</section><section id="anscombe-transformation" class="level2" data-number="4.7"><h2 data-number="4.7" class="anchored" data-anchor-id="anscombe-transformation">
<span class="header-section-number">4.7</span> Anscombe transformation</h2>
<p>Another variance stabilising transformation is the Anscombe transformation, <code>sqrt(max(x+1)-x)</code>. It is applied to negatively skewed data. This transformation can be used to shift the data and compress it towards zero, and remove the influence of extreme values. It is a monotonic transformation, which means that it preserves the order of the data and does not change the relative rankings of the observations.</p>
<p>The Anscombe transformation is useful when dealing with count or frequency data that have a non-linear relationship between the mean and variance; such data are characteristic of Poisson-distributed count data.</p>
<!-- ## Other transformations -->
<!-- -- `log10(max(x + 1) - x)` for negatively skewed data -->
<!-- -- `1/(max(x + 1) - x)` or higher powers than cubes for negatively skewed data -->
</section></section><section id="transformation-and-regressions" class="level1" data-number="5"><h1 data-number="5">
<span class="header-section-number">5</span> Transformation and regressions</h1>
<p>Regression models do not necessarily require data transformations to deal with heteroscedasticity. Generalised Linear Models (GLM) can be used with a variety of variance and error structures in the residuals via so-called link functions. Please consult the <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> function for details.</p>
<p>The linearity requirement specifically applies to linear regressions. However, regressions do not have to be linear. Some degree of curvature can be accommodated by additive (polynomial) models, which are like linear regressions, but with additional terms (you already have the knowledge you need to fit such models). More complex departures from linearity can be modelled by non-linear models (e.g.&nbsp;exponential, logistic, Michaelis-Menten, Gompertz, von Bertalanffy, and their ilk) or Generalised Additive Models (GAM)—these more complex relationships will not be covered in this module. The <code>gam()</code> function in the <strong>mgcv</strong> package fits GAMs. After fitting these parametric or semi-parametric models to accommodate non-linear regressions, the residual error structure still does to meet the normality requirements, and these can be tested as before with simple linear regressions.</p>
</section><section id="conclusion" class="level1" data-number="6"><h1 data-number="6">
<span class="header-section-number">6</span> Conclusion</h1>
<p>Knowing how to successfully implement transformations can be as much alchemy as science and requires a great deal of experience to get right. Due to the multitude of options I cannot offer comprehensive examples to deal with all eventualities—so I will not provide any examples at all! I suggest reading widely on the internet or textbooks, and practising by yourselves on your own datasets.</p>
<!-- ::: callout-important -->
<!-- ## Task I -->
<!-- 1. Find one of the days of measurement where the chicken weights do not pass the assumptions of normality, and another day (not day 21!) in which they do. -->
<!-- 2. transformation the data so that they may pass the assumptions. -->
<!-- ::: -->


<!-- -->

</section><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div id="quarto-reuse" class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{smit2021,
  author = {Smit, AJ},
  title = {6. {Assumptions} for Parametric Statistics},
  date = {2021-01-01},
  url = {https://tangledbank.netlify.app/BCB744/basic_stats/06-assumptions.html},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><div class="quarto-appendix-secondary-label">For attribution, please cite this work as:</div><div id="ref-smit2021" class="csl-entry quarto-appendix-citeas" role="listitem">
Smit A (2021) 6. Assumptions for parametric statistics. <a href="https://tangledbank.netlify.app/BCB744/basic_stats/06-assumptions.html">https://tangledbank.netlify.app/BCB744/basic_stats/06-assumptions.html.
</a>
</div></div></section></div></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><script src="https://utteranc.es/client.js" repo="ajsmit/tangled_bank" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script><nav class="page-navigation column-body"><div class="nav-page nav-page-previous">
      <a href="../../BCB744/basic_stats/05a-decision_guide.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">5a. A quick guide to selecting the right test</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../BCB744/basic_stats/07-t_tests.html" class="pagination-link">
        <span class="nav-page-text">7. <em>t</em>-tests</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb7" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2021-01-01"</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "6. Assumptions for parametric statistics"</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "When assumptions fail alchemy starts"</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>::: {.callout-note appearance="simple"}</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="fu">## In this Chapter</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Revisiting assumptions</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Normality and homogeneity of variance tests</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Revisiting the non-parametric tests</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Log transformation</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Square-root transformation</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Arcsine transformation</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Power transformation</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Lesser-used transformation</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>::: {.callout-important appearance="simple"}</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tasks to complete in this Chapter</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>None</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a><span class="al">![](../../images/paranormal_distributions.jpeg)</span>{fig-align="center" width="600"}</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>Parametric statistical tests such as *t*-tests, ANOVAs, regressions, and correlations are built on some assumptions about the nature of our data. In life, however, sometimes things get messy and the assumptions go unmet. In this Section we will look in more detail into testing the assumptions and what do do when the assumptions are violated.</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The first challenge involves *assessing whether our data satisfy the necessary assumptions* preceding the main inferential statistical procedure---we will explore the various formal assumption tests later on in this section. --&gt;</span></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- The second challenge can be more tricky, depending on the chosen solution. Suppose the data fail to meet one or more of the necessary assumptions: we now have to decide on the next course of action. First prize is to select a suitable non-parametric alternative to the inferential statistical method required to test our hypotheses. Non-parametric tests do not require assumptions about the underlying population distribution, making them a robust alternative. However, if a suitable non-parametric alternative is not available the only feasible way forward is to apply some form of data transformation to the original dataset to 'force' the data to meet the necessary assumptions and thus permitting us to use a parametric statistical test. This process can be complicated as the physical nature of the data may not allow for easy transformation, and different transformations can lead to different conclusions. --&gt;</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- In the sections below we will look at tests for the various assumptions, then we will consider the non-parametric substitutes for the parametric tests, and lastly, we will discuss the alchemy of data transformations. --&gt;</span></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="fu"># Testing the assumptions {#sec-assum}</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a><span class="al">![](../../images/wahlberg_assumptions.jpeg)</span>{fig-align="center" width="600"}</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>The parametric statistical tests that we are frequently required to perform demand that our data fulfil a few crucial assumptions that are not guaranteed to hold. These assumptions are frequently violated as real-world data, particularly biological data, are typically complex and often contain measurement errors or other sources of variability. Therefore, we need to ensure that:</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the data are **normally distributed**, meaning that the data follow a Gaussian distribution;</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>that the data are **homoscedastic**, i.e. the variance should be the same across all levels of the independent variable, and in particular, that there are no outliers;</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the dependent variable must be **continuous**,</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>the observations in the groups being compared are **independent** of each other,</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>I view the last two points as expectations, not an assumptions, because these two aspects of our data are entirely under our control. No amount of transformation or manipulation can make data independent or continuous if they were not produced to be so right from the outset.</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>::: {.callout-note appearance="simple"}</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## *i.i.d.*</span></span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>Sometimes we will see the term *i.i.d.* which stands for "independent and identically distributed". i.i.d. is a general way of stating the assumptions, particularly bullet points 2-4 above.</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>**Independent** means that the occurrence of one event does not affect the occurrence of any other event in the sample. In other words, the observations are unrelated to each other.</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>**Identically distributed** means that each observation is drawn from the same underlying probability distribution. In other words, the statistical properties of each observation are the same.</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>How do we know that the assumptions of normality and homoscedasticity are not violated? Here are your options. Although I mention the stats tests to use, I will not explain each in detail with examples. You should easily be able to figure it out at this stage of your R journey.</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tests for normality</span></span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Histograms showing two randomly generated normal distributions."</span></span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-histo1</span></span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a><span class="co">#| column: margin</span></span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a><span class="co"># Random normal data</span></span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">666</span>)</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>r_dat <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">dat =</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">1000</span>, <span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="dv">3</span>),</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a>                            <span class="fu">rnorm</span>(<span class="at">n =</span> <span class="dv">1000</span>, <span class="at">mean =</span> <span class="dv">8</span>, <span class="at">sd =</span> <span class="dv">2</span>)),</span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>                    <span class="at">sample =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"A"</span>, <span class="dv">1000</span>), <span class="fu">rep</span>(<span class="st">"B"</span>, <span class="dv">1000</span>)))</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a><span class="co"># Create histogram</span></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data =</span> r_dat, <span class="fu">aes</span>(<span class="at">x =</span> dat, <span class="at">fill =</span> sample)) <span class="sc">+</span></span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">position =</span> <span class="st">"dodge"</span>, <span class="at">binwidth =</span> <span class="dv">1</span>,</span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>                 <span class="at">colour =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..count.., <span class="at">fill =</span> sample),</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>               <span class="at">colour =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"value"</span>) <span class="sc">+</span></span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>h</span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>Remember from <span class="co">[</span><span class="ot">Chapter 4</span><span class="co">](04-distributions.qmd)</span> what a normal distribution is/looks like? Let's have a peek below to remind ourselves (@fig-histo1). </span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a>Whereas histograms may be a pretty way to check the normality of our data, there are actual statistical tests for this, which is preferable to a visual inspection alone. But remember that you should *always* visualise your data before performing any statistics on them.</span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hypothesis for normailty</span></span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>$H_{0}$: The distribution of our data is not different from normal (or, the variable is normally distributed).</span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>The **Shapiro-Wilk** test is frequently used to assess the normality of a dataset. It is known to have good power and accuracy for detecting departures from normality, even for small sample sizes, and it is also robust to outliers, making it useful for analysing data that may contain extreme values.</span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a>It tests the *H*~0~ that *the population from which the sample, $x_{1},..., x_{n}$, was drawn is not significantly different from normal*. The test does so by sorting the data from lowest to highest, and a test statistic, $W$, is calculated based on the deviations of the observed values from the expected values under a normal distribution (@eq-shapiro). $W$ is compared to a critical value, based on the sample size and significance level, to determine whether to reject or fail to reject the *H*~0~. </span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a>**The Shapiro-Wilk test**:</span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a>$$W = \frac{(\sum_{i=1}^n a_i x_{(i)})^2}{\sum_{i=1}^n (x_i - \overline{x})^2}$$ {#eq-shapiro}</span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a>Here, $W$ represents the Shapiro-Wilk test statistic, $a_{i}$ are coefficients that depend on the sample size and distribution of the data, $x_{(i)}$ represents the $i$-th order statistic, or the $i$-th smallest value in the sample, and $\overline{x}$ represents the sample mean.</span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a>The Shapiro-Wilk test is available within base R as the function <span class="in">`shapiro.test()`</span>. If the *p*-value is **above** 0.05 we may assume the data to be normally distributed. In order to demonstrate what the output of <span class="in">`shapiro.test()`</span> looks like we will run it on all of the random data we generated.</span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(r_dat<span class="sc">$</span>dat)</span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a>Note that this shows that the data are *not* normally distributed. This is because we have incorrectly run this function simultaneously on two different samples of data. To perform this test correctly, and in the tidy way, we need to recognise the grouping structure (Groups A and B) and select only the second piece of information from the <span class="in">`shapiro.test()`</span> output and ensure that it is presented as a numeric value:</span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a><span class="co"># we use the square bracket notation to select only the *-value;</span></span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a><span class="co"># had we used `[1]` we'd have gotten W</span></span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a>r_dat <span class="sc">%&gt;%</span> </span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(sample) <span class="sc">%&gt;%</span> </span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">norm_dat =</span> <span class="fu">as.numeric</span>(<span class="fu">shapiro.test</span>(dat)[<span class="dv">2</span>]))</span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a>Now we see that our two sample sets are indeed normally distributed.</span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a>Several other tests are available to test whether our data are consistent with a normal distribution:</span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Kolmogorov-Smirnov test** This test is a non-parametric test that compares the empirical distribution of a sample with a hypothesised normal distribution. It is based on the maximum absolute difference between the cumulative distribution function of the sample and the theoretical normal distribution function. This test can also be used to see if one's own data are consistent with other kinds of data distributions. In R the Kolmogorov-Smirnov test is available as <span class="in">`ks.test()`</span>.</span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Anderson-Darling test** Similar to the Shapiro-Wilk test, the Anderson-Darling test is used to test the hypothesis that a sample comes from a normal (or any other) distribution. It is based on the squared differences between the empirical distribution function of the sample and the theoretical normal distribution function. This function is not natively available in base R but the function `ad.test()` is made available in two packages (that I know of), namely, **nortest** and **kSamples**. Read the help files---even though the name of the function is the same in the two packages, they are implemented differently.</span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-150"><a href="#cb7-150" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Lilliefors test** This test is a modification of the Kolmogorov-Smirnov test that is specifically designed for small sample sizes. It is based on the maximum difference between the empirical distribution function of the sample and the normal distribution function. Some R packages such as **nortest** and **descTools** seem to use Lilliefors synonymously with Kolmogorov-Smirnov. These functions are called <span class="in">`lillie.test()`</span> and <span class="in">`LillieTest()`</span>, respectively. </span>
<span id="cb7-151"><a href="#cb7-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Jarque-Bera test** This test is based on the skewness and kurtosis of a sample and tests whether the sample has the skewness and kurtosis expected from a normal distribution. Find it in R as `jarque.bera.test()` in the **DescTools** and **tseries** packages. Again, read the help files as a function with the same name appears in two independent packages and I cannot give assurance that it implemented consistently.</span>
<span id="cb7-153"><a href="#cb7-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-154"><a href="#cb7-154" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Cramer-Von Mises test** The Cramer-Von Mises test is used to assess the goodness of fit of a distribution to a sample of data. The test is based on the cumulative distribution function (CDF) of the sample and the theoretical distribution being tested. See the `cvm.test()` function in the **goftest** package.</span>
<span id="cb7-155"><a href="#cb7-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-156"><a href="#cb7-156" aria-hidden="true" tabindex="-1"></a>Take your pick. The Shapiro-Wilk and Kolmogorov-Smirnov tests are the most frequently used normality tests in my experience but be adventurous and use the Cramer-Von Mises test and surprise your supervisor in an interesting way---more than likely, they will not have heard of it before. When you decide, however, do your homework and read about these pros and cons of the tests as they are not all equally robust to all the surprises data can throw at them.</span>
<span id="cb7-157"><a href="#cb7-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-158"><a href="#cb7-158" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tests for homogeneity of variances {#sec-homogeneity}</span></span>
<span id="cb7-159"><a href="#cb7-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-160"><a href="#cb7-160" aria-hidden="true" tabindex="-1"></a>Besides requiring that our data are normally distributed, we must also ensure that they are **homoscedastic**. This word means that the scedasticity (variance) of our samples is homogeneous (similar). In practical terms this means that the variance of the samples we are comparing should not be more than two to four times greater than one another. In R, we use the function <span class="in">`var()`</span> to check the variance in a sample:</span>
<span id="cb7-161"><a href="#cb7-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-164"><a href="#cb7-164" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb7-165"><a href="#cb7-165" aria-hidden="true" tabindex="-1"></a>r_dat <span class="sc">%&gt;%</span> </span>
<span id="cb7-166"><a href="#cb7-166" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(sample) <span class="sc">%&gt;%</span> </span>
<span id="cb7-167"><a href="#cb7-167" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">sample_var =</span> <span class="fu">var</span>(dat))</span>
<span id="cb7-168"><a href="#cb7-168" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb7-169"><a href="#cb7-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-170"><a href="#cb7-170" aria-hidden="true" tabindex="-1"></a>Above we see that the variance of our two samples is homoscedastic because the variance of one is not more than two to four times greater than the other. However, there are formal tests to establish the equality of variances, as we can see in the following hypothesis tests:</span>
<span id="cb7-171"><a href="#cb7-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-172"><a href="#cb7-172" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb7-173"><a href="#cb7-173" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hypotheses for equality of variances</span></span>
<span id="cb7-174"><a href="#cb7-174" aria-hidden="true" tabindex="-1"></a>The two-sided and one-sided formulations are:</span>
<span id="cb7-175"><a href="#cb7-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-176"><a href="#cb7-176" aria-hidden="true" tabindex="-1"></a>$H_{0}: \sigma^{2}_{A} = \sigma^{2}_{B}$ and $H_{a}: \sigma^{2}_{A} \ne \sigma^{2}_{B}$</span>
<span id="cb7-177"><a href="#cb7-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-178"><a href="#cb7-178" aria-hidden="true" tabindex="-1"></a>$H_{0}: \sigma^{2}_{A} \le \sigma^{2}_{B}$ and $H_{a}: \sigma^{2}_{A} \gt \sigma^{2}_{B}$</span>
<span id="cb7-179"><a href="#cb7-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-180"><a href="#cb7-180" aria-hidden="true" tabindex="-1"></a>$H_{0}: \sigma^{2}_{A} \ge \sigma^{2}_{B}$ and $H_{a}: \sigma^{2}_{A} \lt \sigma^{2}_{B}$</span>
<span id="cb7-181"><a href="#cb7-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-182"><a href="#cb7-182" aria-hidden="true" tabindex="-1"></a>where $\sigma^{2}_{A}$ and $\sigma^{2}_{B}$ are the variances for samples $A$ and $B$, respectively.</span>
<span id="cb7-183"><a href="#cb7-183" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-184"><a href="#cb7-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-185"><a href="#cb7-185" aria-hidden="true" tabindex="-1"></a>The most commonly used test for equality of variances is **Levene's test**, <span class="in">`leveneTest()`</span>. Levene's test assess the equality of variances between two or more groups in a dataset. The *H*~0~ is that the variances of the groups are equal. It is a non-parametric test that does not assume anything about the data's normality and as such it is more robust than the *F*-test.</span>
<span id="cb7-186"><a href="#cb7-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-187"><a href="#cb7-187" aria-hidden="true" tabindex="-1"></a>The test is commonly used in *t*-tests and ANOVA to check that the variances of the dependent variable are the same across all levels of the independent variable. Violating this assumption can lead to incorrect conclusions made from the test outcome, such as those resulting from Type I and Type II errors.</span>
<span id="cb7-188"><a href="#cb7-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-189"><a href="#cb7-189" aria-hidden="true" tabindex="-1"></a>In Levene's test, the absolute deviations of the observations from their group medians are calculated, and the test statistic is computed as the ratio of the sum of the deviations to the degrees of freedom (@eq-levene). The test statistic follows an *F* distribution under the *H*~0~, and a significant result indicates that the variances of the groups are significantly different.</span>
<span id="cb7-190"><a href="#cb7-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-191"><a href="#cb7-191" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb7-192"><a href="#cb7-192" aria-hidden="true" tabindex="-1"></a>**Levene's test**:</span>
<span id="cb7-193"><a href="#cb7-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-194"><a href="#cb7-194" aria-hidden="true" tabindex="-1"></a>$$W = \frac{(N-k)}{(k-1)} \cdot \frac{\sum_{i=1}^k n_i (\bar{z}_i - \bar{z})^2}{\sum_{i=1}^k \sum_{j=1}^{n_i} (z_{ij} - \bar{z}_i)^2}$$ {#eq-levene}</span>
<span id="cb7-195"><a href="#cb7-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-196"><a href="#cb7-196" aria-hidden="true" tabindex="-1"></a>where $W$ represents the Levene's test statistic, $N$ is the total sample size, $k$ is the number of groups being compared, $n_i$ is the sample size of the $i$-th group, $z_{ij}$ is the $j$-th observation in the $i$-th group, $z_{i}$ is the mean of the ith group, and $\bar{z}$ is the overall mean of all groups combined.</span>
<span id="cb7-197"><a href="#cb7-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-198"><a href="#cb7-198" aria-hidden="true" tabindex="-1"></a>The test statistic is calculated by comparing the deviations of the observations within each group from their group mean ($\bar{z}_i$) to the deviations of the group means from the overall mean ($\bar{z}$).</span>
<span id="cb7-199"><a href="#cb7-199" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-200"><a href="#cb7-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-201"><a href="#cb7-201" aria-hidden="true" tabindex="-1"></a>Levene's test is considered robust to non-normality and outliers, making it a useful tool for analysing data that do not meet the assumptions of normality, but it can be sensitive to unequal sample sizes and may not be appropriate for very small sample sizes. </span>
<span id="cb7-202"><a href="#cb7-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-203"><a href="#cb7-203" aria-hidden="true" tabindex="-1"></a>Several other statistical tests are available to assess the homogeneity of variances in a dataset:</span>
<span id="cb7-204"><a href="#cb7-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-205"><a href="#cb7-205" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>***F*-test** This test is also known as the variance ratio test. Use the <span class="in">`var.test()`</span> function in R. It assumes that the underlying data follows a normal distribution and is designed to test the *H*~0~ that the variances of two populations are equal. The test statistic is the ratio of the variances of the two populations. You will often see this test used in the context of an ANOVA to test for homogeneity of variance across groups.</span>
<span id="cb7-206"><a href="#cb7-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-207"><a href="#cb7-207" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Bartlett's test** This test is similar to Levene's test and is used to assess the equality of variances across multiple groups. The test is based on the $\chi$-squared distribution and assumes that the data are normally distributed. Base R has the <span class="in">`bartlett.test()`</span> function.</span>
<span id="cb7-208"><a href="#cb7-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-209"><a href="#cb7-209" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Brown-Forsythe test** This test is a modification of the Levene's test that uses the absolute deviations of the observations from their respective group medians instead of means. This makes the test more robust to outliers and non-normality. It is available in **onewaytests** as the function <span class="in">`bf.test()`</span>.</span>
<span id="cb7-210"><a href="#cb7-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-211"><a href="#cb7-211" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>**Fligner-Killeen test** This is another non-parametric test that uses the medians of the groups instead of the means. It is based on the $\chi$-squared distribution and is also robust to non-normality and outliers. The Fligner test is available in Base R as <span class="in">`fligner.test()`</span>.</span>
<span id="cb7-212"><a href="#cb7-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-213"><a href="#cb7-213" aria-hidden="true" tabindex="-1"></a>As always, supplement your analysis with these checks: i) perform any of the diagnostic plots we covered in the earlier Chapters, or ii) compare the variances and see if they differ by more than a factor of four.</span>
<span id="cb7-214"><a href="#cb7-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-215"><a href="#cb7-215" aria-hidden="true" tabindex="-1"></a>See <span class="co">[</span><span class="ot">this discussion</span><span class="co">](https://stats.stackexchange.com/questions/91872/alternatives-to-one-way-anova-for-heteroskedastic-data)</span> if you would like to know about some more advanced options when faced with heteroscedastic data.</span>
<span id="cb7-216"><a href="#cb7-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-217"><a href="#cb7-217" aria-hidden="true" tabindex="-1"></a><span class="fu"># Epic fail... now what? Non-parametric statistics! {#sec-nonparam}</span></span>
<span id="cb7-218"><a href="#cb7-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-219"><a href="#cb7-219" aria-hidden="true" tabindex="-1"></a>Tests for these two assumptions fail often with real data. Once we have evaluated our data against the two critical assumptions and discovered that one or both of the assumptions are not met, we are presented with two options. Firstly, we can select an appropriate non-parametric test. If that is not possible, then we may need to consider transforming our data. However, it is preferable to avoid the latter option whenever feasible.</span>
<span id="cb7-220"><a href="#cb7-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-221"><a href="#cb7-221" aria-hidden="true" tabindex="-1"></a>::: {.callout-note appearance="simple"}</span>
<span id="cb7-222"><a href="#cb7-222" aria-hidden="true" tabindex="-1"></a><span class="fu">## Parametric and non-parametric tests</span></span>
<span id="cb7-223"><a href="#cb7-223" aria-hidden="true" tabindex="-1"></a>**Parametric tests** assume that the data follow a specific distribution, such as the normal distribution, and that the population parameters are known or can be estimated from the sample data. Examples of parametric tests include *t*-tests, ANOVA, and regression analysis.</span>
<span id="cb7-224"><a href="#cb7-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-225"><a href="#cb7-225" aria-hidden="true" tabindex="-1"></a>**Non-parametric tests** make fewer assumptions about the underlying distribution of the data and are used when the data do not meet the assumptions of parametric tests. Non-parametric tests do not rely on population parameters but instead use ranks or other non-numerical measures of the data. Examples of non-parametric tests include the **Wilcoxon rank-sum test** (non-parametric substitute for *t*-tests) or the **Kruskal-Wallis test** (substitute for ANOVA).</span>
<span id="cb7-226"><a href="#cb7-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-227"><a href="#cb7-227" aria-hidden="true" tabindex="-1"></a>In general, parametric tests are more powerful than non-parametric tests when the assumptions are met, but non-parametric tests are more robust and can be used in a wider range of situations. The choice between parametric and non-parametric tests depends on the nature of the data and the research question being addressed.</span>
<span id="cb7-228"><a href="#cb7-228" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb7-229"><a href="#cb7-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-230"><a href="#cb7-230" aria-hidden="true" tabindex="-1"></a>Non-parametric tests do not assume a specific probability distribution for the data. These tests are often used when the assumptions of normality and homoscedasticity underlying parametric tests are violated. The non-parametric substitutes for the parametric tests that we will often have to use are discussed in <span class="co">[</span><span class="ot">Chapter 11</span><span class="co">](11-glance.qmd)</span>. Below, however, we will talk about data transformations.</span>
<span id="cb7-231"><a href="#cb7-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-232"><a href="#cb7-232" aria-hidden="true" tabindex="-1"></a><span class="fu"># Data transformations</span></span>
<span id="cb7-233"><a href="#cb7-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-234"><a href="#cb7-234" aria-hidden="true" tabindex="-1"></a>Data transformation is used to change the scale of the data in a way that makes it conform to the assumptions of normality and homoscedasticity so that we can proceed with parametric tests in the usual way. Transformations can be used to *change the shape of the distribution* of the data, *reduce the effects of outliers*, or *stabilise the variance* across levels of the independent variable. However, we must often first identify the way in which our data are distributed (refer to <span class="co">[</span><span class="ot">Chapter 4</span><span class="co">](04-distributions.qmd)</span>) so we may better decide how to transformation them in an attempt to coerce them into a format that will pass the assumptions of normality and homoscedasticity.</span>
<span id="cb7-235"><a href="#cb7-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-236"><a href="#cb7-236" aria-hidden="true" tabindex="-1"></a>Common data transformations include **logarithmic**, **square root**, and **reciprocal** transformations, among others. These transformations can be applied to the dependent variable, independent variable, or both, depending on the nature of the data and the research question of interest.</span>
<span id="cb7-237"><a href="#cb7-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-238"><a href="#cb7-238" aria-hidden="true" tabindex="-1"></a>When selecting a data transformation method, it is important to consider the goals of the analysis, as well as the properties of the data. Different transformations can have different effects on the distribution of the data, and may lead to different conclusions or interpretations of the results.</span>
<span id="cb7-239"><a href="#cb7-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-240"><a href="#cb7-240" aria-hidden="true" tabindex="-1"></a>When transforming data, one does a mathematical operation on the observations and then use these transformed numbers in the statistical tests. After one as conducted the statistical analysis and calculated the mean ± SD (or ± 95% CI), these values are back transformed (i.e. by applying the reverse of the transformation function) to the original scale before being reported. Note that in back-transformed data the SD (or CI) are not necessarily symmetrical, so one cannot simply compute one (e.g. the upper) and then assumed the lower one would be the same distance away from the mean.</span>
<span id="cb7-241"><a href="#cb7-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-242"><a href="#cb7-242" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; “*Torture numbers and they will confess to anything*” --- Gregg Easterbrook</span></span>
<span id="cb7-243"><a href="#cb7-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-244"><a href="#cb7-244" aria-hidden="true" tabindex="-1"></a>When transforming data, it is a good idea to know a bit about how data within your field of study are usually transformed---try and use the same approach in your own work. Don't try all the various transformations until you find one that works, else it might seem as if you are trying to massage the data into an acceptable outcome. The effects of transformations are often difficult to see on the shape of data distributions, especially when you have few samples, so trust that what you are doing is correct. Unfortunately, as I said before, transforming data requires a bit of experience and knowledge with the subject matter, so read widely before you commit to one.</span>
<span id="cb7-245"><a href="#cb7-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-246"><a href="#cb7-246" aria-hidden="true" tabindex="-1"></a>Some of the texts below come from <span class="co">[</span><span class="ot">this discussion</span><span class="co">](http://fmwww.bc.edu/repec/bocode/t/transint.html)</span> and from <span class="co">[</span><span class="ot">John H. McDonald</span><span class="co">](http://www.biostathandbook.com/transformation.html)</span>. Below (i.e. the text on log transformation, square-root transformation, and arcsine transformation) I have extracted, often verbatim, the excellent text produced by John H MacDonald from his 'Handbook of Biological Statistics'. Please attribute this text directly to him. I have made minor editorial changes to point towards some R code, but aside from that the text is more-or-less used as is. I strongly suggest reading the preceding text under his 'Data transformations' section, as well as consulting the textbook for in-depth reading about biostatistics. Highly recommended!</span>
<span id="cb7-247"><a href="#cb7-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-248"><a href="#cb7-248" aria-hidden="true" tabindex="-1"></a><span class="fu">## Log transformation</span></span>
<span id="cb7-249"><a href="#cb7-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-250"><a href="#cb7-250" aria-hidden="true" tabindex="-1"></a>Log transformation is often applied to positively skewed data. It consists of taking the log of each observation. You can use either base-10 logs (<span class="in">`log10(x)`</span>) or base-$e$ logs, also known as natural logs (<span class="in">`log(x)`</span>). It makes no difference for a statistical test whether you use base-10 logs or natural logs, because they differ by a constant factor; the base- 10 log of a number is just 2.303...× the natural log of the number. You should specify which log you're using when you write up the results, as it will affect things like the slope and intercept in a regression. I prefer base-10 logs, because it's possible to look at them and see the magnitude of the original number: $log(1) = 0$, $log(10) = 1$, $log(100) = 2$, etc.</span>
<span id="cb7-251"><a href="#cb7-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-252"><a href="#cb7-252" aria-hidden="true" tabindex="-1"></a>The back transformation is to raise 10 or $e$ to the power of the number; if the mean of your base-10 log-transformed data is 1.43, the back transformed mean is $10^{1.43} = 26.9$ (in R, <span class="in">`10^1.43`</span>). If the mean of your base-$e$ log-transformed data is 3.65, the back transformed mean is $e^{3.65} = 38.5$ (in R, <span class="in">`exp(3.65)`</span>). If you have zeros or negative numbers, you can't take the log; you should add a constant to each number to make them positive and non-zero (i.e. <span class="in">`log10(x + 1))`</span>. If you have count data, and some of the counts are zero, the convention is to add 0.5 to each number.</span>
<span id="cb7-253"><a href="#cb7-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-254"><a href="#cb7-254" aria-hidden="true" tabindex="-1"></a>Many variables in biology have log-normal distributions, meaning that after log-transformation, the values are normally distributed. This is because if you take a bunch of independent factors and multiply them together, the resulting product is log-normal. For example, let's say you've planted a bunch of weed seeds, then 10 years later you see how tall the trees are. The height of an individual tree would be affected by the nitrogen in the soil, the amount of water, amount of sunlight, amount of insect damage, etc. Having more nitrogen might make a tree 10% larger than one with less nitrogen; the right amount of water might make it 30% larger than one with too much or too little water; more sunlight might make it 20% larger; less insect damage might make it 15% larger, etc. Thus the final size of a tree would be a function of nitrogen × water × sunlight × insects, and mathematically, this kind of function turns out to be log-normal.</span>
<span id="cb7-255"><a href="#cb7-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-256"><a href="#cb7-256" aria-hidden="true" tabindex="-1"></a><span class="fu">## Arcsine transformation</span></span>
<span id="cb7-257"><a href="#cb7-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-258"><a href="#cb7-258" aria-hidden="true" tabindex="-1"></a>Arcsine transformation is commonly used for proportions, which range from 0 to 1, or percentages that go from 0 to 100. Specifically, this transformation is quite useful when the data follow a binomial distribution and have extreme proportions close to 0 or 1.</span>
<span id="cb7-259"><a href="#cb7-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-260"><a href="#cb7-260" aria-hidden="true" tabindex="-1"></a>A biological example of the type of data suitable for arcsine transformation is the proportion of offspring that survives or the proportion of plants that succumbs to a disease; such data often follow a binomial distribution.</span>
<span id="cb7-261"><a href="#cb7-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-262"><a href="#cb7-262" aria-hidden="true" tabindex="-1"></a>This transformation involves of taking the arcsine of the square root of a number (in R, <span class="in">`arcsin(sqrt(x))`</span>). (The result is given in radians, not degrees, and can range from −π/2 to π/2). The numbers to be arcsine transformed must be in the range 0 to 1. <span class="co">[</span><span class="ot">...</span><span class="co">]</span> the back-transformation is to square the sine of the number (in R, <span class="in">`sin(x)^2`</span>).</span>
<span id="cb7-263"><a href="#cb7-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-264"><a href="#cb7-264" aria-hidden="true" tabindex="-1"></a><span class="fu">## Square root transformation</span></span>
<span id="cb7-265"><a href="#cb7-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-266"><a href="#cb7-266" aria-hidden="true" tabindex="-1"></a>The square root transformation (in R, <span class="in">`sqrt(x)`</span>) is often used to stabilise the variance of data that have a non-linear relationship between the mean and variance (heteroscedasticity). It is effective for reducing right-skewness (positively skewed). Taking the square root of each observation has the effect of compressing the data towards zero and reducing the impact of extreme values. It is a monotonic transformation, which means that it preserves the order of the data and does not change the relative rankings of the observations.</span>
<span id="cb7-267"><a href="#cb7-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-268"><a href="#cb7-268" aria-hidden="true" tabindex="-1"></a>The square root transformation does not work with negative values, but one could add a constant to each number to make them positive.</span>
<span id="cb7-269"><a href="#cb7-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-270"><a href="#cb7-270" aria-hidden="true" tabindex="-1"></a>A square root transformation is most frequently applied where the data are counts or frequencies, such as the number of individuals in a population or the number of events in a certain time period. Count data are prone to the variance increasing with the mean due to the discrete nature of the data. In these cases, the data tend to follow a Poisson distribution, which is characterised by a variance that is equal to the mean. The same applies to some environmental data, such as rainfall or wind; these may also exhibit heteroscedasticity due to extreme weather phenomena.</span>
<span id="cb7-271"><a href="#cb7-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-272"><a href="#cb7-272" aria-hidden="true" tabindex="-1"></a><span class="fu">## Square transformation</span></span>
<span id="cb7-273"><a href="#cb7-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-274"><a href="#cb7-274" aria-hidden="true" tabindex="-1"></a>Another transformation available for dealing with heteroscedasticity is the square transformation. As the name suggests, it involves taking the square of each observation in a dataset (<span class="in">`x^2`</span>). The effect sought is to reduce left skewness.</span>
<span id="cb7-275"><a href="#cb7-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-276"><a href="#cb7-276" aria-hidden="true" tabindex="-1"></a>This transformation has the effect of magnifying the differences between values and so increasing the influence of extreme values. However, this can make outliers more prominent and can make it more challenging to interpret the results of statistical analysis. </span>
<span id="cb7-277"><a href="#cb7-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-278"><a href="#cb7-278" aria-hidden="true" tabindex="-1"></a>The square transformation is often used in situations where the data are related to areas or volumes, such as the size of cells or the volume of an organ, where the data may follow a nonlinear relationship between the mean and variance.</span>
<span id="cb7-279"><a href="#cb7-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-280"><a href="#cb7-280" aria-hidden="true" tabindex="-1"></a><span class="fu">## Cube transformation</span></span>
<span id="cb7-281"><a href="#cb7-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-282"><a href="#cb7-282" aria-hidden="true" tabindex="-1"></a>This transformation also applies to heteroscedastic data. It is sometimes used with moderately left skewed data. This transformation is more drastic than a square transformation, and the drawback are more severe.</span>
<span id="cb7-283"><a href="#cb7-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-284"><a href="#cb7-284" aria-hidden="true" tabindex="-1"></a>The cube transformation is less commonly used than other data transformations such as square-root or log transformation. Use with caution.</span>
<span id="cb7-285"><a href="#cb7-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-286"><a href="#cb7-286" aria-hidden="true" tabindex="-1"></a><span class="fu">## Reciprocal transformation</span></span>
<span id="cb7-287"><a href="#cb7-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-288"><a href="#cb7-288" aria-hidden="true" tabindex="-1"></a>It involves taking the reciprocal or inverse of each observation in a dataset (<span class="in">`1/x`</span>). It is another variance stabilising transformation and is used with severely positively skewed data.</span>
<span id="cb7-289"><a href="#cb7-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-290"><a href="#cb7-290" aria-hidden="true" tabindex="-1"></a><span class="fu">## Anscombe transformation</span></span>
<span id="cb7-291"><a href="#cb7-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-292"><a href="#cb7-292" aria-hidden="true" tabindex="-1"></a>Another variance stabilising transformation is the Anscombe transformation, <span class="in">`sqrt(max(x+1)-x)`</span>. It is applied to negatively skewed data. This transformation can be used to shift the data and compress it towards zero, and remove the influence of extreme values. It is a monotonic transformation, which means that it preserves the order of the data and does not change the relative rankings of the observations.</span>
<span id="cb7-293"><a href="#cb7-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-294"><a href="#cb7-294" aria-hidden="true" tabindex="-1"></a>The Anscombe transformation is useful when dealing with count or frequency data that have a non-linear relationship between the mean and variance; such data are characteristic of Poisson-distributed count data.</span>
<span id="cb7-295"><a href="#cb7-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-296"><a href="#cb7-296" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ## Other transformations --&gt;</span></span>
<span id="cb7-297"><a href="#cb7-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-298"><a href="#cb7-298" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- -- `log10(max(x + 1) - x)` for negatively skewed data --&gt;</span></span>
<span id="cb7-299"><a href="#cb7-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-300"><a href="#cb7-300" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- -- `1/(max(x + 1) - x)` or higher powers than cubes for negatively skewed data --&gt;</span></span>
<span id="cb7-301"><a href="#cb7-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-302"><a href="#cb7-302" aria-hidden="true" tabindex="-1"></a><span class="fu"># Transformation and regressions</span></span>
<span id="cb7-303"><a href="#cb7-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-304"><a href="#cb7-304" aria-hidden="true" tabindex="-1"></a>Regression models do not necessarily require data transformations to deal with heteroscedasticity. Generalised Linear Models (GLM) can be used with a variety of variance and error structures in the residuals via so-called link functions. Please consult the <span class="in">`glm()`</span> function for details.</span>
<span id="cb7-305"><a href="#cb7-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-306"><a href="#cb7-306" aria-hidden="true" tabindex="-1"></a>The linearity requirement specifically applies to linear regressions. However, regressions do not have to be linear. Some degree of curvature can be accommodated by additive (polynomial) models, which are like linear regressions, but with additional terms (you already have the knowledge you need to fit such models). More complex departures from linearity can be modelled by non-linear models (e.g. exponential, logistic, Michaelis-Menten, Gompertz, von Bertalanffy, and their ilk) or Generalised Additive Models (GAM)---these more complex relationships will not be covered in this module. The <span class="in">`gam()`</span> function in the **mgcv** package fits GAMs. After fitting these parametric or semi-parametric models to accommodate non-linear regressions, the residual error structure still does to meet the normality requirements, and these can be tested as before with simple linear regressions.</span>
<span id="cb7-307"><a href="#cb7-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-308"><a href="#cb7-308" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion</span></span>
<span id="cb7-309"><a href="#cb7-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-310"><a href="#cb7-310" aria-hidden="true" tabindex="-1"></a>Knowing how to successfully implement transformations can be as much alchemy as science and requires a great deal of experience to get right. Due to the multitude of options I cannot offer comprehensive examples to deal with all eventualities---so I will not provide any examples at all! I suggest reading widely on the internet or textbooks, and practising by yourselves on your own datasets.</span>
<span id="cb7-311"><a href="#cb7-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-312"><a href="#cb7-312" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ::: callout-important --&gt;</span></span>
<span id="cb7-313"><a href="#cb7-313" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ## Task I --&gt;</span></span>
<span id="cb7-314"><a href="#cb7-314" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- 1. Find one of the days of measurement where the chicken weights do not pass the assumptions of normality, and another day (not day 21!) in which they do. --&gt;</span></span>
<span id="cb7-315"><a href="#cb7-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-316"><a href="#cb7-316" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- 2. transformation the data so that they may pass the assumptions. --&gt;</span></span>
<span id="cb7-317"><a href="#cb7-317" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ::: --&gt;</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">© 2023, AJ Smit</div>   
    <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">This page is built with <a href="https://quarto.org/">Quarto</a>.</div>
  </div>
</footer>


<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>